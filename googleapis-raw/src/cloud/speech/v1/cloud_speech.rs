// This file is generated by rust-protobuf 2.25.2. Do not edit
// @generated

// https://github.com/rust-lang/rust-clippy/issues/702
#![allow(unknown_lints)]
#![allow(clippy::all)]

#![allow(unused_attributes)]
#![cfg_attr(rustfmt, rustfmt::skip)]

#![allow(box_pointers)]
#![allow(dead_code)]
#![allow(missing_docs)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(trivial_casts)]
#![allow(unused_imports)]
#![allow(unused_results)]
//! Generated file from `google/cloud/speech/v1/cloud_speech.proto`

/// Generated files are compatible only with the same version
/// of protobuf runtime.
// const _PROTOBUF_VERSION_CHECK: () = ::protobuf::VERSION_2_25_2;

#[derive(PartialEq,Clone,Default)]
pub struct RecognizeRequest {
    // message fields
    pub config: ::protobuf::SingularPtrField<RecognitionConfig>,
    pub audio: ::protobuf::SingularPtrField<RecognitionAudio>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a RecognizeRequest {
    fn default() -> &'a RecognizeRequest {
        <RecognizeRequest as ::protobuf::Message>::default_instance()
    }
}

impl RecognizeRequest {
    pub fn new() -> RecognizeRequest {
        ::std::default::Default::default()
    }

    // .google.cloud.speech.v1.RecognitionConfig config = 1;


    pub fn get_config(&self) -> &RecognitionConfig {
        self.config.as_ref().unwrap_or_else(|| <RecognitionConfig as ::protobuf::Message>::default_instance())
    }
    pub fn clear_config(&mut self) {
        self.config.clear();
    }

    pub fn has_config(&self) -> bool {
        self.config.is_some()
    }

    // Param is passed by value, moved
    pub fn set_config(&mut self, v: RecognitionConfig) {
        self.config = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_config(&mut self) -> &mut RecognitionConfig {
        if self.config.is_none() {
            self.config.set_default();
        }
        self.config.as_mut().unwrap()
    }

    // Take field
    pub fn take_config(&mut self) -> RecognitionConfig {
        self.config.take().unwrap_or_else(|| RecognitionConfig::new())
    }

    // .google.cloud.speech.v1.RecognitionAudio audio = 2;


    pub fn get_audio(&self) -> &RecognitionAudio {
        self.audio.as_ref().unwrap_or_else(|| <RecognitionAudio as ::protobuf::Message>::default_instance())
    }
    pub fn clear_audio(&mut self) {
        self.audio.clear();
    }

    pub fn has_audio(&self) -> bool {
        self.audio.is_some()
    }

    // Param is passed by value, moved
    pub fn set_audio(&mut self, v: RecognitionAudio) {
        self.audio = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_audio(&mut self) -> &mut RecognitionAudio {
        if self.audio.is_none() {
            self.audio.set_default();
        }
        self.audio.as_mut().unwrap()
    }

    // Take field
    pub fn take_audio(&mut self) -> RecognitionAudio {
        self.audio.take().unwrap_or_else(|| RecognitionAudio::new())
    }
}

impl ::protobuf::Message for RecognizeRequest {
    fn is_initialized(&self) -> bool {
        for v in &self.config {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.audio {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.config)?;
                },
                2 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.audio)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if let Some(ref v) = self.config.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if let Some(ref v) = self.audio.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if let Some(ref v) = self.config.as_ref() {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if let Some(ref v) = self.audio.as_ref() {
            os.write_tag(2, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RecognizeRequest {
        RecognizeRequest::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<RecognitionConfig>>(
                "config",
                |m: &RecognizeRequest| { &m.config },
                |m: &mut RecognizeRequest| { &mut m.config },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<RecognitionAudio>>(
                "audio",
                |m: &RecognizeRequest| { &m.audio },
                |m: &mut RecognizeRequest| { &mut m.audio },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<RecognizeRequest>(
                "RecognizeRequest",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static RecognizeRequest {
        static instance: ::protobuf::rt::LazyV2<RecognizeRequest> = ::protobuf::rt::LazyV2::INIT;
        instance.get(RecognizeRequest::new)
    }
}

impl ::protobuf::Clear for RecognizeRequest {
    fn clear(&mut self) {
        self.config.clear();
        self.audio.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RecognizeRequest {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognizeRequest {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct LongRunningRecognizeRequest {
    // message fields
    pub config: ::protobuf::SingularPtrField<RecognitionConfig>,
    pub audio: ::protobuf::SingularPtrField<RecognitionAudio>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a LongRunningRecognizeRequest {
    fn default() -> &'a LongRunningRecognizeRequest {
        <LongRunningRecognizeRequest as ::protobuf::Message>::default_instance()
    }
}

impl LongRunningRecognizeRequest {
    pub fn new() -> LongRunningRecognizeRequest {
        ::std::default::Default::default()
    }

    // .google.cloud.speech.v1.RecognitionConfig config = 1;


    pub fn get_config(&self) -> &RecognitionConfig {
        self.config.as_ref().unwrap_or_else(|| <RecognitionConfig as ::protobuf::Message>::default_instance())
    }
    pub fn clear_config(&mut self) {
        self.config.clear();
    }

    pub fn has_config(&self) -> bool {
        self.config.is_some()
    }

    // Param is passed by value, moved
    pub fn set_config(&mut self, v: RecognitionConfig) {
        self.config = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_config(&mut self) -> &mut RecognitionConfig {
        if self.config.is_none() {
            self.config.set_default();
        }
        self.config.as_mut().unwrap()
    }

    // Take field
    pub fn take_config(&mut self) -> RecognitionConfig {
        self.config.take().unwrap_or_else(|| RecognitionConfig::new())
    }

    // .google.cloud.speech.v1.RecognitionAudio audio = 2;


    pub fn get_audio(&self) -> &RecognitionAudio {
        self.audio.as_ref().unwrap_or_else(|| <RecognitionAudio as ::protobuf::Message>::default_instance())
    }
    pub fn clear_audio(&mut self) {
        self.audio.clear();
    }

    pub fn has_audio(&self) -> bool {
        self.audio.is_some()
    }

    // Param is passed by value, moved
    pub fn set_audio(&mut self, v: RecognitionAudio) {
        self.audio = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_audio(&mut self) -> &mut RecognitionAudio {
        if self.audio.is_none() {
            self.audio.set_default();
        }
        self.audio.as_mut().unwrap()
    }

    // Take field
    pub fn take_audio(&mut self) -> RecognitionAudio {
        self.audio.take().unwrap_or_else(|| RecognitionAudio::new())
    }
}

impl ::protobuf::Message for LongRunningRecognizeRequest {
    fn is_initialized(&self) -> bool {
        for v in &self.config {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.audio {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.config)?;
                },
                2 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.audio)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if let Some(ref v) = self.config.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if let Some(ref v) = self.audio.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if let Some(ref v) = self.config.as_ref() {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if let Some(ref v) = self.audio.as_ref() {
            os.write_tag(2, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> LongRunningRecognizeRequest {
        LongRunningRecognizeRequest::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<RecognitionConfig>>(
                "config",
                |m: &LongRunningRecognizeRequest| { &m.config },
                |m: &mut LongRunningRecognizeRequest| { &mut m.config },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<RecognitionAudio>>(
                "audio",
                |m: &LongRunningRecognizeRequest| { &m.audio },
                |m: &mut LongRunningRecognizeRequest| { &mut m.audio },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<LongRunningRecognizeRequest>(
                "LongRunningRecognizeRequest",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static LongRunningRecognizeRequest {
        static instance: ::protobuf::rt::LazyV2<LongRunningRecognizeRequest> = ::protobuf::rt::LazyV2::INIT;
        instance.get(LongRunningRecognizeRequest::new)
    }
}

impl ::protobuf::Clear for LongRunningRecognizeRequest {
    fn clear(&mut self) {
        self.config.clear();
        self.audio.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for LongRunningRecognizeRequest {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for LongRunningRecognizeRequest {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct StreamingRecognizeRequest {
    // message oneof groups
    pub streaming_request: ::std::option::Option<StreamingRecognizeRequest_oneof_streaming_request>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a StreamingRecognizeRequest {
    fn default() -> &'a StreamingRecognizeRequest {
        <StreamingRecognizeRequest as ::protobuf::Message>::default_instance()
    }
}

#[derive(Clone,PartialEq,Debug)]
pub enum StreamingRecognizeRequest_oneof_streaming_request {
    streaming_config(StreamingRecognitionConfig),
    audio_content(::std::vec::Vec<u8>),
}

impl StreamingRecognizeRequest {
    pub fn new() -> StreamingRecognizeRequest {
        ::std::default::Default::default()
    }

    // .google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;


    pub fn get_streaming_config(&self) -> &StreamingRecognitionConfig {
        match self.streaming_request {
            ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(ref v)) => v,
            _ => <StreamingRecognitionConfig as ::protobuf::Message>::default_instance(),
        }
    }
    pub fn clear_streaming_config(&mut self) {
        self.streaming_request = ::std::option::Option::None;
    }

    pub fn has_streaming_config(&self) -> bool {
        match self.streaming_request {
            ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(..)) => true,
            _ => false,
        }
    }

    // Param is passed by value, moved
    pub fn set_streaming_config(&mut self, v: StreamingRecognitionConfig) {
        self.streaming_request = ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(v))
    }

    // Mutable pointer to the field.
    pub fn mut_streaming_config(&mut self) -> &mut StreamingRecognitionConfig {
        if let ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(_)) = self.streaming_request {
        } else {
            self.streaming_request = ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(StreamingRecognitionConfig::new()));
        }
        match self.streaming_request {
            ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(ref mut v)) => v,
            _ => panic!(),
        }
    }

    // Take field
    pub fn take_streaming_config(&mut self) -> StreamingRecognitionConfig {
        if self.has_streaming_config() {
            match self.streaming_request.take() {
                ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(v)) => v,
                _ => panic!(),
            }
        } else {
            StreamingRecognitionConfig::new()
        }
    }

    // bytes audio_content = 2;


    pub fn get_audio_content(&self) -> &[u8] {
        match self.streaming_request {
            ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::audio_content(ref v)) => v,
            _ => &[],
        }
    }
    pub fn clear_audio_content(&mut self) {
        self.streaming_request = ::std::option::Option::None;
    }

    pub fn has_audio_content(&self) -> bool {
        match self.streaming_request {
            ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::audio_content(..)) => true,
            _ => false,
        }
    }

    // Param is passed by value, moved
    pub fn set_audio_content(&mut self, v: ::std::vec::Vec<u8>) {
        self.streaming_request = ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::audio_content(v))
    }

    // Mutable pointer to the field.
    pub fn mut_audio_content(&mut self) -> &mut ::std::vec::Vec<u8> {
        if let ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::audio_content(_)) = self.streaming_request {
        } else {
            self.streaming_request = ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::audio_content(::std::vec::Vec::new()));
        }
        match self.streaming_request {
            ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::audio_content(ref mut v)) => v,
            _ => panic!(),
        }
    }

    // Take field
    pub fn take_audio_content(&mut self) -> ::std::vec::Vec<u8> {
        if self.has_audio_content() {
            match self.streaming_request.take() {
                ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::audio_content(v)) => v,
                _ => panic!(),
            }
        } else {
            ::std::vec::Vec::new()
        }
    }
}

impl ::protobuf::Message for StreamingRecognizeRequest {
    fn is_initialized(&self) -> bool {
        if let Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(ref v)) = self.streaming_request {
            if !v.is_initialized() {
                return false;
            }
        }
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    if wire_type != ::protobuf::wire_format::WireTypeLengthDelimited {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    self.streaming_request = ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::streaming_config(is.read_message()?));
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeLengthDelimited {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    self.streaming_request = ::std::option::Option::Some(StreamingRecognizeRequest_oneof_streaming_request::audio_content(is.read_bytes()?));
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if let ::std::option::Option::Some(ref v) = self.streaming_request {
            match v {
                &StreamingRecognizeRequest_oneof_streaming_request::streaming_config(ref v) => {
                    let len = v.compute_size();
                    my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
                },
                &StreamingRecognizeRequest_oneof_streaming_request::audio_content(ref v) => {
                    my_size += ::protobuf::rt::bytes_size(2, &v);
                },
            };
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if let ::std::option::Option::Some(ref v) = self.streaming_request {
            match v {
                &StreamingRecognizeRequest_oneof_streaming_request::streaming_config(ref v) => {
                    os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
                    os.write_raw_varint32(v.get_cached_size())?;
                    v.write_to_with_cached_sizes(os)?;
                },
                &StreamingRecognizeRequest_oneof_streaming_request::audio_content(ref v) => {
                    os.write_bytes(2, v)?;
                },
            };
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> StreamingRecognizeRequest {
        StreamingRecognizeRequest::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_singular_message_accessor::<_, StreamingRecognitionConfig>(
                "streaming_config",
                StreamingRecognizeRequest::has_streaming_config,
                StreamingRecognizeRequest::get_streaming_config,
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_bytes_accessor::<_>(
                "audio_content",
                StreamingRecognizeRequest::has_audio_content,
                StreamingRecognizeRequest::get_audio_content,
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<StreamingRecognizeRequest>(
                "StreamingRecognizeRequest",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static StreamingRecognizeRequest {
        static instance: ::protobuf::rt::LazyV2<StreamingRecognizeRequest> = ::protobuf::rt::LazyV2::INIT;
        instance.get(StreamingRecognizeRequest::new)
    }
}

impl ::protobuf::Clear for StreamingRecognizeRequest {
    fn clear(&mut self) {
        self.streaming_request = ::std::option::Option::None;
        self.streaming_request = ::std::option::Option::None;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for StreamingRecognizeRequest {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for StreamingRecognizeRequest {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct StreamingRecognitionConfig {
    // message fields
    pub config: ::protobuf::SingularPtrField<RecognitionConfig>,
    pub single_utterance: bool,
    pub interim_results: bool,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a StreamingRecognitionConfig {
    fn default() -> &'a StreamingRecognitionConfig {
        <StreamingRecognitionConfig as ::protobuf::Message>::default_instance()
    }
}

impl StreamingRecognitionConfig {
    pub fn new() -> StreamingRecognitionConfig {
        ::std::default::Default::default()
    }

    // .google.cloud.speech.v1.RecognitionConfig config = 1;


    pub fn get_config(&self) -> &RecognitionConfig {
        self.config.as_ref().unwrap_or_else(|| <RecognitionConfig as ::protobuf::Message>::default_instance())
    }
    pub fn clear_config(&mut self) {
        self.config.clear();
    }

    pub fn has_config(&self) -> bool {
        self.config.is_some()
    }

    // Param is passed by value, moved
    pub fn set_config(&mut self, v: RecognitionConfig) {
        self.config = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_config(&mut self) -> &mut RecognitionConfig {
        if self.config.is_none() {
            self.config.set_default();
        }
        self.config.as_mut().unwrap()
    }

    // Take field
    pub fn take_config(&mut self) -> RecognitionConfig {
        self.config.take().unwrap_or_else(|| RecognitionConfig::new())
    }

    // bool single_utterance = 2;


    pub fn get_single_utterance(&self) -> bool {
        self.single_utterance
    }
    pub fn clear_single_utterance(&mut self) {
        self.single_utterance = false;
    }

    // Param is passed by value, moved
    pub fn set_single_utterance(&mut self, v: bool) {
        self.single_utterance = v;
    }

    // bool interim_results = 3;


    pub fn get_interim_results(&self) -> bool {
        self.interim_results
    }
    pub fn clear_interim_results(&mut self) {
        self.interim_results = false;
    }

    // Param is passed by value, moved
    pub fn set_interim_results(&mut self, v: bool) {
        self.interim_results = v;
    }
}

impl ::protobuf::Message for StreamingRecognitionConfig {
    fn is_initialized(&self) -> bool {
        for v in &self.config {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.config)?;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.single_utterance = tmp;
                },
                3 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.interim_results = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if let Some(ref v) = self.config.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if self.single_utterance != false {
            my_size += 2;
        }
        if self.interim_results != false {
            my_size += 2;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if let Some(ref v) = self.config.as_ref() {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if self.single_utterance != false {
            os.write_bool(2, self.single_utterance)?;
        }
        if self.interim_results != false {
            os.write_bool(3, self.interim_results)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> StreamingRecognitionConfig {
        StreamingRecognitionConfig::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<RecognitionConfig>>(
                "config",
                |m: &StreamingRecognitionConfig| { &m.config },
                |m: &mut StreamingRecognitionConfig| { &mut m.config },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "single_utterance",
                |m: &StreamingRecognitionConfig| { &m.single_utterance },
                |m: &mut StreamingRecognitionConfig| { &mut m.single_utterance },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "interim_results",
                |m: &StreamingRecognitionConfig| { &m.interim_results },
                |m: &mut StreamingRecognitionConfig| { &mut m.interim_results },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<StreamingRecognitionConfig>(
                "StreamingRecognitionConfig",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static StreamingRecognitionConfig {
        static instance: ::protobuf::rt::LazyV2<StreamingRecognitionConfig> = ::protobuf::rt::LazyV2::INIT;
        instance.get(StreamingRecognitionConfig::new)
    }
}

impl ::protobuf::Clear for StreamingRecognitionConfig {
    fn clear(&mut self) {
        self.config.clear();
        self.single_utterance = false;
        self.interim_results = false;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for StreamingRecognitionConfig {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for StreamingRecognitionConfig {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct RecognitionConfig {
    // message fields
    pub encoding: RecognitionConfig_AudioEncoding,
    pub sample_rate_hertz: i32,
    pub audio_channel_count: i32,
    pub enable_separate_recognition_per_channel: bool,
    pub language_code: ::std::string::String,
    pub max_alternatives: i32,
    pub profanity_filter: bool,
    pub speech_contexts: ::protobuf::RepeatedField<SpeechContext>,
    pub enable_word_time_offsets: bool,
    pub enable_automatic_punctuation: bool,
    pub diarization_config: ::protobuf::SingularPtrField<SpeakerDiarizationConfig>,
    pub metadata: ::protobuf::SingularPtrField<RecognitionMetadata>,
    pub model: ::std::string::String,
    pub use_enhanced: bool,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a RecognitionConfig {
    fn default() -> &'a RecognitionConfig {
        <RecognitionConfig as ::protobuf::Message>::default_instance()
    }
}

impl RecognitionConfig {
    pub fn new() -> RecognitionConfig {
        ::std::default::Default::default()
    }

    // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;


    pub fn get_encoding(&self) -> RecognitionConfig_AudioEncoding {
        self.encoding
    }
    pub fn clear_encoding(&mut self) {
        self.encoding = RecognitionConfig_AudioEncoding::ENCODING_UNSPECIFIED;
    }

    // Param is passed by value, moved
    pub fn set_encoding(&mut self, v: RecognitionConfig_AudioEncoding) {
        self.encoding = v;
    }

    // int32 sample_rate_hertz = 2;


    pub fn get_sample_rate_hertz(&self) -> i32 {
        self.sample_rate_hertz
    }
    pub fn clear_sample_rate_hertz(&mut self) {
        self.sample_rate_hertz = 0;
    }

    // Param is passed by value, moved
    pub fn set_sample_rate_hertz(&mut self, v: i32) {
        self.sample_rate_hertz = v;
    }

    // int32 audio_channel_count = 7;


    pub fn get_audio_channel_count(&self) -> i32 {
        self.audio_channel_count
    }
    pub fn clear_audio_channel_count(&mut self) {
        self.audio_channel_count = 0;
    }

    // Param is passed by value, moved
    pub fn set_audio_channel_count(&mut self, v: i32) {
        self.audio_channel_count = v;
    }

    // bool enable_separate_recognition_per_channel = 12;


    pub fn get_enable_separate_recognition_per_channel(&self) -> bool {
        self.enable_separate_recognition_per_channel
    }
    pub fn clear_enable_separate_recognition_per_channel(&mut self) {
        self.enable_separate_recognition_per_channel = false;
    }

    // Param is passed by value, moved
    pub fn set_enable_separate_recognition_per_channel(&mut self, v: bool) {
        self.enable_separate_recognition_per_channel = v;
    }

    // string language_code = 3;


    pub fn get_language_code(&self) -> &str {
        &self.language_code
    }
    pub fn clear_language_code(&mut self) {
        self.language_code.clear();
    }

    // Param is passed by value, moved
    pub fn set_language_code(&mut self, v: ::std::string::String) {
        self.language_code = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_language_code(&mut self) -> &mut ::std::string::String {
        &mut self.language_code
    }

    // Take field
    pub fn take_language_code(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.language_code, ::std::string::String::new())
    }

    // int32 max_alternatives = 4;


    pub fn get_max_alternatives(&self) -> i32 {
        self.max_alternatives
    }
    pub fn clear_max_alternatives(&mut self) {
        self.max_alternatives = 0;
    }

    // Param is passed by value, moved
    pub fn set_max_alternatives(&mut self, v: i32) {
        self.max_alternatives = v;
    }

    // bool profanity_filter = 5;


    pub fn get_profanity_filter(&self) -> bool {
        self.profanity_filter
    }
    pub fn clear_profanity_filter(&mut self) {
        self.profanity_filter = false;
    }

    // Param is passed by value, moved
    pub fn set_profanity_filter(&mut self, v: bool) {
        self.profanity_filter = v;
    }

    // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;


    pub fn get_speech_contexts(&self) -> &[SpeechContext] {
        &self.speech_contexts
    }
    pub fn clear_speech_contexts(&mut self) {
        self.speech_contexts.clear();
    }

    // Param is passed by value, moved
    pub fn set_speech_contexts(&mut self, v: ::protobuf::RepeatedField<SpeechContext>) {
        self.speech_contexts = v;
    }

    // Mutable pointer to the field.
    pub fn mut_speech_contexts(&mut self) -> &mut ::protobuf::RepeatedField<SpeechContext> {
        &mut self.speech_contexts
    }

    // Take field
    pub fn take_speech_contexts(&mut self) -> ::protobuf::RepeatedField<SpeechContext> {
        ::std::mem::replace(&mut self.speech_contexts, ::protobuf::RepeatedField::new())
    }

    // bool enable_word_time_offsets = 8;


    pub fn get_enable_word_time_offsets(&self) -> bool {
        self.enable_word_time_offsets
    }
    pub fn clear_enable_word_time_offsets(&mut self) {
        self.enable_word_time_offsets = false;
    }

    // Param is passed by value, moved
    pub fn set_enable_word_time_offsets(&mut self, v: bool) {
        self.enable_word_time_offsets = v;
    }

    // bool enable_automatic_punctuation = 11;


    pub fn get_enable_automatic_punctuation(&self) -> bool {
        self.enable_automatic_punctuation
    }
    pub fn clear_enable_automatic_punctuation(&mut self) {
        self.enable_automatic_punctuation = false;
    }

    // Param is passed by value, moved
    pub fn set_enable_automatic_punctuation(&mut self, v: bool) {
        self.enable_automatic_punctuation = v;
    }

    // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;


    pub fn get_diarization_config(&self) -> &SpeakerDiarizationConfig {
        self.diarization_config.as_ref().unwrap_or_else(|| <SpeakerDiarizationConfig as ::protobuf::Message>::default_instance())
    }
    pub fn clear_diarization_config(&mut self) {
        self.diarization_config.clear();
    }

    pub fn has_diarization_config(&self) -> bool {
        self.diarization_config.is_some()
    }

    // Param is passed by value, moved
    pub fn set_diarization_config(&mut self, v: SpeakerDiarizationConfig) {
        self.diarization_config = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_diarization_config(&mut self) -> &mut SpeakerDiarizationConfig {
        if self.diarization_config.is_none() {
            self.diarization_config.set_default();
        }
        self.diarization_config.as_mut().unwrap()
    }

    // Take field
    pub fn take_diarization_config(&mut self) -> SpeakerDiarizationConfig {
        self.diarization_config.take().unwrap_or_else(|| SpeakerDiarizationConfig::new())
    }

    // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;


    pub fn get_metadata(&self) -> &RecognitionMetadata {
        self.metadata.as_ref().unwrap_or_else(|| <RecognitionMetadata as ::protobuf::Message>::default_instance())
    }
    pub fn clear_metadata(&mut self) {
        self.metadata.clear();
    }

    pub fn has_metadata(&self) -> bool {
        self.metadata.is_some()
    }

    // Param is passed by value, moved
    pub fn set_metadata(&mut self, v: RecognitionMetadata) {
        self.metadata = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_metadata(&mut self) -> &mut RecognitionMetadata {
        if self.metadata.is_none() {
            self.metadata.set_default();
        }
        self.metadata.as_mut().unwrap()
    }

    // Take field
    pub fn take_metadata(&mut self) -> RecognitionMetadata {
        self.metadata.take().unwrap_or_else(|| RecognitionMetadata::new())
    }

    // string model = 13;


    pub fn get_model(&self) -> &str {
        &self.model
    }
    pub fn clear_model(&mut self) {
        self.model.clear();
    }

    // Param is passed by value, moved
    pub fn set_model(&mut self, v: ::std::string::String) {
        self.model = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_model(&mut self) -> &mut ::std::string::String {
        &mut self.model
    }

    // Take field
    pub fn take_model(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.model, ::std::string::String::new())
    }

    // bool use_enhanced = 14;


    pub fn get_use_enhanced(&self) -> bool {
        self.use_enhanced
    }
    pub fn clear_use_enhanced(&mut self) {
        self.use_enhanced = false;
    }

    // Param is passed by value, moved
    pub fn set_use_enhanced(&mut self, v: bool) {
        self.use_enhanced = v;
    }
}

impl ::protobuf::Message for RecognitionConfig {
    fn is_initialized(&self) -> bool {
        for v in &self.speech_contexts {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.diarization_config {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.metadata {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.encoding, 1, &mut self.unknown_fields)?
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.sample_rate_hertz = tmp;
                },
                7 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.audio_channel_count = tmp;
                },
                12 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.enable_separate_recognition_per_channel = tmp;
                },
                3 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.language_code)?;
                },
                4 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.max_alternatives = tmp;
                },
                5 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.profanity_filter = tmp;
                },
                6 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.speech_contexts)?;
                },
                8 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.enable_word_time_offsets = tmp;
                },
                11 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.enable_automatic_punctuation = tmp;
                },
                19 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.diarization_config)?;
                },
                9 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.metadata)?;
                },
                13 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.model)?;
                },
                14 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.use_enhanced = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if self.encoding != RecognitionConfig_AudioEncoding::ENCODING_UNSPECIFIED {
            my_size += ::protobuf::rt::enum_size(1, self.encoding);
        }
        if self.sample_rate_hertz != 0 {
            my_size += ::protobuf::rt::value_size(2, self.sample_rate_hertz, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.audio_channel_count != 0 {
            my_size += ::protobuf::rt::value_size(7, self.audio_channel_count, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.enable_separate_recognition_per_channel != false {
            my_size += 2;
        }
        if !self.language_code.is_empty() {
            my_size += ::protobuf::rt::string_size(3, &self.language_code);
        }
        if self.max_alternatives != 0 {
            my_size += ::protobuf::rt::value_size(4, self.max_alternatives, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.profanity_filter != false {
            my_size += 2;
        }
        for value in &self.speech_contexts {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        if self.enable_word_time_offsets != false {
            my_size += 2;
        }
        if self.enable_automatic_punctuation != false {
            my_size += 2;
        }
        if let Some(ref v) = self.diarization_config.as_ref() {
            let len = v.compute_size();
            my_size += 2 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if let Some(ref v) = self.metadata.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if !self.model.is_empty() {
            my_size += ::protobuf::rt::string_size(13, &self.model);
        }
        if self.use_enhanced != false {
            my_size += 2;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if self.encoding != RecognitionConfig_AudioEncoding::ENCODING_UNSPECIFIED {
            os.write_enum(1, ::protobuf::ProtobufEnum::value(&self.encoding))?;
        }
        if self.sample_rate_hertz != 0 {
            os.write_int32(2, self.sample_rate_hertz)?;
        }
        if self.audio_channel_count != 0 {
            os.write_int32(7, self.audio_channel_count)?;
        }
        if self.enable_separate_recognition_per_channel != false {
            os.write_bool(12, self.enable_separate_recognition_per_channel)?;
        }
        if !self.language_code.is_empty() {
            os.write_string(3, &self.language_code)?;
        }
        if self.max_alternatives != 0 {
            os.write_int32(4, self.max_alternatives)?;
        }
        if self.profanity_filter != false {
            os.write_bool(5, self.profanity_filter)?;
        }
        for v in &self.speech_contexts {
            os.write_tag(6, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        if self.enable_word_time_offsets != false {
            os.write_bool(8, self.enable_word_time_offsets)?;
        }
        if self.enable_automatic_punctuation != false {
            os.write_bool(11, self.enable_automatic_punctuation)?;
        }
        if let Some(ref v) = self.diarization_config.as_ref() {
            os.write_tag(19, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if let Some(ref v) = self.metadata.as_ref() {
            os.write_tag(9, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if !self.model.is_empty() {
            os.write_string(13, &self.model)?;
        }
        if self.use_enhanced != false {
            os.write_bool(14, self.use_enhanced)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RecognitionConfig {
        RecognitionConfig::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RecognitionConfig_AudioEncoding>>(
                "encoding",
                |m: &RecognitionConfig| { &m.encoding },
                |m: &mut RecognitionConfig| { &mut m.encoding },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "sample_rate_hertz",
                |m: &RecognitionConfig| { &m.sample_rate_hertz },
                |m: &mut RecognitionConfig| { &mut m.sample_rate_hertz },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "audio_channel_count",
                |m: &RecognitionConfig| { &m.audio_channel_count },
                |m: &mut RecognitionConfig| { &mut m.audio_channel_count },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "enable_separate_recognition_per_channel",
                |m: &RecognitionConfig| { &m.enable_separate_recognition_per_channel },
                |m: &mut RecognitionConfig| { &mut m.enable_separate_recognition_per_channel },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "language_code",
                |m: &RecognitionConfig| { &m.language_code },
                |m: &mut RecognitionConfig| { &mut m.language_code },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "max_alternatives",
                |m: &RecognitionConfig| { &m.max_alternatives },
                |m: &mut RecognitionConfig| { &mut m.max_alternatives },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "profanity_filter",
                |m: &RecognitionConfig| { &m.profanity_filter },
                |m: &mut RecognitionConfig| { &mut m.profanity_filter },
            ));
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<SpeechContext>>(
                "speech_contexts",
                |m: &RecognitionConfig| { &m.speech_contexts },
                |m: &mut RecognitionConfig| { &mut m.speech_contexts },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "enable_word_time_offsets",
                |m: &RecognitionConfig| { &m.enable_word_time_offsets },
                |m: &mut RecognitionConfig| { &mut m.enable_word_time_offsets },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "enable_automatic_punctuation",
                |m: &RecognitionConfig| { &m.enable_automatic_punctuation },
                |m: &mut RecognitionConfig| { &mut m.enable_automatic_punctuation },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<SpeakerDiarizationConfig>>(
                "diarization_config",
                |m: &RecognitionConfig| { &m.diarization_config },
                |m: &mut RecognitionConfig| { &mut m.diarization_config },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<RecognitionMetadata>>(
                "metadata",
                |m: &RecognitionConfig| { &m.metadata },
                |m: &mut RecognitionConfig| { &mut m.metadata },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "model",
                |m: &RecognitionConfig| { &m.model },
                |m: &mut RecognitionConfig| { &mut m.model },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "use_enhanced",
                |m: &RecognitionConfig| { &m.use_enhanced },
                |m: &mut RecognitionConfig| { &mut m.use_enhanced },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<RecognitionConfig>(
                "RecognitionConfig",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static RecognitionConfig {
        static instance: ::protobuf::rt::LazyV2<RecognitionConfig> = ::protobuf::rt::LazyV2::INIT;
        instance.get(RecognitionConfig::new)
    }
}

impl ::protobuf::Clear for RecognitionConfig {
    fn clear(&mut self) {
        self.encoding = RecognitionConfig_AudioEncoding::ENCODING_UNSPECIFIED;
        self.sample_rate_hertz = 0;
        self.audio_channel_count = 0;
        self.enable_separate_recognition_per_channel = false;
        self.language_code.clear();
        self.max_alternatives = 0;
        self.profanity_filter = false;
        self.speech_contexts.clear();
        self.enable_word_time_offsets = false;
        self.enable_automatic_punctuation = false;
        self.diarization_config.clear();
        self.metadata.clear();
        self.model.clear();
        self.use_enhanced = false;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RecognitionConfig {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognitionConfig {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RecognitionConfig_AudioEncoding {
    ENCODING_UNSPECIFIED = 0,
    LINEAR16 = 1,
    FLAC = 2,
    MULAW = 3,
    AMR = 4,
    AMR_WB = 5,
    OGG_OPUS = 6,
    SPEEX_WITH_HEADER_BYTE = 7,
}

impl ::protobuf::ProtobufEnum for RecognitionConfig_AudioEncoding {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RecognitionConfig_AudioEncoding> {
        match value {
            0 => ::std::option::Option::Some(RecognitionConfig_AudioEncoding::ENCODING_UNSPECIFIED),
            1 => ::std::option::Option::Some(RecognitionConfig_AudioEncoding::LINEAR16),
            2 => ::std::option::Option::Some(RecognitionConfig_AudioEncoding::FLAC),
            3 => ::std::option::Option::Some(RecognitionConfig_AudioEncoding::MULAW),
            4 => ::std::option::Option::Some(RecognitionConfig_AudioEncoding::AMR),
            5 => ::std::option::Option::Some(RecognitionConfig_AudioEncoding::AMR_WB),
            6 => ::std::option::Option::Some(RecognitionConfig_AudioEncoding::OGG_OPUS),
            7 => ::std::option::Option::Some(RecognitionConfig_AudioEncoding::SPEEX_WITH_HEADER_BYTE),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RecognitionConfig_AudioEncoding] = &[
            RecognitionConfig_AudioEncoding::ENCODING_UNSPECIFIED,
            RecognitionConfig_AudioEncoding::LINEAR16,
            RecognitionConfig_AudioEncoding::FLAC,
            RecognitionConfig_AudioEncoding::MULAW,
            RecognitionConfig_AudioEncoding::AMR,
            RecognitionConfig_AudioEncoding::AMR_WB,
            RecognitionConfig_AudioEncoding::OGG_OPUS,
            RecognitionConfig_AudioEncoding::SPEEX_WITH_HEADER_BYTE,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RecognitionConfig_AudioEncoding>("RecognitionConfig.AudioEncoding", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RecognitionConfig_AudioEncoding {
}

impl ::std::default::Default for RecognitionConfig_AudioEncoding {
    fn default() -> Self {
        RecognitionConfig_AudioEncoding::ENCODING_UNSPECIFIED
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognitionConfig_AudioEncoding {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct SpeakerDiarizationConfig {
    // message fields
    pub enable_speaker_diarization: bool,
    pub min_speaker_count: i32,
    pub max_speaker_count: i32,
    pub speaker_tag: i32,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a SpeakerDiarizationConfig {
    fn default() -> &'a SpeakerDiarizationConfig {
        <SpeakerDiarizationConfig as ::protobuf::Message>::default_instance()
    }
}

impl SpeakerDiarizationConfig {
    pub fn new() -> SpeakerDiarizationConfig {
        ::std::default::Default::default()
    }

    // bool enable_speaker_diarization = 1;


    pub fn get_enable_speaker_diarization(&self) -> bool {
        self.enable_speaker_diarization
    }
    pub fn clear_enable_speaker_diarization(&mut self) {
        self.enable_speaker_diarization = false;
    }

    // Param is passed by value, moved
    pub fn set_enable_speaker_diarization(&mut self, v: bool) {
        self.enable_speaker_diarization = v;
    }

    // int32 min_speaker_count = 2;


    pub fn get_min_speaker_count(&self) -> i32 {
        self.min_speaker_count
    }
    pub fn clear_min_speaker_count(&mut self) {
        self.min_speaker_count = 0;
    }

    // Param is passed by value, moved
    pub fn set_min_speaker_count(&mut self, v: i32) {
        self.min_speaker_count = v;
    }

    // int32 max_speaker_count = 3;


    pub fn get_max_speaker_count(&self) -> i32 {
        self.max_speaker_count
    }
    pub fn clear_max_speaker_count(&mut self) {
        self.max_speaker_count = 0;
    }

    // Param is passed by value, moved
    pub fn set_max_speaker_count(&mut self, v: i32) {
        self.max_speaker_count = v;
    }

    // int32 speaker_tag = 5;


    pub fn get_speaker_tag(&self) -> i32 {
        self.speaker_tag
    }
    pub fn clear_speaker_tag(&mut self) {
        self.speaker_tag = 0;
    }

    // Param is passed by value, moved
    pub fn set_speaker_tag(&mut self, v: i32) {
        self.speaker_tag = v;
    }
}

impl ::protobuf::Message for SpeakerDiarizationConfig {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.enable_speaker_diarization = tmp;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.min_speaker_count = tmp;
                },
                3 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.max_speaker_count = tmp;
                },
                5 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.speaker_tag = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if self.enable_speaker_diarization != false {
            my_size += 2;
        }
        if self.min_speaker_count != 0 {
            my_size += ::protobuf::rt::value_size(2, self.min_speaker_count, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.max_speaker_count != 0 {
            my_size += ::protobuf::rt::value_size(3, self.max_speaker_count, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.speaker_tag != 0 {
            my_size += ::protobuf::rt::value_size(5, self.speaker_tag, ::protobuf::wire_format::WireTypeVarint);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if self.enable_speaker_diarization != false {
            os.write_bool(1, self.enable_speaker_diarization)?;
        }
        if self.min_speaker_count != 0 {
            os.write_int32(2, self.min_speaker_count)?;
        }
        if self.max_speaker_count != 0 {
            os.write_int32(3, self.max_speaker_count)?;
        }
        if self.speaker_tag != 0 {
            os.write_int32(5, self.speaker_tag)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> SpeakerDiarizationConfig {
        SpeakerDiarizationConfig::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "enable_speaker_diarization",
                |m: &SpeakerDiarizationConfig| { &m.enable_speaker_diarization },
                |m: &mut SpeakerDiarizationConfig| { &mut m.enable_speaker_diarization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "min_speaker_count",
                |m: &SpeakerDiarizationConfig| { &m.min_speaker_count },
                |m: &mut SpeakerDiarizationConfig| { &mut m.min_speaker_count },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "max_speaker_count",
                |m: &SpeakerDiarizationConfig| { &m.max_speaker_count },
                |m: &mut SpeakerDiarizationConfig| { &mut m.max_speaker_count },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "speaker_tag",
                |m: &SpeakerDiarizationConfig| { &m.speaker_tag },
                |m: &mut SpeakerDiarizationConfig| { &mut m.speaker_tag },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<SpeakerDiarizationConfig>(
                "SpeakerDiarizationConfig",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static SpeakerDiarizationConfig {
        static instance: ::protobuf::rt::LazyV2<SpeakerDiarizationConfig> = ::protobuf::rt::LazyV2::INIT;
        instance.get(SpeakerDiarizationConfig::new)
    }
}

impl ::protobuf::Clear for SpeakerDiarizationConfig {
    fn clear(&mut self) {
        self.enable_speaker_diarization = false;
        self.min_speaker_count = 0;
        self.max_speaker_count = 0;
        self.speaker_tag = 0;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for SpeakerDiarizationConfig {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for SpeakerDiarizationConfig {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct RecognitionMetadata {
    // message fields
    pub interaction_type: RecognitionMetadata_InteractionType,
    pub industry_naics_code_of_audio: u32,
    pub microphone_distance: RecognitionMetadata_MicrophoneDistance,
    pub original_media_type: RecognitionMetadata_OriginalMediaType,
    pub recording_device_type: RecognitionMetadata_RecordingDeviceType,
    pub recording_device_name: ::std::string::String,
    pub original_mime_type: ::std::string::String,
    pub audio_topic: ::std::string::String,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a RecognitionMetadata {
    fn default() -> &'a RecognitionMetadata {
        <RecognitionMetadata as ::protobuf::Message>::default_instance()
    }
}

impl RecognitionMetadata {
    pub fn new() -> RecognitionMetadata {
        ::std::default::Default::default()
    }

    // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;


    pub fn get_interaction_type(&self) -> RecognitionMetadata_InteractionType {
        self.interaction_type
    }
    pub fn clear_interaction_type(&mut self) {
        self.interaction_type = RecognitionMetadata_InteractionType::INTERACTION_TYPE_UNSPECIFIED;
    }

    // Param is passed by value, moved
    pub fn set_interaction_type(&mut self, v: RecognitionMetadata_InteractionType) {
        self.interaction_type = v;
    }

    // uint32 industry_naics_code_of_audio = 3;


    pub fn get_industry_naics_code_of_audio(&self) -> u32 {
        self.industry_naics_code_of_audio
    }
    pub fn clear_industry_naics_code_of_audio(&mut self) {
        self.industry_naics_code_of_audio = 0;
    }

    // Param is passed by value, moved
    pub fn set_industry_naics_code_of_audio(&mut self, v: u32) {
        self.industry_naics_code_of_audio = v;
    }

    // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;


    pub fn get_microphone_distance(&self) -> RecognitionMetadata_MicrophoneDistance {
        self.microphone_distance
    }
    pub fn clear_microphone_distance(&mut self) {
        self.microphone_distance = RecognitionMetadata_MicrophoneDistance::MICROPHONE_DISTANCE_UNSPECIFIED;
    }

    // Param is passed by value, moved
    pub fn set_microphone_distance(&mut self, v: RecognitionMetadata_MicrophoneDistance) {
        self.microphone_distance = v;
    }

    // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;


    pub fn get_original_media_type(&self) -> RecognitionMetadata_OriginalMediaType {
        self.original_media_type
    }
    pub fn clear_original_media_type(&mut self) {
        self.original_media_type = RecognitionMetadata_OriginalMediaType::ORIGINAL_MEDIA_TYPE_UNSPECIFIED;
    }

    // Param is passed by value, moved
    pub fn set_original_media_type(&mut self, v: RecognitionMetadata_OriginalMediaType) {
        self.original_media_type = v;
    }

    // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;


    pub fn get_recording_device_type(&self) -> RecognitionMetadata_RecordingDeviceType {
        self.recording_device_type
    }
    pub fn clear_recording_device_type(&mut self) {
        self.recording_device_type = RecognitionMetadata_RecordingDeviceType::RECORDING_DEVICE_TYPE_UNSPECIFIED;
    }

    // Param is passed by value, moved
    pub fn set_recording_device_type(&mut self, v: RecognitionMetadata_RecordingDeviceType) {
        self.recording_device_type = v;
    }

    // string recording_device_name = 7;


    pub fn get_recording_device_name(&self) -> &str {
        &self.recording_device_name
    }
    pub fn clear_recording_device_name(&mut self) {
        self.recording_device_name.clear();
    }

    // Param is passed by value, moved
    pub fn set_recording_device_name(&mut self, v: ::std::string::String) {
        self.recording_device_name = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_recording_device_name(&mut self) -> &mut ::std::string::String {
        &mut self.recording_device_name
    }

    // Take field
    pub fn take_recording_device_name(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.recording_device_name, ::std::string::String::new())
    }

    // string original_mime_type = 8;


    pub fn get_original_mime_type(&self) -> &str {
        &self.original_mime_type
    }
    pub fn clear_original_mime_type(&mut self) {
        self.original_mime_type.clear();
    }

    // Param is passed by value, moved
    pub fn set_original_mime_type(&mut self, v: ::std::string::String) {
        self.original_mime_type = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_original_mime_type(&mut self) -> &mut ::std::string::String {
        &mut self.original_mime_type
    }

    // Take field
    pub fn take_original_mime_type(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.original_mime_type, ::std::string::String::new())
    }

    // string audio_topic = 10;


    pub fn get_audio_topic(&self) -> &str {
        &self.audio_topic
    }
    pub fn clear_audio_topic(&mut self) {
        self.audio_topic.clear();
    }

    // Param is passed by value, moved
    pub fn set_audio_topic(&mut self, v: ::std::string::String) {
        self.audio_topic = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_audio_topic(&mut self) -> &mut ::std::string::String {
        &mut self.audio_topic
    }

    // Take field
    pub fn take_audio_topic(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.audio_topic, ::std::string::String::new())
    }
}

impl ::protobuf::Message for RecognitionMetadata {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.interaction_type, 1, &mut self.unknown_fields)?
                },
                3 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_uint32()?;
                    self.industry_naics_code_of_audio = tmp;
                },
                4 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.microphone_distance, 4, &mut self.unknown_fields)?
                },
                5 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.original_media_type, 5, &mut self.unknown_fields)?
                },
                6 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.recording_device_type, 6, &mut self.unknown_fields)?
                },
                7 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.recording_device_name)?;
                },
                8 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.original_mime_type)?;
                },
                10 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.audio_topic)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if self.interaction_type != RecognitionMetadata_InteractionType::INTERACTION_TYPE_UNSPECIFIED {
            my_size += ::protobuf::rt::enum_size(1, self.interaction_type);
        }
        if self.industry_naics_code_of_audio != 0 {
            my_size += ::protobuf::rt::value_size(3, self.industry_naics_code_of_audio, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.microphone_distance != RecognitionMetadata_MicrophoneDistance::MICROPHONE_DISTANCE_UNSPECIFIED {
            my_size += ::protobuf::rt::enum_size(4, self.microphone_distance);
        }
        if self.original_media_type != RecognitionMetadata_OriginalMediaType::ORIGINAL_MEDIA_TYPE_UNSPECIFIED {
            my_size += ::protobuf::rt::enum_size(5, self.original_media_type);
        }
        if self.recording_device_type != RecognitionMetadata_RecordingDeviceType::RECORDING_DEVICE_TYPE_UNSPECIFIED {
            my_size += ::protobuf::rt::enum_size(6, self.recording_device_type);
        }
        if !self.recording_device_name.is_empty() {
            my_size += ::protobuf::rt::string_size(7, &self.recording_device_name);
        }
        if !self.original_mime_type.is_empty() {
            my_size += ::protobuf::rt::string_size(8, &self.original_mime_type);
        }
        if !self.audio_topic.is_empty() {
            my_size += ::protobuf::rt::string_size(10, &self.audio_topic);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if self.interaction_type != RecognitionMetadata_InteractionType::INTERACTION_TYPE_UNSPECIFIED {
            os.write_enum(1, ::protobuf::ProtobufEnum::value(&self.interaction_type))?;
        }
        if self.industry_naics_code_of_audio != 0 {
            os.write_uint32(3, self.industry_naics_code_of_audio)?;
        }
        if self.microphone_distance != RecognitionMetadata_MicrophoneDistance::MICROPHONE_DISTANCE_UNSPECIFIED {
            os.write_enum(4, ::protobuf::ProtobufEnum::value(&self.microphone_distance))?;
        }
        if self.original_media_type != RecognitionMetadata_OriginalMediaType::ORIGINAL_MEDIA_TYPE_UNSPECIFIED {
            os.write_enum(5, ::protobuf::ProtobufEnum::value(&self.original_media_type))?;
        }
        if self.recording_device_type != RecognitionMetadata_RecordingDeviceType::RECORDING_DEVICE_TYPE_UNSPECIFIED {
            os.write_enum(6, ::protobuf::ProtobufEnum::value(&self.recording_device_type))?;
        }
        if !self.recording_device_name.is_empty() {
            os.write_string(7, &self.recording_device_name)?;
        }
        if !self.original_mime_type.is_empty() {
            os.write_string(8, &self.original_mime_type)?;
        }
        if !self.audio_topic.is_empty() {
            os.write_string(10, &self.audio_topic)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RecognitionMetadata {
        RecognitionMetadata::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RecognitionMetadata_InteractionType>>(
                "interaction_type",
                |m: &RecognitionMetadata| { &m.interaction_type },
                |m: &mut RecognitionMetadata| { &mut m.interaction_type },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeUint32>(
                "industry_naics_code_of_audio",
                |m: &RecognitionMetadata| { &m.industry_naics_code_of_audio },
                |m: &mut RecognitionMetadata| { &mut m.industry_naics_code_of_audio },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RecognitionMetadata_MicrophoneDistance>>(
                "microphone_distance",
                |m: &RecognitionMetadata| { &m.microphone_distance },
                |m: &mut RecognitionMetadata| { &mut m.microphone_distance },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RecognitionMetadata_OriginalMediaType>>(
                "original_media_type",
                |m: &RecognitionMetadata| { &m.original_media_type },
                |m: &mut RecognitionMetadata| { &mut m.original_media_type },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RecognitionMetadata_RecordingDeviceType>>(
                "recording_device_type",
                |m: &RecognitionMetadata| { &m.recording_device_type },
                |m: &mut RecognitionMetadata| { &mut m.recording_device_type },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "recording_device_name",
                |m: &RecognitionMetadata| { &m.recording_device_name },
                |m: &mut RecognitionMetadata| { &mut m.recording_device_name },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "original_mime_type",
                |m: &RecognitionMetadata| { &m.original_mime_type },
                |m: &mut RecognitionMetadata| { &mut m.original_mime_type },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "audio_topic",
                |m: &RecognitionMetadata| { &m.audio_topic },
                |m: &mut RecognitionMetadata| { &mut m.audio_topic },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<RecognitionMetadata>(
                "RecognitionMetadata",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static RecognitionMetadata {
        static instance: ::protobuf::rt::LazyV2<RecognitionMetadata> = ::protobuf::rt::LazyV2::INIT;
        instance.get(RecognitionMetadata::new)
    }
}

impl ::protobuf::Clear for RecognitionMetadata {
    fn clear(&mut self) {
        self.interaction_type = RecognitionMetadata_InteractionType::INTERACTION_TYPE_UNSPECIFIED;
        self.industry_naics_code_of_audio = 0;
        self.microphone_distance = RecognitionMetadata_MicrophoneDistance::MICROPHONE_DISTANCE_UNSPECIFIED;
        self.original_media_type = RecognitionMetadata_OriginalMediaType::ORIGINAL_MEDIA_TYPE_UNSPECIFIED;
        self.recording_device_type = RecognitionMetadata_RecordingDeviceType::RECORDING_DEVICE_TYPE_UNSPECIFIED;
        self.recording_device_name.clear();
        self.original_mime_type.clear();
        self.audio_topic.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RecognitionMetadata {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognitionMetadata {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RecognitionMetadata_InteractionType {
    INTERACTION_TYPE_UNSPECIFIED = 0,
    DISCUSSION = 1,
    PRESENTATION = 2,
    PHONE_CALL = 3,
    VOICEMAIL = 4,
    PROFESSIONALLY_PRODUCED = 5,
    VOICE_SEARCH = 6,
    VOICE_COMMAND = 7,
    DICTATION = 8,
}

impl ::protobuf::ProtobufEnum for RecognitionMetadata_InteractionType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RecognitionMetadata_InteractionType> {
        match value {
            0 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::INTERACTION_TYPE_UNSPECIFIED),
            1 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::DISCUSSION),
            2 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::PRESENTATION),
            3 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::PHONE_CALL),
            4 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::VOICEMAIL),
            5 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::PROFESSIONALLY_PRODUCED),
            6 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::VOICE_SEARCH),
            7 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::VOICE_COMMAND),
            8 => ::std::option::Option::Some(RecognitionMetadata_InteractionType::DICTATION),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RecognitionMetadata_InteractionType] = &[
            RecognitionMetadata_InteractionType::INTERACTION_TYPE_UNSPECIFIED,
            RecognitionMetadata_InteractionType::DISCUSSION,
            RecognitionMetadata_InteractionType::PRESENTATION,
            RecognitionMetadata_InteractionType::PHONE_CALL,
            RecognitionMetadata_InteractionType::VOICEMAIL,
            RecognitionMetadata_InteractionType::PROFESSIONALLY_PRODUCED,
            RecognitionMetadata_InteractionType::VOICE_SEARCH,
            RecognitionMetadata_InteractionType::VOICE_COMMAND,
            RecognitionMetadata_InteractionType::DICTATION,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RecognitionMetadata_InteractionType>("RecognitionMetadata.InteractionType", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RecognitionMetadata_InteractionType {
}

impl ::std::default::Default for RecognitionMetadata_InteractionType {
    fn default() -> Self {
        RecognitionMetadata_InteractionType::INTERACTION_TYPE_UNSPECIFIED
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognitionMetadata_InteractionType {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RecognitionMetadata_MicrophoneDistance {
    MICROPHONE_DISTANCE_UNSPECIFIED = 0,
    NEARFIELD = 1,
    MIDFIELD = 2,
    FARFIELD = 3,
}

impl ::protobuf::ProtobufEnum for RecognitionMetadata_MicrophoneDistance {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RecognitionMetadata_MicrophoneDistance> {
        match value {
            0 => ::std::option::Option::Some(RecognitionMetadata_MicrophoneDistance::MICROPHONE_DISTANCE_UNSPECIFIED),
            1 => ::std::option::Option::Some(RecognitionMetadata_MicrophoneDistance::NEARFIELD),
            2 => ::std::option::Option::Some(RecognitionMetadata_MicrophoneDistance::MIDFIELD),
            3 => ::std::option::Option::Some(RecognitionMetadata_MicrophoneDistance::FARFIELD),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RecognitionMetadata_MicrophoneDistance] = &[
            RecognitionMetadata_MicrophoneDistance::MICROPHONE_DISTANCE_UNSPECIFIED,
            RecognitionMetadata_MicrophoneDistance::NEARFIELD,
            RecognitionMetadata_MicrophoneDistance::MIDFIELD,
            RecognitionMetadata_MicrophoneDistance::FARFIELD,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RecognitionMetadata_MicrophoneDistance>("RecognitionMetadata.MicrophoneDistance", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RecognitionMetadata_MicrophoneDistance {
}

impl ::std::default::Default for RecognitionMetadata_MicrophoneDistance {
    fn default() -> Self {
        RecognitionMetadata_MicrophoneDistance::MICROPHONE_DISTANCE_UNSPECIFIED
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognitionMetadata_MicrophoneDistance {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RecognitionMetadata_OriginalMediaType {
    ORIGINAL_MEDIA_TYPE_UNSPECIFIED = 0,
    AUDIO = 1,
    VIDEO = 2,
}

impl ::protobuf::ProtobufEnum for RecognitionMetadata_OriginalMediaType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RecognitionMetadata_OriginalMediaType> {
        match value {
            0 => ::std::option::Option::Some(RecognitionMetadata_OriginalMediaType::ORIGINAL_MEDIA_TYPE_UNSPECIFIED),
            1 => ::std::option::Option::Some(RecognitionMetadata_OriginalMediaType::AUDIO),
            2 => ::std::option::Option::Some(RecognitionMetadata_OriginalMediaType::VIDEO),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RecognitionMetadata_OriginalMediaType] = &[
            RecognitionMetadata_OriginalMediaType::ORIGINAL_MEDIA_TYPE_UNSPECIFIED,
            RecognitionMetadata_OriginalMediaType::AUDIO,
            RecognitionMetadata_OriginalMediaType::VIDEO,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RecognitionMetadata_OriginalMediaType>("RecognitionMetadata.OriginalMediaType", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RecognitionMetadata_OriginalMediaType {
}

impl ::std::default::Default for RecognitionMetadata_OriginalMediaType {
    fn default() -> Self {
        RecognitionMetadata_OriginalMediaType::ORIGINAL_MEDIA_TYPE_UNSPECIFIED
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognitionMetadata_OriginalMediaType {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RecognitionMetadata_RecordingDeviceType {
    RECORDING_DEVICE_TYPE_UNSPECIFIED = 0,
    SMARTPHONE = 1,
    PC = 2,
    PHONE_LINE = 3,
    VEHICLE = 4,
    OTHER_OUTDOOR_DEVICE = 5,
    OTHER_INDOOR_DEVICE = 6,
}

impl ::protobuf::ProtobufEnum for RecognitionMetadata_RecordingDeviceType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RecognitionMetadata_RecordingDeviceType> {
        match value {
            0 => ::std::option::Option::Some(RecognitionMetadata_RecordingDeviceType::RECORDING_DEVICE_TYPE_UNSPECIFIED),
            1 => ::std::option::Option::Some(RecognitionMetadata_RecordingDeviceType::SMARTPHONE),
            2 => ::std::option::Option::Some(RecognitionMetadata_RecordingDeviceType::PC),
            3 => ::std::option::Option::Some(RecognitionMetadata_RecordingDeviceType::PHONE_LINE),
            4 => ::std::option::Option::Some(RecognitionMetadata_RecordingDeviceType::VEHICLE),
            5 => ::std::option::Option::Some(RecognitionMetadata_RecordingDeviceType::OTHER_OUTDOOR_DEVICE),
            6 => ::std::option::Option::Some(RecognitionMetadata_RecordingDeviceType::OTHER_INDOOR_DEVICE),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RecognitionMetadata_RecordingDeviceType] = &[
            RecognitionMetadata_RecordingDeviceType::RECORDING_DEVICE_TYPE_UNSPECIFIED,
            RecognitionMetadata_RecordingDeviceType::SMARTPHONE,
            RecognitionMetadata_RecordingDeviceType::PC,
            RecognitionMetadata_RecordingDeviceType::PHONE_LINE,
            RecognitionMetadata_RecordingDeviceType::VEHICLE,
            RecognitionMetadata_RecordingDeviceType::OTHER_OUTDOOR_DEVICE,
            RecognitionMetadata_RecordingDeviceType::OTHER_INDOOR_DEVICE,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RecognitionMetadata_RecordingDeviceType>("RecognitionMetadata.RecordingDeviceType", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RecognitionMetadata_RecordingDeviceType {
}

impl ::std::default::Default for RecognitionMetadata_RecordingDeviceType {
    fn default() -> Self {
        RecognitionMetadata_RecordingDeviceType::RECORDING_DEVICE_TYPE_UNSPECIFIED
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognitionMetadata_RecordingDeviceType {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct SpeechContext {
    // message fields
    pub phrases: ::protobuf::RepeatedField<::std::string::String>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a SpeechContext {
    fn default() -> &'a SpeechContext {
        <SpeechContext as ::protobuf::Message>::default_instance()
    }
}

impl SpeechContext {
    pub fn new() -> SpeechContext {
        ::std::default::Default::default()
    }

    // repeated string phrases = 1;


    pub fn get_phrases(&self) -> &[::std::string::String] {
        &self.phrases
    }
    pub fn clear_phrases(&mut self) {
        self.phrases.clear();
    }

    // Param is passed by value, moved
    pub fn set_phrases(&mut self, v: ::protobuf::RepeatedField<::std::string::String>) {
        self.phrases = v;
    }

    // Mutable pointer to the field.
    pub fn mut_phrases(&mut self) -> &mut ::protobuf::RepeatedField<::std::string::String> {
        &mut self.phrases
    }

    // Take field
    pub fn take_phrases(&mut self) -> ::protobuf::RepeatedField<::std::string::String> {
        ::std::mem::replace(&mut self.phrases, ::protobuf::RepeatedField::new())
    }
}

impl ::protobuf::Message for SpeechContext {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_repeated_string_into(wire_type, is, &mut self.phrases)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.phrases {
            my_size += ::protobuf::rt::string_size(1, &value);
        };
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        for v in &self.phrases {
            os.write_string(1, &v)?;
        };
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> SpeechContext {
        SpeechContext::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "phrases",
                |m: &SpeechContext| { &m.phrases },
                |m: &mut SpeechContext| { &mut m.phrases },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<SpeechContext>(
                "SpeechContext",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static SpeechContext {
        static instance: ::protobuf::rt::LazyV2<SpeechContext> = ::protobuf::rt::LazyV2::INIT;
        instance.get(SpeechContext::new)
    }
}

impl ::protobuf::Clear for SpeechContext {
    fn clear(&mut self) {
        self.phrases.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for SpeechContext {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for SpeechContext {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct RecognitionAudio {
    // message oneof groups
    pub audio_source: ::std::option::Option<RecognitionAudio_oneof_audio_source>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a RecognitionAudio {
    fn default() -> &'a RecognitionAudio {
        <RecognitionAudio as ::protobuf::Message>::default_instance()
    }
}

#[derive(Clone,PartialEq,Debug)]
pub enum RecognitionAudio_oneof_audio_source {
    content(::std::vec::Vec<u8>),
    uri(::std::string::String),
}

impl RecognitionAudio {
    pub fn new() -> RecognitionAudio {
        ::std::default::Default::default()
    }

    // bytes content = 1;


    pub fn get_content(&self) -> &[u8] {
        match self.audio_source {
            ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::content(ref v)) => v,
            _ => &[],
        }
    }
    pub fn clear_content(&mut self) {
        self.audio_source = ::std::option::Option::None;
    }

    pub fn has_content(&self) -> bool {
        match self.audio_source {
            ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::content(..)) => true,
            _ => false,
        }
    }

    // Param is passed by value, moved
    pub fn set_content(&mut self, v: ::std::vec::Vec<u8>) {
        self.audio_source = ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::content(v))
    }

    // Mutable pointer to the field.
    pub fn mut_content(&mut self) -> &mut ::std::vec::Vec<u8> {
        if let ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::content(_)) = self.audio_source {
        } else {
            self.audio_source = ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::content(::std::vec::Vec::new()));
        }
        match self.audio_source {
            ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::content(ref mut v)) => v,
            _ => panic!(),
        }
    }

    // Take field
    pub fn take_content(&mut self) -> ::std::vec::Vec<u8> {
        if self.has_content() {
            match self.audio_source.take() {
                ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::content(v)) => v,
                _ => panic!(),
            }
        } else {
            ::std::vec::Vec::new()
        }
    }

    // string uri = 2;


    pub fn get_uri(&self) -> &str {
        match self.audio_source {
            ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::uri(ref v)) => v,
            _ => "",
        }
    }
    pub fn clear_uri(&mut self) {
        self.audio_source = ::std::option::Option::None;
    }

    pub fn has_uri(&self) -> bool {
        match self.audio_source {
            ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::uri(..)) => true,
            _ => false,
        }
    }

    // Param is passed by value, moved
    pub fn set_uri(&mut self, v: ::std::string::String) {
        self.audio_source = ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::uri(v))
    }

    // Mutable pointer to the field.
    pub fn mut_uri(&mut self) -> &mut ::std::string::String {
        if let ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::uri(_)) = self.audio_source {
        } else {
            self.audio_source = ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::uri(::std::string::String::new()));
        }
        match self.audio_source {
            ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::uri(ref mut v)) => v,
            _ => panic!(),
        }
    }

    // Take field
    pub fn take_uri(&mut self) -> ::std::string::String {
        if self.has_uri() {
            match self.audio_source.take() {
                ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::uri(v)) => v,
                _ => panic!(),
            }
        } else {
            ::std::string::String::new()
        }
    }
}

impl ::protobuf::Message for RecognitionAudio {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    if wire_type != ::protobuf::wire_format::WireTypeLengthDelimited {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    self.audio_source = ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::content(is.read_bytes()?));
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeLengthDelimited {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    self.audio_source = ::std::option::Option::Some(RecognitionAudio_oneof_audio_source::uri(is.read_string()?));
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if let ::std::option::Option::Some(ref v) = self.audio_source {
            match v {
                &RecognitionAudio_oneof_audio_source::content(ref v) => {
                    my_size += ::protobuf::rt::bytes_size(1, &v);
                },
                &RecognitionAudio_oneof_audio_source::uri(ref v) => {
                    my_size += ::protobuf::rt::string_size(2, &v);
                },
            };
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if let ::std::option::Option::Some(ref v) = self.audio_source {
            match v {
                &RecognitionAudio_oneof_audio_source::content(ref v) => {
                    os.write_bytes(1, v)?;
                },
                &RecognitionAudio_oneof_audio_source::uri(ref v) => {
                    os.write_string(2, v)?;
                },
            };
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RecognitionAudio {
        RecognitionAudio::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_singular_bytes_accessor::<_>(
                "content",
                RecognitionAudio::has_content,
                RecognitionAudio::get_content,
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_string_accessor::<_>(
                "uri",
                RecognitionAudio::has_uri,
                RecognitionAudio::get_uri,
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<RecognitionAudio>(
                "RecognitionAudio",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static RecognitionAudio {
        static instance: ::protobuf::rt::LazyV2<RecognitionAudio> = ::protobuf::rt::LazyV2::INIT;
        instance.get(RecognitionAudio::new)
    }
}

impl ::protobuf::Clear for RecognitionAudio {
    fn clear(&mut self) {
        self.audio_source = ::std::option::Option::None;
        self.audio_source = ::std::option::Option::None;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RecognitionAudio {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognitionAudio {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct RecognizeResponse {
    // message fields
    pub results: ::protobuf::RepeatedField<SpeechRecognitionResult>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a RecognizeResponse {
    fn default() -> &'a RecognizeResponse {
        <RecognizeResponse as ::protobuf::Message>::default_instance()
    }
}

impl RecognizeResponse {
    pub fn new() -> RecognizeResponse {
        ::std::default::Default::default()
    }

    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;


    pub fn get_results(&self) -> &[SpeechRecognitionResult] {
        &self.results
    }
    pub fn clear_results(&mut self) {
        self.results.clear();
    }

    // Param is passed by value, moved
    pub fn set_results(&mut self, v: ::protobuf::RepeatedField<SpeechRecognitionResult>) {
        self.results = v;
    }

    // Mutable pointer to the field.
    pub fn mut_results(&mut self) -> &mut ::protobuf::RepeatedField<SpeechRecognitionResult> {
        &mut self.results
    }

    // Take field
    pub fn take_results(&mut self) -> ::protobuf::RepeatedField<SpeechRecognitionResult> {
        ::std::mem::replace(&mut self.results, ::protobuf::RepeatedField::new())
    }
}

impl ::protobuf::Message for RecognizeResponse {
    fn is_initialized(&self) -> bool {
        for v in &self.results {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                2 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.results)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.results {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        for v in &self.results {
            os.write_tag(2, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RecognizeResponse {
        RecognizeResponse::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<SpeechRecognitionResult>>(
                "results",
                |m: &RecognizeResponse| { &m.results },
                |m: &mut RecognizeResponse| { &mut m.results },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<RecognizeResponse>(
                "RecognizeResponse",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static RecognizeResponse {
        static instance: ::protobuf::rt::LazyV2<RecognizeResponse> = ::protobuf::rt::LazyV2::INIT;
        instance.get(RecognizeResponse::new)
    }
}

impl ::protobuf::Clear for RecognizeResponse {
    fn clear(&mut self) {
        self.results.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RecognizeResponse {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RecognizeResponse {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct LongRunningRecognizeResponse {
    // message fields
    pub results: ::protobuf::RepeatedField<SpeechRecognitionResult>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a LongRunningRecognizeResponse {
    fn default() -> &'a LongRunningRecognizeResponse {
        <LongRunningRecognizeResponse as ::protobuf::Message>::default_instance()
    }
}

impl LongRunningRecognizeResponse {
    pub fn new() -> LongRunningRecognizeResponse {
        ::std::default::Default::default()
    }

    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;


    pub fn get_results(&self) -> &[SpeechRecognitionResult] {
        &self.results
    }
    pub fn clear_results(&mut self) {
        self.results.clear();
    }

    // Param is passed by value, moved
    pub fn set_results(&mut self, v: ::protobuf::RepeatedField<SpeechRecognitionResult>) {
        self.results = v;
    }

    // Mutable pointer to the field.
    pub fn mut_results(&mut self) -> &mut ::protobuf::RepeatedField<SpeechRecognitionResult> {
        &mut self.results
    }

    // Take field
    pub fn take_results(&mut self) -> ::protobuf::RepeatedField<SpeechRecognitionResult> {
        ::std::mem::replace(&mut self.results, ::protobuf::RepeatedField::new())
    }
}

impl ::protobuf::Message for LongRunningRecognizeResponse {
    fn is_initialized(&self) -> bool {
        for v in &self.results {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                2 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.results)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.results {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        for v in &self.results {
            os.write_tag(2, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> LongRunningRecognizeResponse {
        LongRunningRecognizeResponse::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<SpeechRecognitionResult>>(
                "results",
                |m: &LongRunningRecognizeResponse| { &m.results },
                |m: &mut LongRunningRecognizeResponse| { &mut m.results },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<LongRunningRecognizeResponse>(
                "LongRunningRecognizeResponse",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static LongRunningRecognizeResponse {
        static instance: ::protobuf::rt::LazyV2<LongRunningRecognizeResponse> = ::protobuf::rt::LazyV2::INIT;
        instance.get(LongRunningRecognizeResponse::new)
    }
}

impl ::protobuf::Clear for LongRunningRecognizeResponse {
    fn clear(&mut self) {
        self.results.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for LongRunningRecognizeResponse {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for LongRunningRecognizeResponse {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct LongRunningRecognizeMetadata {
    // message fields
    pub progress_percent: i32,
    pub start_time: ::protobuf::SingularPtrField<::protobuf::well_known_types::Timestamp>,
    pub last_update_time: ::protobuf::SingularPtrField<::protobuf::well_known_types::Timestamp>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a LongRunningRecognizeMetadata {
    fn default() -> &'a LongRunningRecognizeMetadata {
        <LongRunningRecognizeMetadata as ::protobuf::Message>::default_instance()
    }
}

impl LongRunningRecognizeMetadata {
    pub fn new() -> LongRunningRecognizeMetadata {
        ::std::default::Default::default()
    }

    // int32 progress_percent = 1;


    pub fn get_progress_percent(&self) -> i32 {
        self.progress_percent
    }
    pub fn clear_progress_percent(&mut self) {
        self.progress_percent = 0;
    }

    // Param is passed by value, moved
    pub fn set_progress_percent(&mut self, v: i32) {
        self.progress_percent = v;
    }

    // .google.protobuf.Timestamp start_time = 2;


    pub fn get_start_time(&self) -> &::protobuf::well_known_types::Timestamp {
        self.start_time.as_ref().unwrap_or_else(|| <::protobuf::well_known_types::Timestamp as ::protobuf::Message>::default_instance())
    }
    pub fn clear_start_time(&mut self) {
        self.start_time.clear();
    }

    pub fn has_start_time(&self) -> bool {
        self.start_time.is_some()
    }

    // Param is passed by value, moved
    pub fn set_start_time(&mut self, v: ::protobuf::well_known_types::Timestamp) {
        self.start_time = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_start_time(&mut self) -> &mut ::protobuf::well_known_types::Timestamp {
        if self.start_time.is_none() {
            self.start_time.set_default();
        }
        self.start_time.as_mut().unwrap()
    }

    // Take field
    pub fn take_start_time(&mut self) -> ::protobuf::well_known_types::Timestamp {
        self.start_time.take().unwrap_or_else(|| ::protobuf::well_known_types::Timestamp::new())
    }

    // .google.protobuf.Timestamp last_update_time = 3;


    pub fn get_last_update_time(&self) -> &::protobuf::well_known_types::Timestamp {
        self.last_update_time.as_ref().unwrap_or_else(|| <::protobuf::well_known_types::Timestamp as ::protobuf::Message>::default_instance())
    }
    pub fn clear_last_update_time(&mut self) {
        self.last_update_time.clear();
    }

    pub fn has_last_update_time(&self) -> bool {
        self.last_update_time.is_some()
    }

    // Param is passed by value, moved
    pub fn set_last_update_time(&mut self, v: ::protobuf::well_known_types::Timestamp) {
        self.last_update_time = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_last_update_time(&mut self) -> &mut ::protobuf::well_known_types::Timestamp {
        if self.last_update_time.is_none() {
            self.last_update_time.set_default();
        }
        self.last_update_time.as_mut().unwrap()
    }

    // Take field
    pub fn take_last_update_time(&mut self) -> ::protobuf::well_known_types::Timestamp {
        self.last_update_time.take().unwrap_or_else(|| ::protobuf::well_known_types::Timestamp::new())
    }
}

impl ::protobuf::Message for LongRunningRecognizeMetadata {
    fn is_initialized(&self) -> bool {
        for v in &self.start_time {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.last_update_time {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.progress_percent = tmp;
                },
                2 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.start_time)?;
                },
                3 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.last_update_time)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if self.progress_percent != 0 {
            my_size += ::protobuf::rt::value_size(1, self.progress_percent, ::protobuf::wire_format::WireTypeVarint);
        }
        if let Some(ref v) = self.start_time.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if let Some(ref v) = self.last_update_time.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if self.progress_percent != 0 {
            os.write_int32(1, self.progress_percent)?;
        }
        if let Some(ref v) = self.start_time.as_ref() {
            os.write_tag(2, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if let Some(ref v) = self.last_update_time.as_ref() {
            os.write_tag(3, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> LongRunningRecognizeMetadata {
        LongRunningRecognizeMetadata::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "progress_percent",
                |m: &LongRunningRecognizeMetadata| { &m.progress_percent },
                |m: &mut LongRunningRecognizeMetadata| { &mut m.progress_percent },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<::protobuf::well_known_types::Timestamp>>(
                "start_time",
                |m: &LongRunningRecognizeMetadata| { &m.start_time },
                |m: &mut LongRunningRecognizeMetadata| { &mut m.start_time },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<::protobuf::well_known_types::Timestamp>>(
                "last_update_time",
                |m: &LongRunningRecognizeMetadata| { &m.last_update_time },
                |m: &mut LongRunningRecognizeMetadata| { &mut m.last_update_time },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<LongRunningRecognizeMetadata>(
                "LongRunningRecognizeMetadata",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static LongRunningRecognizeMetadata {
        static instance: ::protobuf::rt::LazyV2<LongRunningRecognizeMetadata> = ::protobuf::rt::LazyV2::INIT;
        instance.get(LongRunningRecognizeMetadata::new)
    }
}

impl ::protobuf::Clear for LongRunningRecognizeMetadata {
    fn clear(&mut self) {
        self.progress_percent = 0;
        self.start_time.clear();
        self.last_update_time.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for LongRunningRecognizeMetadata {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for LongRunningRecognizeMetadata {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct StreamingRecognizeResponse {
    // message fields
    pub error: ::protobuf::SingularPtrField<super::status::Status>,
    pub results: ::protobuf::RepeatedField<StreamingRecognitionResult>,
    pub speech_event_type: StreamingRecognizeResponse_SpeechEventType,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a StreamingRecognizeResponse {
    fn default() -> &'a StreamingRecognizeResponse {
        <StreamingRecognizeResponse as ::protobuf::Message>::default_instance()
    }
}

impl StreamingRecognizeResponse {
    pub fn new() -> StreamingRecognizeResponse {
        ::std::default::Default::default()
    }

    // .google.rpc.Status error = 1;


    pub fn get_error(&self) -> &super::status::Status {
        self.error.as_ref().unwrap_or_else(|| <super::status::Status as ::protobuf::Message>::default_instance())
    }
    pub fn clear_error(&mut self) {
        self.error.clear();
    }

    pub fn has_error(&self) -> bool {
        self.error.is_some()
    }

    // Param is passed by value, moved
    pub fn set_error(&mut self, v: super::status::Status) {
        self.error = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_error(&mut self) -> &mut super::status::Status {
        if self.error.is_none() {
            self.error.set_default();
        }
        self.error.as_mut().unwrap()
    }

    // Take field
    pub fn take_error(&mut self) -> super::status::Status {
        self.error.take().unwrap_or_else(|| super::status::Status::new())
    }

    // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;


    pub fn get_results(&self) -> &[StreamingRecognitionResult] {
        &self.results
    }
    pub fn clear_results(&mut self) {
        self.results.clear();
    }

    // Param is passed by value, moved
    pub fn set_results(&mut self, v: ::protobuf::RepeatedField<StreamingRecognitionResult>) {
        self.results = v;
    }

    // Mutable pointer to the field.
    pub fn mut_results(&mut self) -> &mut ::protobuf::RepeatedField<StreamingRecognitionResult> {
        &mut self.results
    }

    // Take field
    pub fn take_results(&mut self) -> ::protobuf::RepeatedField<StreamingRecognitionResult> {
        ::std::mem::replace(&mut self.results, ::protobuf::RepeatedField::new())
    }

    // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;


    pub fn get_speech_event_type(&self) -> StreamingRecognizeResponse_SpeechEventType {
        self.speech_event_type
    }
    pub fn clear_speech_event_type(&mut self) {
        self.speech_event_type = StreamingRecognizeResponse_SpeechEventType::SPEECH_EVENT_UNSPECIFIED;
    }

    // Param is passed by value, moved
    pub fn set_speech_event_type(&mut self, v: StreamingRecognizeResponse_SpeechEventType) {
        self.speech_event_type = v;
    }
}

impl ::protobuf::Message for StreamingRecognizeResponse {
    fn is_initialized(&self) -> bool {
        for v in &self.error {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.results {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.error)?;
                },
                2 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.results)?;
                },
                4 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.speech_event_type, 4, &mut self.unknown_fields)?
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if let Some(ref v) = self.error.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        for value in &self.results {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        if self.speech_event_type != StreamingRecognizeResponse_SpeechEventType::SPEECH_EVENT_UNSPECIFIED {
            my_size += ::protobuf::rt::enum_size(4, self.speech_event_type);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if let Some(ref v) = self.error.as_ref() {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        for v in &self.results {
            os.write_tag(2, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        if self.speech_event_type != StreamingRecognizeResponse_SpeechEventType::SPEECH_EVENT_UNSPECIFIED {
            os.write_enum(4, ::protobuf::ProtobufEnum::value(&self.speech_event_type))?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> StreamingRecognizeResponse {
        StreamingRecognizeResponse::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<super::status::Status>>(
                "error",
                |m: &StreamingRecognizeResponse| { &m.error },
                |m: &mut StreamingRecognizeResponse| { &mut m.error },
            ));
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<StreamingRecognitionResult>>(
                "results",
                |m: &StreamingRecognizeResponse| { &m.results },
                |m: &mut StreamingRecognizeResponse| { &mut m.results },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<StreamingRecognizeResponse_SpeechEventType>>(
                "speech_event_type",
                |m: &StreamingRecognizeResponse| { &m.speech_event_type },
                |m: &mut StreamingRecognizeResponse| { &mut m.speech_event_type },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<StreamingRecognizeResponse>(
                "StreamingRecognizeResponse",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static StreamingRecognizeResponse {
        static instance: ::protobuf::rt::LazyV2<StreamingRecognizeResponse> = ::protobuf::rt::LazyV2::INIT;
        instance.get(StreamingRecognizeResponse::new)
    }
}

impl ::protobuf::Clear for StreamingRecognizeResponse {
    fn clear(&mut self) {
        self.error.clear();
        self.results.clear();
        self.speech_event_type = StreamingRecognizeResponse_SpeechEventType::SPEECH_EVENT_UNSPECIFIED;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for StreamingRecognizeResponse {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for StreamingRecognizeResponse {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum StreamingRecognizeResponse_SpeechEventType {
    SPEECH_EVENT_UNSPECIFIED = 0,
    END_OF_SINGLE_UTTERANCE = 1,
}

impl ::protobuf::ProtobufEnum for StreamingRecognizeResponse_SpeechEventType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<StreamingRecognizeResponse_SpeechEventType> {
        match value {
            0 => ::std::option::Option::Some(StreamingRecognizeResponse_SpeechEventType::SPEECH_EVENT_UNSPECIFIED),
            1 => ::std::option::Option::Some(StreamingRecognizeResponse_SpeechEventType::END_OF_SINGLE_UTTERANCE),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [StreamingRecognizeResponse_SpeechEventType] = &[
            StreamingRecognizeResponse_SpeechEventType::SPEECH_EVENT_UNSPECIFIED,
            StreamingRecognizeResponse_SpeechEventType::END_OF_SINGLE_UTTERANCE,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<StreamingRecognizeResponse_SpeechEventType>("StreamingRecognizeResponse.SpeechEventType", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for StreamingRecognizeResponse_SpeechEventType {
}

impl ::std::default::Default for StreamingRecognizeResponse_SpeechEventType {
    fn default() -> Self {
        StreamingRecognizeResponse_SpeechEventType::SPEECH_EVENT_UNSPECIFIED
    }
}

impl ::protobuf::reflect::ProtobufValue for StreamingRecognizeResponse_SpeechEventType {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct StreamingRecognitionResult {
    // message fields
    pub alternatives: ::protobuf::RepeatedField<SpeechRecognitionAlternative>,
    pub is_final: bool,
    pub stability: f32,
    pub result_end_time: ::protobuf::SingularPtrField<::protobuf::well_known_types::Duration>,
    pub channel_tag: i32,
    pub language_code: ::std::string::String,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a StreamingRecognitionResult {
    fn default() -> &'a StreamingRecognitionResult {
        <StreamingRecognitionResult as ::protobuf::Message>::default_instance()
    }
}

impl StreamingRecognitionResult {
    pub fn new() -> StreamingRecognitionResult {
        ::std::default::Default::default()
    }

    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;


    pub fn get_alternatives(&self) -> &[SpeechRecognitionAlternative] {
        &self.alternatives
    }
    pub fn clear_alternatives(&mut self) {
        self.alternatives.clear();
    }

    // Param is passed by value, moved
    pub fn set_alternatives(&mut self, v: ::protobuf::RepeatedField<SpeechRecognitionAlternative>) {
        self.alternatives = v;
    }

    // Mutable pointer to the field.
    pub fn mut_alternatives(&mut self) -> &mut ::protobuf::RepeatedField<SpeechRecognitionAlternative> {
        &mut self.alternatives
    }

    // Take field
    pub fn take_alternatives(&mut self) -> ::protobuf::RepeatedField<SpeechRecognitionAlternative> {
        ::std::mem::replace(&mut self.alternatives, ::protobuf::RepeatedField::new())
    }

    // bool is_final = 2;


    pub fn get_is_final(&self) -> bool {
        self.is_final
    }
    pub fn clear_is_final(&mut self) {
        self.is_final = false;
    }

    // Param is passed by value, moved
    pub fn set_is_final(&mut self, v: bool) {
        self.is_final = v;
    }

    // float stability = 3;


    pub fn get_stability(&self) -> f32 {
        self.stability
    }
    pub fn clear_stability(&mut self) {
        self.stability = 0.;
    }

    // Param is passed by value, moved
    pub fn set_stability(&mut self, v: f32) {
        self.stability = v;
    }

    // .google.protobuf.Duration result_end_time = 4;


    pub fn get_result_end_time(&self) -> &::protobuf::well_known_types::Duration {
        self.result_end_time.as_ref().unwrap_or_else(|| <::protobuf::well_known_types::Duration as ::protobuf::Message>::default_instance())
    }
    pub fn clear_result_end_time(&mut self) {
        self.result_end_time.clear();
    }

    pub fn has_result_end_time(&self) -> bool {
        self.result_end_time.is_some()
    }

    // Param is passed by value, moved
    pub fn set_result_end_time(&mut self, v: ::protobuf::well_known_types::Duration) {
        self.result_end_time = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_result_end_time(&mut self) -> &mut ::protobuf::well_known_types::Duration {
        if self.result_end_time.is_none() {
            self.result_end_time.set_default();
        }
        self.result_end_time.as_mut().unwrap()
    }

    // Take field
    pub fn take_result_end_time(&mut self) -> ::protobuf::well_known_types::Duration {
        self.result_end_time.take().unwrap_or_else(|| ::protobuf::well_known_types::Duration::new())
    }

    // int32 channel_tag = 5;


    pub fn get_channel_tag(&self) -> i32 {
        self.channel_tag
    }
    pub fn clear_channel_tag(&mut self) {
        self.channel_tag = 0;
    }

    // Param is passed by value, moved
    pub fn set_channel_tag(&mut self, v: i32) {
        self.channel_tag = v;
    }

    // string language_code = 6;


    pub fn get_language_code(&self) -> &str {
        &self.language_code
    }
    pub fn clear_language_code(&mut self) {
        self.language_code.clear();
    }

    // Param is passed by value, moved
    pub fn set_language_code(&mut self, v: ::std::string::String) {
        self.language_code = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_language_code(&mut self) -> &mut ::std::string::String {
        &mut self.language_code
    }

    // Take field
    pub fn take_language_code(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.language_code, ::std::string::String::new())
    }
}

impl ::protobuf::Message for StreamingRecognitionResult {
    fn is_initialized(&self) -> bool {
        for v in &self.alternatives {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.result_end_time {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.alternatives)?;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.is_final = tmp;
                },
                3 => {
                    if wire_type != ::protobuf::wire_format::WireTypeFixed32 {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_float()?;
                    self.stability = tmp;
                },
                4 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.result_end_time)?;
                },
                5 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.channel_tag = tmp;
                },
                6 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.language_code)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.alternatives {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        if self.is_final != false {
            my_size += 2;
        }
        if self.stability != 0. {
            my_size += 5;
        }
        if let Some(ref v) = self.result_end_time.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if self.channel_tag != 0 {
            my_size += ::protobuf::rt::value_size(5, self.channel_tag, ::protobuf::wire_format::WireTypeVarint);
        }
        if !self.language_code.is_empty() {
            my_size += ::protobuf::rt::string_size(6, &self.language_code);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        for v in &self.alternatives {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        if self.is_final != false {
            os.write_bool(2, self.is_final)?;
        }
        if self.stability != 0. {
            os.write_float(3, self.stability)?;
        }
        if let Some(ref v) = self.result_end_time.as_ref() {
            os.write_tag(4, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if self.channel_tag != 0 {
            os.write_int32(5, self.channel_tag)?;
        }
        if !self.language_code.is_empty() {
            os.write_string(6, &self.language_code)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> StreamingRecognitionResult {
        StreamingRecognitionResult::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<SpeechRecognitionAlternative>>(
                "alternatives",
                |m: &StreamingRecognitionResult| { &m.alternatives },
                |m: &mut StreamingRecognitionResult| { &mut m.alternatives },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "is_final",
                |m: &StreamingRecognitionResult| { &m.is_final },
                |m: &mut StreamingRecognitionResult| { &mut m.is_final },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeFloat>(
                "stability",
                |m: &StreamingRecognitionResult| { &m.stability },
                |m: &mut StreamingRecognitionResult| { &mut m.stability },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<::protobuf::well_known_types::Duration>>(
                "result_end_time",
                |m: &StreamingRecognitionResult| { &m.result_end_time },
                |m: &mut StreamingRecognitionResult| { &mut m.result_end_time },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "channel_tag",
                |m: &StreamingRecognitionResult| { &m.channel_tag },
                |m: &mut StreamingRecognitionResult| { &mut m.channel_tag },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "language_code",
                |m: &StreamingRecognitionResult| { &m.language_code },
                |m: &mut StreamingRecognitionResult| { &mut m.language_code },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<StreamingRecognitionResult>(
                "StreamingRecognitionResult",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static StreamingRecognitionResult {
        static instance: ::protobuf::rt::LazyV2<StreamingRecognitionResult> = ::protobuf::rt::LazyV2::INIT;
        instance.get(StreamingRecognitionResult::new)
    }
}

impl ::protobuf::Clear for StreamingRecognitionResult {
    fn clear(&mut self) {
        self.alternatives.clear();
        self.is_final = false;
        self.stability = 0.;
        self.result_end_time.clear();
        self.channel_tag = 0;
        self.language_code.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for StreamingRecognitionResult {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for StreamingRecognitionResult {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct SpeechRecognitionResult {
    // message fields
    pub alternatives: ::protobuf::RepeatedField<SpeechRecognitionAlternative>,
    pub channel_tag: i32,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a SpeechRecognitionResult {
    fn default() -> &'a SpeechRecognitionResult {
        <SpeechRecognitionResult as ::protobuf::Message>::default_instance()
    }
}

impl SpeechRecognitionResult {
    pub fn new() -> SpeechRecognitionResult {
        ::std::default::Default::default()
    }

    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;


    pub fn get_alternatives(&self) -> &[SpeechRecognitionAlternative] {
        &self.alternatives
    }
    pub fn clear_alternatives(&mut self) {
        self.alternatives.clear();
    }

    // Param is passed by value, moved
    pub fn set_alternatives(&mut self, v: ::protobuf::RepeatedField<SpeechRecognitionAlternative>) {
        self.alternatives = v;
    }

    // Mutable pointer to the field.
    pub fn mut_alternatives(&mut self) -> &mut ::protobuf::RepeatedField<SpeechRecognitionAlternative> {
        &mut self.alternatives
    }

    // Take field
    pub fn take_alternatives(&mut self) -> ::protobuf::RepeatedField<SpeechRecognitionAlternative> {
        ::std::mem::replace(&mut self.alternatives, ::protobuf::RepeatedField::new())
    }

    // int32 channel_tag = 2;


    pub fn get_channel_tag(&self) -> i32 {
        self.channel_tag
    }
    pub fn clear_channel_tag(&mut self) {
        self.channel_tag = 0;
    }

    // Param is passed by value, moved
    pub fn set_channel_tag(&mut self, v: i32) {
        self.channel_tag = v;
    }
}

impl ::protobuf::Message for SpeechRecognitionResult {
    fn is_initialized(&self) -> bool {
        for v in &self.alternatives {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.alternatives)?;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.channel_tag = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.alternatives {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        if self.channel_tag != 0 {
            my_size += ::protobuf::rt::value_size(2, self.channel_tag, ::protobuf::wire_format::WireTypeVarint);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        for v in &self.alternatives {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        if self.channel_tag != 0 {
            os.write_int32(2, self.channel_tag)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> SpeechRecognitionResult {
        SpeechRecognitionResult::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<SpeechRecognitionAlternative>>(
                "alternatives",
                |m: &SpeechRecognitionResult| { &m.alternatives },
                |m: &mut SpeechRecognitionResult| { &mut m.alternatives },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "channel_tag",
                |m: &SpeechRecognitionResult| { &m.channel_tag },
                |m: &mut SpeechRecognitionResult| { &mut m.channel_tag },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<SpeechRecognitionResult>(
                "SpeechRecognitionResult",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static SpeechRecognitionResult {
        static instance: ::protobuf::rt::LazyV2<SpeechRecognitionResult> = ::protobuf::rt::LazyV2::INIT;
        instance.get(SpeechRecognitionResult::new)
    }
}

impl ::protobuf::Clear for SpeechRecognitionResult {
    fn clear(&mut self) {
        self.alternatives.clear();
        self.channel_tag = 0;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for SpeechRecognitionResult {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for SpeechRecognitionResult {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct SpeechRecognitionAlternative {
    // message fields
    pub transcript: ::std::string::String,
    pub confidence: f32,
    pub words: ::protobuf::RepeatedField<WordInfo>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a SpeechRecognitionAlternative {
    fn default() -> &'a SpeechRecognitionAlternative {
        <SpeechRecognitionAlternative as ::protobuf::Message>::default_instance()
    }
}

impl SpeechRecognitionAlternative {
    pub fn new() -> SpeechRecognitionAlternative {
        ::std::default::Default::default()
    }

    // string transcript = 1;


    pub fn get_transcript(&self) -> &str {
        &self.transcript
    }
    pub fn clear_transcript(&mut self) {
        self.transcript.clear();
    }

    // Param is passed by value, moved
    pub fn set_transcript(&mut self, v: ::std::string::String) {
        self.transcript = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_transcript(&mut self) -> &mut ::std::string::String {
        &mut self.transcript
    }

    // Take field
    pub fn take_transcript(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.transcript, ::std::string::String::new())
    }

    // float confidence = 2;


    pub fn get_confidence(&self) -> f32 {
        self.confidence
    }
    pub fn clear_confidence(&mut self) {
        self.confidence = 0.;
    }

    // Param is passed by value, moved
    pub fn set_confidence(&mut self, v: f32) {
        self.confidence = v;
    }

    // repeated .google.cloud.speech.v1.WordInfo words = 3;


    pub fn get_words(&self) -> &[WordInfo] {
        &self.words
    }
    pub fn clear_words(&mut self) {
        self.words.clear();
    }

    // Param is passed by value, moved
    pub fn set_words(&mut self, v: ::protobuf::RepeatedField<WordInfo>) {
        self.words = v;
    }

    // Mutable pointer to the field.
    pub fn mut_words(&mut self) -> &mut ::protobuf::RepeatedField<WordInfo> {
        &mut self.words
    }

    // Take field
    pub fn take_words(&mut self) -> ::protobuf::RepeatedField<WordInfo> {
        ::std::mem::replace(&mut self.words, ::protobuf::RepeatedField::new())
    }
}

impl ::protobuf::Message for SpeechRecognitionAlternative {
    fn is_initialized(&self) -> bool {
        for v in &self.words {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.transcript)?;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeFixed32 {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_float()?;
                    self.confidence = tmp;
                },
                3 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.words)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if !self.transcript.is_empty() {
            my_size += ::protobuf::rt::string_size(1, &self.transcript);
        }
        if self.confidence != 0. {
            my_size += 5;
        }
        for value in &self.words {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if !self.transcript.is_empty() {
            os.write_string(1, &self.transcript)?;
        }
        if self.confidence != 0. {
            os.write_float(2, self.confidence)?;
        }
        for v in &self.words {
            os.write_tag(3, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> SpeechRecognitionAlternative {
        SpeechRecognitionAlternative::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "transcript",
                |m: &SpeechRecognitionAlternative| { &m.transcript },
                |m: &mut SpeechRecognitionAlternative| { &mut m.transcript },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeFloat>(
                "confidence",
                |m: &SpeechRecognitionAlternative| { &m.confidence },
                |m: &mut SpeechRecognitionAlternative| { &mut m.confidence },
            ));
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<WordInfo>>(
                "words",
                |m: &SpeechRecognitionAlternative| { &m.words },
                |m: &mut SpeechRecognitionAlternative| { &mut m.words },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<SpeechRecognitionAlternative>(
                "SpeechRecognitionAlternative",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static SpeechRecognitionAlternative {
        static instance: ::protobuf::rt::LazyV2<SpeechRecognitionAlternative> = ::protobuf::rt::LazyV2::INIT;
        instance.get(SpeechRecognitionAlternative::new)
    }
}

impl ::protobuf::Clear for SpeechRecognitionAlternative {
    fn clear(&mut self) {
        self.transcript.clear();
        self.confidence = 0.;
        self.words.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for SpeechRecognitionAlternative {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for SpeechRecognitionAlternative {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct WordInfo {
    // message fields
    pub start_time: ::protobuf::SingularPtrField<::protobuf::well_known_types::Duration>,
    pub end_time: ::protobuf::SingularPtrField<::protobuf::well_known_types::Duration>,
    pub word: ::std::string::String,
    pub speaker_tag: i32,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a WordInfo {
    fn default() -> &'a WordInfo {
        <WordInfo as ::protobuf::Message>::default_instance()
    }
}

impl WordInfo {
    pub fn new() -> WordInfo {
        ::std::default::Default::default()
    }

    // .google.protobuf.Duration start_time = 1;


    pub fn get_start_time(&self) -> &::protobuf::well_known_types::Duration {
        self.start_time.as_ref().unwrap_or_else(|| <::protobuf::well_known_types::Duration as ::protobuf::Message>::default_instance())
    }
    pub fn clear_start_time(&mut self) {
        self.start_time.clear();
    }

    pub fn has_start_time(&self) -> bool {
        self.start_time.is_some()
    }

    // Param is passed by value, moved
    pub fn set_start_time(&mut self, v: ::protobuf::well_known_types::Duration) {
        self.start_time = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_start_time(&mut self) -> &mut ::protobuf::well_known_types::Duration {
        if self.start_time.is_none() {
            self.start_time.set_default();
        }
        self.start_time.as_mut().unwrap()
    }

    // Take field
    pub fn take_start_time(&mut self) -> ::protobuf::well_known_types::Duration {
        self.start_time.take().unwrap_or_else(|| ::protobuf::well_known_types::Duration::new())
    }

    // .google.protobuf.Duration end_time = 2;


    pub fn get_end_time(&self) -> &::protobuf::well_known_types::Duration {
        self.end_time.as_ref().unwrap_or_else(|| <::protobuf::well_known_types::Duration as ::protobuf::Message>::default_instance())
    }
    pub fn clear_end_time(&mut self) {
        self.end_time.clear();
    }

    pub fn has_end_time(&self) -> bool {
        self.end_time.is_some()
    }

    // Param is passed by value, moved
    pub fn set_end_time(&mut self, v: ::protobuf::well_known_types::Duration) {
        self.end_time = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_end_time(&mut self) -> &mut ::protobuf::well_known_types::Duration {
        if self.end_time.is_none() {
            self.end_time.set_default();
        }
        self.end_time.as_mut().unwrap()
    }

    // Take field
    pub fn take_end_time(&mut self) -> ::protobuf::well_known_types::Duration {
        self.end_time.take().unwrap_or_else(|| ::protobuf::well_known_types::Duration::new())
    }

    // string word = 3;


    pub fn get_word(&self) -> &str {
        &self.word
    }
    pub fn clear_word(&mut self) {
        self.word.clear();
    }

    // Param is passed by value, moved
    pub fn set_word(&mut self, v: ::std::string::String) {
        self.word = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_word(&mut self) -> &mut ::std::string::String {
        &mut self.word
    }

    // Take field
    pub fn take_word(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.word, ::std::string::String::new())
    }

    // int32 speaker_tag = 5;


    pub fn get_speaker_tag(&self) -> i32 {
        self.speaker_tag
    }
    pub fn clear_speaker_tag(&mut self) {
        self.speaker_tag = 0;
    }

    // Param is passed by value, moved
    pub fn set_speaker_tag(&mut self, v: i32) {
        self.speaker_tag = v;
    }
}

impl ::protobuf::Message for WordInfo {
    fn is_initialized(&self) -> bool {
        for v in &self.start_time {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.end_time {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.start_time)?;
                },
                2 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.end_time)?;
                },
                3 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.word)?;
                },
                5 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.speaker_tag = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if let Some(ref v) = self.start_time.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if let Some(ref v) = self.end_time.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if !self.word.is_empty() {
            my_size += ::protobuf::rt::string_size(3, &self.word);
        }
        if self.speaker_tag != 0 {
            my_size += ::protobuf::rt::value_size(5, self.speaker_tag, ::protobuf::wire_format::WireTypeVarint);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if let Some(ref v) = self.start_time.as_ref() {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if let Some(ref v) = self.end_time.as_ref() {
            os.write_tag(2, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if !self.word.is_empty() {
            os.write_string(3, &self.word)?;
        }
        if self.speaker_tag != 0 {
            os.write_int32(5, self.speaker_tag)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> WordInfo {
        WordInfo::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<::protobuf::well_known_types::Duration>>(
                "start_time",
                |m: &WordInfo| { &m.start_time },
                |m: &mut WordInfo| { &mut m.start_time },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<::protobuf::well_known_types::Duration>>(
                "end_time",
                |m: &WordInfo| { &m.end_time },
                |m: &mut WordInfo| { &mut m.end_time },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "word",
                |m: &WordInfo| { &m.word },
                |m: &mut WordInfo| { &mut m.word },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "speaker_tag",
                |m: &WordInfo| { &m.speaker_tag },
                |m: &mut WordInfo| { &mut m.speaker_tag },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<WordInfo>(
                "WordInfo",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static WordInfo {
        static instance: ::protobuf::rt::LazyV2<WordInfo> = ::protobuf::rt::LazyV2::INIT;
        instance.get(WordInfo::new)
    }
}

impl ::protobuf::Clear for WordInfo {
    fn clear(&mut self) {
        self.start_time.clear();
        self.end_time.clear();
        self.word.clear();
        self.speaker_tag = 0;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for WordInfo {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for WordInfo {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

static file_descriptor_proto_data: &'static [u8] = b"\
    \n)google/cloud/speech/v1/cloud_speech.proto\x12\x16google.cloud.speech.\
    v1\x1a\x1cgoogle/api/annotations.proto\x1a\x17google/api/client.proto\
    \x1a\x1fgoogle/api/field_behavior.proto\x1a#google/longrunning/operation\
    s.proto\x1a\x19google/protobuf/any.proto\x1a\x1egoogle/protobuf/duration\
    .proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x17google/rpc/status.p\
    roto\"\x9f\x01\n\x10RecognizeRequest\x12F\n\x06config\x18\x01\x20\x01(\
    \x0b2).google.cloud.speech.v1.RecognitionConfigR\x06configB\x03\xe0A\x02\
    \x12C\n\x05audio\x18\x02\x20\x01(\x0b2(.google.cloud.speech.v1.Recogniti\
    onAudioR\x05audioB\x03\xe0A\x02\"\xaa\x01\n\x1bLongRunningRecognizeReque\
    st\x12F\n\x06config\x18\x01\x20\x01(\x0b2).google.cloud.speech.v1.Recogn\
    itionConfigR\x06configB\x03\xe0A\x02\x12C\n\x05audio\x18\x02\x20\x01(\
    \x0b2(.google.cloud.speech.v1.RecognitionAudioR\x05audioB\x03\xe0A\x02\"\
    \xb8\x01\n\x19StreamingRecognizeRequest\x12_\n\x10streaming_config\x18\
    \x01\x20\x01(\x0b22.google.cloud.speech.v1.StreamingRecognitionConfigH\0\
    R\x0fstreamingConfig\x12%\n\raudio_content\x18\x02\x20\x01(\x0cH\0R\x0ca\
    udioContentB\x13\n\x11streaming_request\"\xb8\x01\n\x1aStreamingRecognit\
    ionConfig\x12F\n\x06config\x18\x01\x20\x01(\x0b2).google.cloud.speech.v1\
    .RecognitionConfigR\x06configB\x03\xe0A\x02\x12)\n\x10single_utterance\
    \x18\x02\x20\x01(\x08R\x0fsingleUtterance\x12'\n\x0finterim_results\x18\
    \x03\x20\x01(\x08R\x0einterimResults\"\xd6\x07\n\x11RecognitionConfig\
    \x12S\n\x08encoding\x18\x01\x20\x01(\x0e27.google.cloud.speech.v1.Recogn\
    itionConfig.AudioEncodingR\x08encoding\x12*\n\x11sample_rate_hertz\x18\
    \x02\x20\x01(\x05R\x0fsampleRateHertz\x12.\n\x13audio_channel_count\x18\
    \x07\x20\x01(\x05R\x11audioChannelCount\x12T\n'enable_separate_recogniti\
    on_per_channel\x18\x0c\x20\x01(\x08R#enableSeparateRecognitionPerChannel\
    \x12(\n\rlanguage_code\x18\x03\x20\x01(\tR\x0clanguageCodeB\x03\xe0A\x02\
    \x12)\n\x10max_alternatives\x18\x04\x20\x01(\x05R\x0fmaxAlternatives\x12\
    )\n\x10profanity_filter\x18\x05\x20\x01(\x08R\x0fprofanityFilter\x12N\n\
    \x0fspeech_contexts\x18\x06\x20\x03(\x0b2%.google.cloud.speech.v1.Speech\
    ContextR\x0espeechContexts\x127\n\x18enable_word_time_offsets\x18\x08\
    \x20\x01(\x08R\x15enableWordTimeOffsets\x12@\n\x1cenable_automatic_punct\
    uation\x18\x0b\x20\x01(\x08R\x1aenableAutomaticPunctuation\x12_\n\x12dia\
    rization_config\x18\x13\x20\x01(\x0b20.google.cloud.speech.v1.SpeakerDia\
    rizationConfigR\x11diarizationConfig\x12G\n\x08metadata\x18\t\x20\x01(\
    \x0b2+.google.cloud.speech.v1.RecognitionMetadataR\x08metadata\x12\x14\n\
    \x05model\x18\r\x20\x01(\tR\x05model\x12!\n\x0cuse_enhanced\x18\x0e\x20\
    \x01(\x08R\x0buseEnhanced\"\x8b\x01\n\rAudioEncoding\x12\x18\n\x14ENCODI\
    NG_UNSPECIFIED\x10\0\x12\x0c\n\x08LINEAR16\x10\x01\x12\x08\n\x04FLAC\x10\
    \x02\x12\t\n\x05MULAW\x10\x03\x12\x07\n\x03AMR\x10\x04\x12\n\n\x06AMR_WB\
    \x10\x05\x12\x0c\n\x08OGG_OPUS\x10\x06\x12\x1a\n\x16SPEEX_WITH_HEADER_BY\
    TE\x10\x07\"\xd8\x01\n\x18SpeakerDiarizationConfig\x12<\n\x1aenable_spea\
    ker_diarization\x18\x01\x20\x01(\x08R\x18enableSpeakerDiarization\x12*\n\
    \x11min_speaker_count\x18\x02\x20\x01(\x05R\x0fminSpeakerCount\x12*\n\
    \x11max_speaker_count\x18\x03\x20\x01(\x05R\x0fmaxSpeakerCount\x12&\n\
    \x0bspeaker_tag\x18\x05\x20\x01(\x05R\nspeakerTagB\x05\x18\x01\xe0A\x03\
    \"\xba\t\n\x13RecognitionMetadata\x12f\n\x10interaction_type\x18\x01\x20\
    \x01(\x0e2;.google.cloud.speech.v1.RecognitionMetadata.InteractionTypeR\
    \x0finteractionType\x12>\n\x1cindustry_naics_code_of_audio\x18\x03\x20\
    \x01(\rR\x18industryNaicsCodeOfAudio\x12o\n\x13microphone_distance\x18\
    \x04\x20\x01(\x0e2>.google.cloud.speech.v1.RecognitionMetadata.Microphon\
    eDistanceR\x12microphoneDistance\x12m\n\x13original_media_type\x18\x05\
    \x20\x01(\x0e2=.google.cloud.speech.v1.RecognitionMetadata.OriginalMedia\
    TypeR\x11originalMediaType\x12s\n\x15recording_device_type\x18\x06\x20\
    \x01(\x0e2?.google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceTy\
    peR\x13recordingDeviceType\x122\n\x15recording_device_name\x18\x07\x20\
    \x01(\tR\x13recordingDeviceName\x12,\n\x12original_mime_type\x18\x08\x20\
    \x01(\tR\x10originalMimeType\x12\x1f\n\x0baudio_topic\x18\n\x20\x01(\tR\
    \naudioTopic\"\xc5\x01\n\x0fInteractionType\x12\x20\n\x1cINTERACTION_TYP\
    E_UNSPECIFIED\x10\0\x12\x0e\n\nDISCUSSION\x10\x01\x12\x10\n\x0cPRESENTAT\
    ION\x10\x02\x12\x0e\n\nPHONE_CALL\x10\x03\x12\r\n\tVOICEMAIL\x10\x04\x12\
    \x1b\n\x17PROFESSIONALLY_PRODUCED\x10\x05\x12\x10\n\x0cVOICE_SEARCH\x10\
    \x06\x12\x11\n\rVOICE_COMMAND\x10\x07\x12\r\n\tDICTATION\x10\x08\"d\n\
    \x12MicrophoneDistance\x12#\n\x1fMICROPHONE_DISTANCE_UNSPECIFIED\x10\0\
    \x12\r\n\tNEARFIELD\x10\x01\x12\x0c\n\x08MIDFIELD\x10\x02\x12\x0c\n\x08F\
    ARFIELD\x10\x03\"N\n\x11OriginalMediaType\x12#\n\x1fORIGINAL_MEDIA_TYPE_\
    UNSPECIFIED\x10\0\x12\t\n\x05AUDIO\x10\x01\x12\t\n\x05VIDEO\x10\x02\"\
    \xa4\x01\n\x13RecordingDeviceType\x12%\n!RECORDING_DEVICE_TYPE_UNSPECIFI\
    ED\x10\0\x12\x0e\n\nSMARTPHONE\x10\x01\x12\x06\n\x02PC\x10\x02\x12\x0e\n\
    \nPHONE_LINE\x10\x03\x12\x0b\n\x07VEHICLE\x10\x04\x12\x18\n\x14OTHER_OUT\
    DOOR_DEVICE\x10\x05\x12\x17\n\x13OTHER_INDOOR_DEVICE\x10\x06\")\n\rSpeec\
    hContext\x12\x18\n\x07phrases\x18\x01\x20\x03(\tR\x07phrases\"R\n\x10Rec\
    ognitionAudio\x12\x1a\n\x07content\x18\x01\x20\x01(\x0cH\0R\x07content\
    \x12\x12\n\x03uri\x18\x02\x20\x01(\tH\0R\x03uriB\x0e\n\x0caudio_source\"\
    ^\n\x11RecognizeResponse\x12I\n\x07results\x18\x02\x20\x03(\x0b2/.google\
    .cloud.speech.v1.SpeechRecognitionResultR\x07results\"i\n\x1cLongRunning\
    RecognizeResponse\x12I\n\x07results\x18\x02\x20\x03(\x0b2/.google.cloud.\
    speech.v1.SpeechRecognitionResultR\x07results\"\xca\x01\n\x1cLongRunning\
    RecognizeMetadata\x12)\n\x10progress_percent\x18\x01\x20\x01(\x05R\x0fpr\
    ogressPercent\x129\n\nstart_time\x18\x02\x20\x01(\x0b2\x1a.google.protob\
    uf.TimestampR\tstartTime\x12D\n\x10last_update_time\x18\x03\x20\x01(\x0b\
    2\x1a.google.protobuf.TimestampR\x0elastUpdateTime\"\xd2\x02\n\x1aStream\
    ingRecognizeResponse\x12(\n\x05error\x18\x01\x20\x01(\x0b2\x12.google.rp\
    c.StatusR\x05error\x12L\n\x07results\x18\x02\x20\x03(\x0b22.google.cloud\
    .speech.v1.StreamingRecognitionResultR\x07results\x12n\n\x11speech_event\
    _type\x18\x04\x20\x01(\x0e2B.google.cloud.speech.v1.StreamingRecognizeRe\
    sponse.SpeechEventTypeR\x0fspeechEventType\"L\n\x0fSpeechEventType\x12\
    \x1c\n\x18SPEECH_EVENT_UNSPECIFIED\x10\0\x12\x1b\n\x17END_OF_SINGLE_UTTE\
    RANCE\x10\x01\"\xbd\x02\n\x1aStreamingRecognitionResult\x12X\n\x0caltern\
    atives\x18\x01\x20\x03(\x0b24.google.cloud.speech.v1.SpeechRecognitionAl\
    ternativeR\x0calternatives\x12\x19\n\x08is_final\x18\x02\x20\x01(\x08R\
    \x07isFinal\x12\x1c\n\tstability\x18\x03\x20\x01(\x02R\tstability\x12A\n\
    \x0fresult_end_time\x18\x04\x20\x01(\x0b2\x19.google.protobuf.DurationR\
    \rresultEndTime\x12\x1f\n\x0bchannel_tag\x18\x05\x20\x01(\x05R\nchannelT\
    ag\x12(\n\rlanguage_code\x18\x06\x20\x01(\tR\x0clanguageCodeB\x03\xe0A\
    \x03\"\x94\x01\n\x17SpeechRecognitionResult\x12X\n\x0calternatives\x18\
    \x01\x20\x03(\x0b24.google.cloud.speech.v1.SpeechRecognitionAlternativeR\
    \x0calternatives\x12\x1f\n\x0bchannel_tag\x18\x02\x20\x01(\x05R\nchannel\
    Tag\"\x96\x01\n\x1cSpeechRecognitionAlternative\x12\x1e\n\ntranscript\
    \x18\x01\x20\x01(\tR\ntranscript\x12\x1e\n\nconfidence\x18\x02\x20\x01(\
    \x02R\nconfidence\x126\n\x05words\x18\x03\x20\x03(\x0b2\x20.google.cloud\
    .speech.v1.WordInfoR\x05words\"\xb4\x01\n\x08WordInfo\x128\n\nstart_time\
    \x18\x01\x20\x01(\x0b2\x19.google.protobuf.DurationR\tstartTime\x124\n\
    \x08end_time\x18\x02\x20\x01(\x0b2\x19.google.protobuf.DurationR\x07endT\
    ime\x12\x12\n\x04word\x18\x03\x20\x01(\tR\x04word\x12$\n\x0bspeaker_tag\
    \x18\x05\x20\x01(\x05R\nspeakerTagB\x03\xe0A\x032\xd1\x04\n\x06Speech\
    \x12\x90\x01\n\tRecognize\x12(.google.cloud.speech.v1.RecognizeRequest\
    \x1a).google.cloud.speech.v1.RecognizeResponse\".\x82\xd3\xe4\x93\x02\
    \x19\"\x14/v1/speech:recognize:\x01*\xdaA\x0cconfig,audio\x12\xe4\x01\n\
    \x14LongRunningRecognize\x123.google.cloud.speech.v1.LongRunningRecogniz\
    eRequest\x1a\x1d.google.longrunning.Operation\"x\xcaA<\n\x1cLongRunningR\
    ecognizeResponse\x12\x1cLongRunningRecognizeMetadata\x82\xd3\xe4\x93\x02\
    $\"\x1f/v1/speech:longrunningrecognize:\x01*\xdaA\x0cconfig,audio\x12\
    \x81\x01\n\x12StreamingRecognize\x121.google.cloud.speech.v1.StreamingRe\
    cognizeRequest\x1a2.google.cloud.speech.v1.StreamingRecognizeResponse\"\
    \0(\x010\x01\x1aI\xd2A.https://www.googleapis.com/auth/cloud-platform\
    \xcaA\x15speech.googleapis.comBr\n\x1acom.google.cloud.speech.v1B\x0bSpe\
    echProtoP\x01Z<google.golang.org/genproto/googleapis/cloud/speech/v1;spe\
    ech\xf8\x01\x01\xa2\x02\x03GCSJ\xb2\x81\x02\n\x07\x12\x05\x0f\0\xf6\x05\
    \x01\n\xbe\x04\n\x01\x0c\x12\x03\x0f\0\x122\xb3\x04\x20Copyright\x202019\
    \x20Google\x20LLC.\n\n\x20Licensed\x20under\x20the\x20Apache\x20License,\
    \x20Version\x202.0\x20(the\x20\"License\");\n\x20you\x20may\x20not\x20us\
    e\x20this\x20file\x20except\x20in\x20compliance\x20with\x20the\x20Licens\
    e.\n\x20You\x20may\x20obtain\x20a\x20copy\x20of\x20the\x20License\x20at\
    \n\n\x20\x20\x20\x20\x20http://www.apache.org/licenses/LICENSE-2.0\n\n\
    \x20Unless\x20required\x20by\x20applicable\x20law\x20or\x20agreed\x20to\
    \x20in\x20writing,\x20software\n\x20distributed\x20under\x20the\x20Licen\
    se\x20is\x20distributed\x20on\x20an\x20\"AS\x20IS\"\x20BASIS,\n\x20WITHO\
    UT\x20WARRANTIES\x20OR\x20CONDITIONS\x20OF\x20ANY\x20KIND,\x20either\x20\
    express\x20or\x20implied.\n\x20See\x20the\x20License\x20for\x20the\x20sp\
    ecific\x20language\x20governing\x20permissions\x20and\n\x20limitations\
    \x20under\x20the\x20License.\n\n\n\x08\n\x01\x02\x12\x03\x11\0\x1f\n\t\n\
    \x02\x03\0\x12\x03\x13\0&\n\t\n\x02\x03\x01\x12\x03\x14\0!\n\t\n\x02\x03\
    \x02\x12\x03\x15\0)\n\t\n\x02\x03\x03\x12\x03\x16\0-\n\t\n\x02\x03\x04\
    \x12\x03\x17\0#\n\t\n\x02\x03\x05\x12\x03\x18\0(\n\t\n\x02\x03\x06\x12\
    \x03\x19\0)\n\t\n\x02\x03\x07\x12\x03\x1a\0!\n\x08\n\x01\x08\x12\x03\x1c\
    \0\x1f\n\t\n\x02\x08\x1f\x12\x03\x1c\0\x1f\n\x08\n\x01\x08\x12\x03\x1d\0\
    S\n\t\n\x02\x08\x0b\x12\x03\x1d\0S\n\x08\n\x01\x08\x12\x03\x1e\0\"\n\t\n\
    \x02\x08\n\x12\x03\x1e\0\"\n\x08\n\x01\x08\x12\x03\x1f\0,\n\t\n\x02\x08\
    \x08\x12\x03\x1f\0,\n\x08\n\x01\x08\x12\x03\x20\03\n\t\n\x02\x08\x01\x12\
    \x03\x20\03\n\x08\n\x01\x08\x12\x03!\0!\n\t\n\x02\x08$\x12\x03!\0!\n>\n\
    \x02\x06\0\x12\x04$\0H\x01\x1a2\x20Service\x20that\x20implements\x20Goog\
    le\x20Cloud\x20Speech\x20API.\n\n\n\n\x03\x06\0\x01\x12\x03$\x08\x0e\n\n\
    \n\x03\x06\0\x03\x12\x03%\x02=\n\x0c\n\x05\x06\0\x03\x99\x08\x12\x03%\
    \x02=\n\n\n\x03\x06\0\x03\x12\x03&\x02V\n\x0c\n\x05\x06\0\x03\x9a\x08\
    \x12\x03&\x02V\nv\n\x04\x06\0\x02\0\x12\x04*\x020\x03\x1ah\x20Performs\
    \x20synchronous\x20speech\x20recognition:\x20receive\x20results\x20after\
    \x20all\x20audio\n\x20has\x20been\x20sent\x20and\x20processed.\n\n\x0c\n\
    \x05\x06\0\x02\0\x01\x12\x03*\x06\x0f\n\x0c\n\x05\x06\0\x02\0\x02\x12\
    \x03*\x10\x20\n\x0c\n\x05\x06\0\x02\0\x03\x12\x03*+<\n\r\n\x05\x06\0\x02\
    \0\x04\x12\x04+\x04.\x06\n\x11\n\t\x06\0\x02\0\x04\xb0\xca\xbc\"\x12\x04\
    +\x04.\x06\n\x0c\n\x05\x06\0\x02\0\x04\x12\x03/\x04:\n\x0f\n\x08\x06\0\
    \x02\0\x04\x9b\x08\0\x12\x03/\x04:\n\x81\x03\n\x04\x06\0\x02\x01\x12\x04\
    8\x02B\x03\x1a\xf2\x02\x20Performs\x20asynchronous\x20speech\x20recognit\
    ion:\x20receive\x20results\x20via\x20the\n\x20google.longrunning.Operati\
    ons\x20interface.\x20Returns\x20either\x20an\n\x20`Operation.error`\x20o\
    r\x20an\x20`Operation.response`\x20which\x20contains\n\x20a\x20`LongRunn\
    ingRecognizeResponse`\x20message.\n\x20For\x20more\x20information\x20on\
    \x20asynchronous\x20speech\x20recognition,\x20see\x20the\n\x20[how-to](h\
    ttps://cloud.google.com/speech-to-text/docs/async-recognize).\n\n\x0c\n\
    \x05\x06\0\x02\x01\x01\x12\x038\x06\x1a\n\x0c\n\x05\x06\0\x02\x01\x02\
    \x12\x038\x1b6\n\x0c\n\x05\x06\0\x02\x01\x03\x12\x038A]\n\r\n\x05\x06\0\
    \x02\x01\x04\x12\x049\x04<\x06\n\x11\n\t\x06\0\x02\x01\x04\xb0\xca\xbc\"\
    \x12\x049\x04<\x06\n\x0c\n\x05\x06\0\x02\x01\x04\x12\x03=\x04:\n\x0f\n\
    \x08\x06\0\x02\x01\x04\x9b\x08\0\x12\x03=\x04:\n\r\n\x05\x06\0\x02\x01\
    \x04\x12\x04>\x04A\x06\n\x0f\n\x07\x06\0\x02\x01\x04\x99\x08\x12\x04>\
    \x04A\x06\n\xa6\x01\n\x04\x06\0\x02\x02\x12\x04F\x02G\x03\x1a\x97\x01\
    \x20Performs\x20bidirectional\x20streaming\x20speech\x20recognition:\x20\
    receive\x20results\x20while\n\x20sending\x20audio.\x20This\x20method\x20\
    is\x20only\x20available\x20via\x20the\x20gRPC\x20API\x20(not\x20REST).\n\
    \n\x0c\n\x05\x06\0\x02\x02\x01\x12\x03F\x06\x18\n\x0c\n\x05\x06\0\x02\
    \x02\x05\x12\x03F\x19\x1f\n\x0c\n\x05\x06\0\x02\x02\x02\x12\x03F\x209\n\
    \x0c\n\x05\x06\0\x02\x02\x06\x12\x03FDJ\n\x0c\n\x05\x06\0\x02\x02\x03\
    \x12\x03FKe\nR\n\x02\x04\0\x12\x04K\0R\x01\x1aF\x20The\x20top-level\x20m\
    essage\x20sent\x20by\x20the\x20client\x20for\x20the\x20`Recognize`\x20me\
    thod.\n\n\n\n\x03\x04\0\x01\x12\x03K\x08\x18\nk\n\x04\x04\0\x02\0\x12\
    \x03N\x02H\x1a^\x20Required.\x20Provides\x20information\x20to\x20the\x20\
    recognizer\x20that\x20specifies\x20how\x20to\n\x20process\x20the\x20requ\
    est.\n\n\x0c\n\x05\x04\0\x02\0\x06\x12\x03N\x02\x13\n\x0c\n\x05\x04\0\
    \x02\0\x01\x12\x03N\x14\x1a\n\x0c\n\x05\x04\0\x02\0\x03\x12\x03N\x1d\x1e\
    \n\x0c\n\x05\x04\0\x02\0\x08\x12\x03N\x1fG\n\x0f\n\x08\x04\0\x02\0\x08\
    \x9c\x08\0\x12\x03N\x20F\n9\n\x04\x04\0\x02\x01\x12\x03Q\x02F\x1a,\x20Re\
    quired.\x20The\x20audio\x20data\x20to\x20be\x20recognized.\n\n\x0c\n\x05\
    \x04\0\x02\x01\x06\x12\x03Q\x02\x12\n\x0c\n\x05\x04\0\x02\x01\x01\x12\
    \x03Q\x13\x18\n\x0c\n\x05\x04\0\x02\x01\x03\x12\x03Q\x1b\x1c\n\x0c\n\x05\
    \x04\0\x02\x01\x08\x12\x03Q\x1dE\n\x0f\n\x08\x04\0\x02\x01\x08\x9c\x08\0\
    \x12\x03Q\x1eD\n^\n\x02\x04\x01\x12\x04V\0]\x01\x1aR\x20The\x20top-level\
    \x20message\x20sent\x20by\x20the\x20client\x20for\x20the\x20`LongRunning\
    Recognize`\n\x20method.\n\n\n\n\x03\x04\x01\x01\x12\x03V\x08#\nk\n\x04\
    \x04\x01\x02\0\x12\x03Y\x02H\x1a^\x20Required.\x20Provides\x20informatio\
    n\x20to\x20the\x20recognizer\x20that\x20specifies\x20how\x20to\n\x20proc\
    ess\x20the\x20request.\n\n\x0c\n\x05\x04\x01\x02\0\x06\x12\x03Y\x02\x13\
    \n\x0c\n\x05\x04\x01\x02\0\x01\x12\x03Y\x14\x1a\n\x0c\n\x05\x04\x01\x02\
    \0\x03\x12\x03Y\x1d\x1e\n\x0c\n\x05\x04\x01\x02\0\x08\x12\x03Y\x1fG\n\
    \x0f\n\x08\x04\x01\x02\0\x08\x9c\x08\0\x12\x03Y\x20F\n9\n\x04\x04\x01\
    \x02\x01\x12\x03\\\x02F\x1a,\x20Required.\x20The\x20audio\x20data\x20to\
    \x20be\x20recognized.\n\n\x0c\n\x05\x04\x01\x02\x01\x06\x12\x03\\\x02\
    \x12\n\x0c\n\x05\x04\x01\x02\x01\x01\x12\x03\\\x13\x18\n\x0c\n\x05\x04\
    \x01\x02\x01\x03\x12\x03\\\x1b\x1c\n\x0c\n\x05\x04\x01\x02\x01\x08\x12\
    \x03\\\x1dE\n\x0f\n\x08\x04\x01\x02\x01\x08\x9c\x08\0\x12\x03\\\x1eD\n\
    \xe2\x02\n\x02\x04\x02\x12\x04d\0v\x01\x1a\xd5\x02\x20The\x20top-level\
    \x20message\x20sent\x20by\x20the\x20client\x20for\x20the\x20`StreamingRe\
    cognize`\x20method.\n\x20Multiple\x20`StreamingRecognizeRequest`\x20mess\
    ages\x20are\x20sent.\x20The\x20first\x20message\n\x20must\x20contain\x20\
    a\x20`streaming_config`\x20message\x20and\x20must\x20not\x20contain\n\
    \x20`audio_content`.\x20All\x20subsequent\x20messages\x20must\x20contain\
    \x20`audio_content`\x20and\n\x20must\x20not\x20contain\x20a\x20`streamin\
    g_config`\x20message.\n\n\n\n\x03\x04\x02\x01\x12\x03d\x08!\n[\n\x04\x04\
    \x02\x08\0\x12\x04f\x02u\x03\x1aM\x20The\x20streaming\x20request,\x20whi\
    ch\x20is\x20either\x20a\x20streaming\x20config\x20or\x20audio\x20content\
    .\n\n\x0c\n\x05\x04\x02\x08\0\x01\x12\x03f\x08\x19\n\xbd\x01\n\x04\x04\
    \x02\x02\0\x12\x03j\x044\x1a\xaf\x01\x20Provides\x20information\x20to\
    \x20the\x20recognizer\x20that\x20specifies\x20how\x20to\x20process\x20th\
    e\n\x20request.\x20The\x20first\x20`StreamingRecognizeRequest`\x20messag\
    e\x20must\x20contain\x20a\n\x20`streaming_config`\x20\x20message.\n\n\
    \x0c\n\x05\x04\x02\x02\0\x06\x12\x03j\x04\x1e\n\x0c\n\x05\x04\x02\x02\0\
    \x01\x12\x03j\x1f/\n\x0c\n\x05\x04\x02\x02\0\x03\x12\x03j23\n\xb3\x04\n\
    \x04\x04\x02\x02\x01\x12\x03t\x04\x1c\x1a\xa5\x04\x20The\x20audio\x20dat\
    a\x20to\x20be\x20recognized.\x20Sequential\x20chunks\x20of\x20audio\x20d\
    ata\x20are\x20sent\n\x20in\x20sequential\x20`StreamingRecognizeRequest`\
    \x20messages.\x20The\x20first\n\x20`StreamingRecognizeRequest`\x20messag\
    e\x20must\x20not\x20contain\x20`audio_content`\x20data\n\x20and\x20all\
    \x20subsequent\x20`StreamingRecognizeRequest`\x20messages\x20must\x20con\
    tain\n\x20`audio_content`\x20data.\x20The\x20audio\x20bytes\x20must\x20b\
    e\x20encoded\x20as\x20specified\x20in\n\x20`RecognitionConfig`.\x20Note:\
    \x20as\x20with\x20all\x20bytes\x20fields,\x20proto\x20buffers\x20use\x20\
    a\n\x20pure\x20binary\x20representation\x20(not\x20base64).\x20See\n\x20\
    [content\x20limits](https://cloud.google.com/speech-to-text/quotas#conte\
    nt).\n\n\x0c\n\x05\x04\x02\x02\x01\x05\x12\x03t\x04\t\n\x0c\n\x05\x04\
    \x02\x02\x01\x01\x12\x03t\n\x17\n\x0c\n\x05\x04\x02\x02\x01\x03\x12\x03t\
    \x1a\x1b\na\n\x02\x04\x03\x12\x05z\0\x91\x01\x01\x1aT\x20Provides\x20inf\
    ormation\x20to\x20the\x20recognizer\x20that\x20specifies\x20how\x20to\
    \x20process\x20the\n\x20request.\n\n\n\n\x03\x04\x03\x01\x12\x03z\x08\"\
    \nk\n\x04\x04\x03\x02\0\x12\x03}\x02H\x1a^\x20Required.\x20Provides\x20i\
    nformation\x20to\x20the\x20recognizer\x20that\x20specifies\x20how\x20to\
    \n\x20process\x20the\x20request.\n\n\x0c\n\x05\x04\x03\x02\0\x06\x12\x03\
    }\x02\x13\n\x0c\n\x05\x04\x03\x02\0\x01\x12\x03}\x14\x1a\n\x0c\n\x05\x04\
    \x03\x02\0\x03\x12\x03}\x1d\x1e\n\x0c\n\x05\x04\x03\x02\0\x08\x12\x03}\
    \x1fG\n\x0f\n\x08\x04\x03\x02\0\x08\x9c\x08\0\x12\x03}\x20F\n\x9d\x05\n\
    \x04\x04\x03\x02\x01\x12\x04\x8a\x01\x02\x1c\x1a\x8e\x05\x20If\x20`false\
    `\x20or\x20omitted,\x20the\x20recognizer\x20will\x20perform\x20continuou\
    s\n\x20recognition\x20(continuing\x20to\x20wait\x20for\x20and\x20process\
    \x20audio\x20even\x20if\x20the\x20user\n\x20pauses\x20speaking)\x20until\
    \x20the\x20client\x20closes\x20the\x20input\x20stream\x20(gRPC\x20API)\
    \x20or\n\x20until\x20the\x20maximum\x20time\x20limit\x20has\x20been\x20r\
    eached.\x20May\x20return\x20multiple\n\x20`StreamingRecognitionResult`s\
    \x20with\x20the\x20`is_final`\x20flag\x20set\x20to\x20`true`.\n\n\x20If\
    \x20`true`,\x20the\x20recognizer\x20will\x20detect\x20a\x20single\x20spo\
    ken\x20utterance.\x20When\x20it\n\x20detects\x20that\x20the\x20user\x20h\
    as\x20paused\x20or\x20stopped\x20speaking,\x20it\x20will\x20return\x20an\
    \n\x20`END_OF_SINGLE_UTTERANCE`\x20event\x20and\x20cease\x20recognition.\
    \x20It\x20will\x20return\x20no\n\x20more\x20than\x20one\x20`StreamingRec\
    ognitionResult`\x20with\x20the\x20`is_final`\x20flag\x20set\x20to\n\x20`\
    true`.\n\n\r\n\x05\x04\x03\x02\x01\x05\x12\x04\x8a\x01\x02\x06\n\r\n\x05\
    \x04\x03\x02\x01\x01\x12\x04\x8a\x01\x07\x17\n\r\n\x05\x04\x03\x02\x01\
    \x03\x12\x04\x8a\x01\x1a\x1b\n\xf8\x01\n\x04\x04\x03\x02\x02\x12\x04\x90\
    \x01\x02\x1b\x1a\xe9\x01\x20If\x20`true`,\x20interim\x20results\x20(tent\
    ative\x20hypotheses)\x20may\x20be\n\x20returned\x20as\x20they\x20become\
    \x20available\x20(these\x20interim\x20results\x20are\x20indicated\x20wit\
    h\n\x20the\x20`is_final=false`\x20flag).\n\x20If\x20`false`\x20or\x20omi\
    tted,\x20only\x20`is_final=true`\x20result(s)\x20are\x20returned.\n\n\r\
    \n\x05\x04\x03\x02\x02\x05\x12\x04\x90\x01\x02\x06\n\r\n\x05\x04\x03\x02\
    \x02\x01\x12\x04\x90\x01\x07\x16\n\r\n\x05\x04\x03\x02\x02\x03\x12\x04\
    \x90\x01\x19\x1a\nb\n\x02\x04\x04\x12\x06\x95\x01\0\xde\x02\x01\x1aT\x20\
    Provides\x20information\x20to\x20the\x20recognizer\x20that\x20specifies\
    \x20how\x20to\x20process\x20the\n\x20request.\n\n\x0b\n\x03\x04\x04\x01\
    \x12\x04\x95\x01\x08\x19\n\xe5\t\n\x04\x04\x04\x04\0\x12\x06\xac\x01\x02\
    \xd7\x01\x03\x1a\xd4\t\x20The\x20encoding\x20of\x20the\x20audio\x20data\
    \x20sent\x20in\x20the\x20request.\n\n\x20All\x20encodings\x20support\x20\
    only\x201\x20channel\x20(mono)\x20audio,\x20unless\x20the\n\x20`audio_ch\
    annel_count`\x20and\x20`enable_separate_recognition_per_channel`\x20fiel\
    ds\n\x20are\x20set.\n\n\x20For\x20best\x20results,\x20the\x20audio\x20so\
    urce\x20should\x20be\x20captured\x20and\x20transmitted\x20using\n\x20a\
    \x20lossless\x20encoding\x20(`FLAC`\x20or\x20`LINEAR16`).\x20The\x20accu\
    racy\x20of\x20the\x20speech\n\x20recognition\x20can\x20be\x20reduced\x20\
    if\x20lossy\x20codecs\x20are\x20used\x20to\x20capture\x20or\x20transmit\
    \n\x20audio,\x20particularly\x20if\x20background\x20noise\x20is\x20prese\
    nt.\x20Lossy\x20codecs\x20include\n\x20`MULAW`,\x20`AMR`,\x20`AMR_WB`,\
    \x20`OGG_OPUS`,\x20`SPEEX_WITH_HEADER_BYTE`,\x20and\x20`MP3`.\n\n\x20The\
    \x20`FLAC`\x20and\x20`WAV`\x20audio\x20file\x20formats\x20include\x20a\
    \x20header\x20that\x20describes\x20the\n\x20included\x20audio\x20content\
    .\x20You\x20can\x20request\x20recognition\x20for\x20`WAV`\x20files\x20th\
    at\n\x20contain\x20either\x20`LINEAR16`\x20or\x20`MULAW`\x20encoded\x20a\
    udio.\n\x20If\x20you\x20send\x20`FLAC`\x20or\x20`WAV`\x20audio\x20file\
    \x20format\x20in\n\x20your\x20request,\x20you\x20do\x20not\x20need\x20to\
    \x20specify\x20an\x20`AudioEncoding`;\x20the\x20audio\n\x20encoding\x20f\
    ormat\x20is\x20determined\x20from\x20the\x20file\x20header.\x20If\x20you\
    \x20specify\n\x20an\x20`AudioEncoding`\x20when\x20you\x20send\x20\x20sen\
    d\x20`FLAC`\x20or\x20`WAV`\x20audio,\x20the\n\x20encoding\x20configurati\
    on\x20must\x20match\x20the\x20encoding\x20described\x20in\x20the\x20audi\
    o\n\x20header;\x20otherwise\x20the\x20request\x20returns\x20an\n\x20[goo\
    gle.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]\x20erro\
    r\x20code.\n\n\r\n\x05\x04\x04\x04\0\x01\x12\x04\xac\x01\x07\x14\n\x20\n\
    \x06\x04\x04\x04\0\x02\0\x12\x04\xae\x01\x04\x1d\x1a\x10\x20Not\x20speci\
    fied.\n\n\x0f\n\x07\x04\x04\x04\0\x02\0\x01\x12\x04\xae\x01\x04\x18\n\
    \x0f\n\x07\x04\x04\x04\0\x02\0\x02\x12\x04\xae\x01\x1b\x1c\nP\n\x06\x04\
    \x04\x04\0\x02\x01\x12\x04\xb1\x01\x04\x11\x1a@\x20Uncompressed\x2016-bi\
    t\x20signed\x20little-endian\x20samples\x20(Linear\x20PCM).\n\n\x0f\n\
    \x07\x04\x04\x04\0\x02\x01\x01\x12\x04\xb1\x01\x04\x0c\n\x0f\n\x07\x04\
    \x04\x04\0\x02\x01\x02\x12\x04\xb1\x01\x0f\x10\n\xc4\x02\n\x06\x04\x04\
    \x04\0\x02\x02\x12\x04\xb9\x01\x04\r\x1a\xb3\x02\x20`FLAC`\x20(Free\x20L\
    ossless\x20Audio\n\x20Codec)\x20is\x20the\x20recommended\x20encoding\x20\
    because\x20it\x20is\n\x20lossless--therefore\x20recognition\x20is\x20not\
    \x20compromised--and\n\x20requires\x20only\x20about\x20half\x20the\x20ba\
    ndwidth\x20of\x20`LINEAR16`.\x20`FLAC`\x20stream\n\x20encoding\x20suppor\
    ts\x2016-bit\x20and\x2024-bit\x20samples,\x20however,\x20not\x20all\x20f\
    ields\x20in\n\x20`STREAMINFO`\x20are\x20supported.\n\n\x0f\n\x07\x04\x04\
    \x04\0\x02\x02\x01\x12\x04\xb9\x01\x04\x08\n\x0f\n\x07\x04\x04\x04\0\x02\
    \x02\x02\x12\x04\xb9\x01\x0b\x0c\nZ\n\x06\x04\x04\x04\0\x02\x03\x12\x04\
    \xbc\x01\x04\x0e\x1aJ\x208-bit\x20samples\x20that\x20compand\x2014-bit\
    \x20audio\x20samples\x20using\x20G.711\x20PCMU/mu-law.\n\n\x0f\n\x07\x04\
    \x04\x04\0\x02\x03\x01\x12\x04\xbc\x01\x04\t\n\x0f\n\x07\x04\x04\x04\0\
    \x02\x03\x02\x12\x04\xbc\x01\x0c\r\nY\n\x06\x04\x04\x04\0\x02\x04\x12\
    \x04\xbf\x01\x04\x0c\x1aI\x20Adaptive\x20Multi-Rate\x20Narrowband\x20cod\
    ec.\x20`sample_rate_hertz`\x20must\x20be\x208000.\n\n\x0f\n\x07\x04\x04\
    \x04\0\x02\x04\x01\x12\x04\xbf\x01\x04\x07\n\x0f\n\x07\x04\x04\x04\0\x02\
    \x04\x02\x12\x04\xbf\x01\n\x0b\nX\n\x06\x04\x04\x04\0\x02\x05\x12\x04\
    \xc2\x01\x04\x0f\x1aH\x20Adaptive\x20Multi-Rate\x20Wideband\x20codec.\
    \x20`sample_rate_hertz`\x20must\x20be\x2016000.\n\n\x0f\n\x07\x04\x04\
    \x04\0\x02\x05\x01\x12\x04\xc2\x01\x04\n\n\x0f\n\x07\x04\x04\x04\0\x02\
    \x05\x02\x12\x04\xc2\x01\r\x0e\n\xb3\x01\n\x06\x04\x04\x04\0\x02\x06\x12\
    \x04\xc7\x01\x04\x11\x1a\xa2\x01\x20Opus\x20encoded\x20audio\x20frames\
    \x20in\x20Ogg\x20container\n\x20([OggOpus](https://wiki.xiph.org/OggOpus\
    )).\n\x20`sample_rate_hertz`\x20must\x20be\x20one\x20of\x208000,\x201200\
    0,\x2016000,\x2024000,\x20or\x2048000.\n\n\x0f\n\x07\x04\x04\x04\0\x02\
    \x06\x01\x12\x04\xc7\x01\x04\x0c\n\x0f\n\x07\x04\x04\x04\0\x02\x06\x02\
    \x12\x04\xc7\x01\x0f\x10\n\xd9\x06\n\x06\x04\x04\x04\0\x02\x07\x12\x04\
    \xd6\x01\x04\x1f\x1a\xc8\x06\x20Although\x20the\x20use\x20of\x20lossy\
    \x20encodings\x20is\x20not\x20recommended,\x20if\x20a\x20very\x20low\n\
    \x20bitrate\x20encoding\x20is\x20required,\x20`OGG_OPUS`\x20is\x20highly\
    \x20preferred\x20over\n\x20Speex\x20encoding.\x20The\x20[Speex](https://\
    speex.org/)\x20\x20encoding\x20supported\x20by\n\x20Cloud\x20Speech\x20A\
    PI\x20has\x20a\x20header\x20byte\x20in\x20each\x20block,\x20as\x20in\x20\
    MIME\x20type\n\x20`audio/x-speex-with-header-byte`.\n\x20It\x20is\x20a\
    \x20variant\x20of\x20the\x20RTP\x20Speex\x20encoding\x20defined\x20in\n\
    \x20[RFC\x205574](https://tools.ietf.org/html/rfc5574).\n\x20The\x20stre\
    am\x20is\x20a\x20sequence\x20of\x20blocks,\x20one\x20block\x20per\x20RTP\
    \x20packet.\x20Each\x20block\n\x20starts\x20with\x20a\x20byte\x20contain\
    ing\x20the\x20length\x20of\x20the\x20block,\x20in\x20bytes,\x20followed\
    \n\x20by\x20one\x20or\x20more\x20frames\x20of\x20Speex\x20data,\x20padde\
    d\x20to\x20an\x20integral\x20number\x20of\n\x20bytes\x20(octets)\x20as\
    \x20specified\x20in\x20RFC\x205574.\x20In\x20other\x20words,\x20each\x20\
    RTP\x20header\n\x20is\x20replaced\x20with\x20a\x20single\x20byte\x20cont\
    aining\x20the\x20block\x20length.\x20Only\x20Speex\n\x20wideband\x20is\
    \x20supported.\x20`sample_rate_hertz`\x20must\x20be\x2016000.\n\n\x0f\n\
    \x07\x04\x04\x04\0\x02\x07\x01\x12\x04\xd6\x01\x04\x1a\n\x0f\n\x07\x04\
    \x04\x04\0\x02\x07\x02\x12\x04\xd6\x01\x1d\x1e\n\x8e\x02\n\x04\x04\x04\
    \x02\0\x12\x04\xdc\x01\x02\x1d\x1a\xff\x01\x20Encoding\x20of\x20audio\
    \x20data\x20sent\x20in\x20all\x20`RecognitionAudio`\x20messages.\n\x20Th\
    is\x20field\x20is\x20optional\x20for\x20`FLAC`\x20and\x20`WAV`\x20audio\
    \x20files\x20and\x20required\n\x20for\x20all\x20other\x20audio\x20format\
    s.\x20For\x20details,\x20see\x20[AudioEncoding][google.cloud.speech.v1.R\
    ecognitionConfig.AudioEncoding].\n\n\r\n\x05\x04\x04\x02\0\x06\x12\x04\
    \xdc\x01\x02\x0f\n\r\n\x05\x04\x04\x02\0\x01\x12\x04\xdc\x01\x10\x18\n\r\
    \n\x05\x04\x04\x02\0\x03\x12\x04\xdc\x01\x1b\x1c\n\xfc\x03\n\x04\x04\x04\
    \x02\x01\x12\x04\xe5\x01\x02\x1e\x1a\xed\x03\x20Sample\x20rate\x20in\x20\
    Hertz\x20of\x20the\x20audio\x20data\x20sent\x20in\x20all\n\x20`Recogniti\
    onAudio`\x20messages.\x20Valid\x20values\x20are:\x208000-48000.\n\x20160\
    00\x20is\x20optimal.\x20For\x20best\x20results,\x20set\x20the\x20samplin\
    g\x20rate\x20of\x20the\x20audio\n\x20source\x20to\x2016000\x20Hz.\x20If\
    \x20that's\x20not\x20possible,\x20use\x20the\x20native\x20sample\x20rate\
    \x20of\n\x20the\x20audio\x20source\x20(instead\x20of\x20re-sampling).\n\
    \x20This\x20field\x20is\x20optional\x20for\x20FLAC\x20and\x20WAV\x20audi\
    o\x20files,\x20but\x20is\n\x20required\x20for\x20all\x20other\x20audio\
    \x20formats.\x20For\x20details,\x20see\x20[AudioEncoding][google.cloud.s\
    peech.v1.RecognitionConfig.AudioEncoding].\n\n\r\n\x05\x04\x04\x02\x01\
    \x05\x12\x04\xe5\x01\x02\x07\n\r\n\x05\x04\x04\x02\x01\x01\x12\x04\xe5\
    \x01\x08\x19\n\r\n\x05\x04\x04\x02\x01\x03\x12\x04\xe5\x01\x1c\x1d\n\xee\
    \x03\n\x04\x04\x04\x02\x02\x12\x04\xf0\x01\x02\x20\x1a\xdf\x03\x20The\
    \x20number\x20of\x20channels\x20in\x20the\x20input\x20audio\x20data.\n\
    \x20ONLY\x20set\x20this\x20for\x20MULTI-CHANNEL\x20recognition.\n\x20Val\
    id\x20values\x20for\x20LINEAR16\x20and\x20FLAC\x20are\x20`1`-`8`.\n\x20V\
    alid\x20values\x20for\x20OGG_OPUS\x20are\x20'1'-'254'.\n\x20Valid\x20val\
    ue\x20for\x20MULAW,\x20AMR,\x20AMR_WB\x20and\x20SPEEX_WITH_HEADER_BYTE\
    \x20is\x20only\x20`1`.\n\x20If\x20`0`\x20or\x20omitted,\x20defaults\x20t\
    o\x20one\x20channel\x20(mono).\n\x20Note:\x20We\x20only\x20recognize\x20\
    the\x20first\x20channel\x20by\x20default.\n\x20To\x20perform\x20independ\
    ent\x20recognition\x20on\x20each\x20channel\x20set\n\x20`enable_separate\
    _recognition_per_channel`\x20to\x20'true'.\n\n\r\n\x05\x04\x04\x02\x02\
    \x05\x12\x04\xf0\x01\x02\x07\n\r\n\x05\x04\x04\x02\x02\x01\x12\x04\xf0\
    \x01\x08\x1b\n\r\n\x05\x04\x04\x02\x02\x03\x12\x04\xf0\x01\x1e\x1f\n\xad\
    \x03\n\x04\x04\x04\x02\x03\x12\x04\xf8\x01\x024\x1a\x9e\x03\x20This\x20n\
    eeds\x20to\x20be\x20set\x20to\x20`true`\x20explicitly\x20and\x20`audio_c\
    hannel_count`\x20>\x201\n\x20to\x20get\x20each\x20channel\x20recognized\
    \x20separately.\x20The\x20recognition\x20result\x20will\n\x20contain\x20\
    a\x20`channel_tag`\x20field\x20to\x20state\x20which\x20channel\x20that\
    \x20result\x20belongs\n\x20to.\x20If\x20this\x20is\x20not\x20true,\x20we\
    \x20will\x20only\x20recognize\x20the\x20first\x20channel.\x20The\n\x20re\
    quest\x20is\x20billed\x20cumulatively\x20for\x20all\x20channels\x20recog\
    nized:\n\x20`audio_channel_count`\x20multiplied\x20by\x20the\x20length\
    \x20of\x20the\x20audio.\n\n\r\n\x05\x04\x04\x02\x03\x05\x12\x04\xf8\x01\
    \x02\x06\n\r\n\x05\x04\x04\x02\x03\x01\x12\x04\xf8\x01\x07.\n\r\n\x05\
    \x04\x04\x02\x03\x03\x12\x04\xf8\x0113\n\xa3\x02\n\x04\x04\x04\x02\x04\
    \x12\x04\x80\x02\x02D\x1a\x94\x02\x20Required.\x20The\x20language\x20of\
    \x20the\x20supplied\x20audio\x20as\x20a\n\x20[BCP-47](https://www.rfc-ed\
    itor.org/rfc/bcp/bcp47.txt)\x20language\x20tag.\n\x20Example:\x20\"en-US\
    \".\n\x20See\x20[Language\n\x20Support](https://cloud.google.com/speech-\
    to-text/docs/languages)\x20for\x20a\x20list\n\x20of\x20the\x20currently\
    \x20supported\x20language\x20codes.\n\n\r\n\x05\x04\x04\x02\x04\x05\x12\
    \x04\x80\x02\x02\x08\n\r\n\x05\x04\x04\x02\x04\x01\x12\x04\x80\x02\t\x16\
    \n\r\n\x05\x04\x04\x02\x04\x03\x12\x04\x80\x02\x19\x1a\n\r\n\x05\x04\x04\
    \x02\x04\x08\x12\x04\x80\x02\x1bC\n\x10\n\x08\x04\x04\x02\x04\x08\x9c\
    \x08\0\x12\x04\x80\x02\x1cB\n\xef\x02\n\x04\x04\x04\x02\x05\x12\x04\x88\
    \x02\x02\x1d\x1a\xe0\x02\x20Maximum\x20number\x20of\x20recognition\x20hy\
    potheses\x20to\x20be\x20returned.\n\x20Specifically,\x20the\x20maximum\
    \x20number\x20of\x20`SpeechRecognitionAlternative`\x20messages\n\x20with\
    in\x20each\x20`SpeechRecognitionResult`.\n\x20The\x20server\x20may\x20re\
    turn\x20fewer\x20than\x20`max_alternatives`.\n\x20Valid\x20values\x20are\
    \x20`0`-`30`.\x20A\x20value\x20of\x20`0`\x20or\x20`1`\x20will\x20return\
    \x20a\x20maximum\x20of\n\x20one.\x20If\x20omitted,\x20will\x20return\x20\
    a\x20maximum\x20of\x20one.\n\n\r\n\x05\x04\x04\x02\x05\x05\x12\x04\x88\
    \x02\x02\x07\n\r\n\x05\x04\x04\x02\x05\x01\x12\x04\x88\x02\x08\x18\n\r\n\
    \x05\x04\x04\x02\x05\x03\x12\x04\x88\x02\x1b\x1c\n\xf4\x01\n\x04\x04\x04\
    \x02\x06\x12\x04\x8e\x02\x02\x1c\x1a\xe5\x01\x20If\x20set\x20to\x20`true\
    `,\x20the\x20server\x20will\x20attempt\x20to\x20filter\x20out\n\x20profa\
    nities,\x20replacing\x20all\x20but\x20the\x20initial\x20character\x20in\
    \x20each\x20filtered\x20word\n\x20with\x20asterisks,\x20e.g.\x20\"f***\"\
    .\x20If\x20set\x20to\x20`false`\x20or\x20omitted,\x20profanities\n\x20wo\
    n't\x20be\x20filtered\x20out.\n\n\r\n\x05\x04\x04\x02\x06\x05\x12\x04\
    \x8e\x02\x02\x06\n\r\n\x05\x04\x04\x02\x06\x01\x12\x04\x8e\x02\x07\x17\n\
    \r\n\x05\x04\x04\x02\x06\x03\x12\x04\x8e\x02\x1a\x1b\n\xff\x01\n\x04\x04\
    \x04\x02\x07\x12\x04\x95\x02\x02-\x1a\xf0\x01\x20Array\x20of\x20[SpeechC\
    ontext][google.cloud.speech.v1.SpeechContext].\n\x20A\x20means\x20to\x20\
    provide\x20context\x20to\x20assist\x20the\x20speech\x20recognition.\x20F\
    or\x20more\n\x20information,\x20see\n\x20[speech\n\x20adaptation](https:\
    //cloud.google.com/speech-to-text/docs/context-strength).\n\n\r\n\x05\
    \x04\x04\x02\x07\x04\x12\x04\x95\x02\x02\n\n\r\n\x05\x04\x04\x02\x07\x06\
    \x12\x04\x95\x02\x0b\x18\n\r\n\x05\x04\x04\x02\x07\x01\x12\x04\x95\x02\
    \x19(\n\r\n\x05\x04\x04\x02\x07\x03\x12\x04\x95\x02+,\n\xde\x01\n\x04\
    \x04\x04\x02\x08\x12\x04\x9b\x02\x02$\x1a\xcf\x01\x20If\x20`true`,\x20th\
    e\x20top\x20result\x20includes\x20a\x20list\x20of\x20words\x20and\n\x20t\
    he\x20start\x20and\x20end\x20time\x20offsets\x20(timestamps)\x20for\x20t\
    hose\x20words.\x20If\n\x20`false`,\x20no\x20word-level\x20time\x20offset\
    \x20information\x20is\x20returned.\x20The\x20default\x20is\n\x20`false`.\
    \n\n\r\n\x05\x04\x04\x02\x08\x05\x12\x04\x9b\x02\x02\x06\n\r\n\x05\x04\
    \x04\x02\x08\x01\x12\x04\x9b\x02\x07\x1f\n\r\n\x05\x04\x04\x02\x08\x03\
    \x12\x04\x9b\x02\"#\n\xb2\x03\n\x04\x04\x04\x02\t\x12\x04\xa4\x02\x02)\
    \x1a\xa3\x03\x20If\x20'true',\x20adds\x20punctuation\x20to\x20recognitio\
    n\x20result\x20hypotheses.\n\x20This\x20feature\x20is\x20only\x20availab\
    le\x20in\x20select\x20languages.\x20Setting\x20this\x20for\n\x20requests\
    \x20in\x20other\x20languages\x20has\x20no\x20effect\x20at\x20all.\n\x20T\
    he\x20default\x20'false'\x20value\x20does\x20not\x20add\x20punctuation\
    \x20to\x20result\x20hypotheses.\n\x20Note:\x20This\x20is\x20currently\
    \x20offered\x20as\x20an\x20experimental\x20service,\x20complimentary\n\
    \x20to\x20all\x20users.\x20In\x20the\x20future\x20this\x20may\x20be\x20e\
    xclusively\x20available\x20as\x20a\n\x20premium\x20feature.\n\n\r\n\x05\
    \x04\x04\x02\t\x05\x12\x04\xa4\x02\x02\x06\n\r\n\x05\x04\x04\x02\t\x01\
    \x12\x04\xa4\x02\x07#\n\r\n\x05\x04\x04\x02\t\x03\x12\x04\xa4\x02&(\n\
    \xab\x04\n\x04\x04\x04\x02\n\x12\x04\xae\x02\x023\x1a\x9c\x04\x20Config\
    \x20to\x20enable\x20speaker\x20diarization\x20and\x20set\x20additional\n\
    \x20parameters\x20to\x20make\x20diarization\x20better\x20suited\x20for\
    \x20your\x20application.\n\x20Note:\x20When\x20this\x20is\x20enabled,\
    \x20we\x20send\x20all\x20the\x20words\x20from\x20the\x20beginning\x20of\
    \x20the\n\x20audio\x20for\x20the\x20top\x20alternative\x20in\x20every\
    \x20consecutive\x20STREAMING\x20responses.\n\x20This\x20is\x20done\x20in\
    \x20order\x20to\x20improve\x20our\x20speaker\x20tags\x20as\x20our\x20mod\
    els\x20learn\x20to\n\x20identify\x20the\x20speakers\x20in\x20the\x20conv\
    ersation\x20over\x20time.\n\x20For\x20non-streaming\x20requests,\x20the\
    \x20diarization\x20results\x20will\x20be\x20provided\x20only\n\x20in\x20\
    the\x20top\x20alternative\x20of\x20the\x20FINAL\x20SpeechRecognitionResu\
    lt.\n\n\r\n\x05\x04\x04\x02\n\x06\x12\x04\xae\x02\x02\x1a\n\r\n\x05\x04\
    \x04\x02\n\x01\x12\x04\xae\x02\x1b-\n\r\n\x05\x04\x04\x02\n\x03\x12\x04\
    \xae\x0202\n0\n\x04\x04\x04\x02\x0b\x12\x04\xb1\x02\x02#\x1a\"\x20Metada\
    ta\x20regarding\x20this\x20request.\n\n\r\n\x05\x04\x04\x02\x0b\x06\x12\
    \x04\xb1\x02\x02\x15\n\r\n\x05\x04\x04\x02\x0b\x01\x12\x04\xb1\x02\x16\
    \x1e\n\r\n\x05\x04\x04\x02\x0b\x03\x12\x04\xb1\x02!\"\n\xba\t\n\x04\x04\
    \x04\x02\x0c\x12\x04\xd3\x02\x02\x14\x1a\xab\t\x20Which\x20model\x20to\
    \x20select\x20for\x20the\x20given\x20request.\x20Select\x20the\x20model\
    \n\x20best\x20suited\x20to\x20your\x20domain\x20to\x20get\x20best\x20res\
    ults.\x20If\x20a\x20model\x20is\x20not\n\x20explicitly\x20specified,\x20\
    then\x20we\x20auto-select\x20a\x20model\x20based\x20on\x20the\x20paramet\
    ers\n\x20in\x20the\x20RecognitionConfig.\n\x20<table>\n\x20\x20\x20<tr>\
    \n\x20\x20\x20\x20\x20<td><b>Model</b></td>\n\x20\x20\x20\x20\x20<td><b>\
    Description</b></td>\n\x20\x20\x20</tr>\n\x20\x20\x20<tr>\n\x20\x20\x20\
    \x20\x20<td><code>command_and_search</code></td>\n\x20\x20\x20\x20\x20<t\
    d>Best\x20for\x20short\x20queries\x20such\x20as\x20voice\x20commands\x20\
    or\x20voice\x20search.</td>\n\x20\x20\x20</tr>\n\x20\x20\x20<tr>\n\x20\
    \x20\x20\x20\x20<td><code>phone_call</code></td>\n\x20\x20\x20\x20\x20<t\
    d>Best\x20for\x20audio\x20that\x20originated\x20from\x20a\x20phone\x20ca\
    ll\x20(typically\n\x20\x20\x20\x20\x20recorded\x20at\x20an\x208khz\x20sa\
    mpling\x20rate).</td>\n\x20\x20\x20</tr>\n\x20\x20\x20<tr>\n\x20\x20\x20\
    \x20\x20<td><code>video</code></td>\n\x20\x20\x20\x20\x20<td>Best\x20for\
    \x20audio\x20that\x20originated\x20from\x20from\x20video\x20or\x20includ\
    es\x20multiple\n\x20\x20\x20\x20\x20\x20\x20\x20\x20speakers.\x20Ideally\
    \x20the\x20audio\x20is\x20recorded\x20at\x20a\x2016khz\x20or\x20greater\
    \n\x20\x20\x20\x20\x20\x20\x20\x20\x20sampling\x20rate.\x20This\x20is\
    \x20a\x20premium\x20model\x20that\x20costs\x20more\x20than\x20the\n\x20\
    \x20\x20\x20\x20\x20\x20\x20\x20standard\x20rate.</td>\n\x20\x20\x20</tr\
    >\n\x20\x20\x20<tr>\n\x20\x20\x20\x20\x20<td><code>default</code></td>\n\
    \x20\x20\x20\x20\x20<td>Best\x20for\x20audio\x20that\x20is\x20not\x20one\
    \x20of\x20the\x20specific\x20audio\x20models.\n\x20\x20\x20\x20\x20\x20\
    \x20\x20\x20For\x20example,\x20long-form\x20audio.\x20Ideally\x20the\x20\
    audio\x20is\x20high-fidelity,\n\x20\x20\x20\x20\x20\x20\x20\x20\x20recor\
    ded\x20at\x20a\x2016khz\x20or\x20greater\x20sampling\x20rate.</td>\n\x20\
    \x20\x20</tr>\n\x20</table>\n\n\r\n\x05\x04\x04\x02\x0c\x05\x12\x04\xd3\
    \x02\x02\x08\n\r\n\x05\x04\x04\x02\x0c\x01\x12\x04\xd3\x02\t\x0e\n\r\n\
    \x05\x04\x04\x02\x0c\x03\x12\x04\xd3\x02\x11\x13\n\x99\x03\n\x04\x04\x04\
    \x02\r\x12\x04\xdd\x02\x02\x19\x1a\x8a\x03\x20Set\x20to\x20true\x20to\
    \x20use\x20an\x20enhanced\x20model\x20for\x20speech\x20recognition.\n\
    \x20If\x20`use_enhanced`\x20is\x20set\x20to\x20true\x20and\x20the\x20`mo\
    del`\x20field\x20is\x20not\x20set,\x20then\n\x20an\x20appropriate\x20enh\
    anced\x20model\x20is\x20chosen\x20if\x20an\x20enhanced\x20model\x20exist\
    s\x20for\n\x20the\x20audio.\n\n\x20If\x20`use_enhanced`\x20is\x20true\
    \x20and\x20an\x20enhanced\x20version\x20of\x20the\x20specified\x20model\
    \n\x20does\x20not\x20exist,\x20then\x20the\x20speech\x20is\x20recognized\
    \x20using\x20the\x20standard\x20version\n\x20of\x20the\x20specified\x20m\
    odel.\n\n\r\n\x05\x04\x04\x02\r\x05\x12\x04\xdd\x02\x02\x06\n\r\n\x05\
    \x04\x04\x02\r\x01\x12\x04\xdd\x02\x07\x13\n\r\n\x05\x04\x04\x02\r\x03\
    \x12\x04\xdd\x02\x16\x18\n5\n\x02\x04\x05\x12\x06\xe1\x02\0\xf4\x02\x01\
    \x1a'\x20Config\x20to\x20enable\x20speaker\x20diarization.\n\n\x0b\n\x03\
    \x04\x05\x01\x12\x04\xe1\x02\x08\x20\n\xaf\x01\n\x04\x04\x05\x02\0\x12\
    \x04\xe5\x02\x02&\x1a\xa0\x01\x20If\x20'true',\x20enables\x20speaker\x20\
    detection\x20for\x20each\x20recognized\x20word\x20in\n\x20the\x20top\x20\
    alternative\x20of\x20the\x20recognition\x20result\x20using\x20a\x20speak\
    er_tag\x20provided\n\x20in\x20the\x20WordInfo.\n\n\r\n\x05\x04\x05\x02\0\
    \x05\x12\x04\xe5\x02\x02\x06\n\r\n\x05\x04\x05\x02\0\x01\x12\x04\xe5\x02\
    \x07!\n\r\n\x05\x04\x05\x02\0\x03\x12\x04\xe5\x02$%\n\xde\x01\n\x04\x04\
    \x05\x02\x01\x12\x04\xea\x02\x02\x1e\x1a\xcf\x01\x20Minimum\x20number\
    \x20of\x20speakers\x20in\x20the\x20conversation.\x20This\x20range\x20giv\
    es\x20you\x20more\n\x20flexibility\x20by\x20allowing\x20the\x20system\
    \x20to\x20automatically\x20determine\x20the\x20correct\n\x20number\x20of\
    \x20speakers.\x20If\x20not\x20set,\x20the\x20default\x20value\x20is\x202\
    .\n\n\r\n\x05\x04\x05\x02\x01\x05\x12\x04\xea\x02\x02\x07\n\r\n\x05\x04\
    \x05\x02\x01\x01\x12\x04\xea\x02\x08\x19\n\r\n\x05\x04\x05\x02\x01\x03\
    \x12\x04\xea\x02\x1c\x1d\n\xde\x01\n\x04\x04\x05\x02\x02\x12\x04\xef\x02\
    \x02\x1e\x1a\xcf\x01\x20Maximum\x20number\x20of\x20speakers\x20in\x20the\
    \x20conversation.\x20This\x20range\x20gives\x20you\x20more\n\x20flexibil\
    ity\x20by\x20allowing\x20the\x20system\x20to\x20automatically\x20determi\
    ne\x20the\x20correct\n\x20number\x20of\x20speakers.\x20If\x20not\x20set,\
    \x20the\x20default\x20value\x20is\x206.\n\n\r\n\x05\x04\x05\x02\x02\x05\
    \x12\x04\xef\x02\x02\x07\n\r\n\x05\x04\x05\x02\x02\x01\x12\x04\xef\x02\
    \x08\x19\n\r\n\x05\x04\x05\x02\x02\x03\x12\x04\xef\x02\x1c\x1d\n\x19\n\
    \x04\x04\x05\x02\x03\x12\x06\xf2\x02\x02\xf3\x02E\x1a\t\x20Unused.\n\n\r\
    \n\x05\x04\x05\x02\x03\x05\x12\x04\xf2\x02\x02\x07\n\r\n\x05\x04\x05\x02\
    \x03\x01\x12\x04\xf2\x02\x08\x13\n\r\n\x05\x04\x05\x02\x03\x03\x12\x04\
    \xf2\x02\x16\x17\n\r\n\x05\x04\x05\x02\x03\x08\x12\x04\xf3\x02\x06D\n\
    \x10\n\x08\x04\x05\x02\x03\x08\x9c\x08\0\x12\x04\xf3\x02\x070\n\x0e\n\
    \x06\x04\x05\x02\x03\x08\x03\x12\x04\xf3\x022C\n;\n\x02\x04\x06\x12\x06\
    \xf7\x02\0\xf3\x03\x01\x1a-\x20Description\x20of\x20audio\x20data\x20to\
    \x20be\x20recognized.\n\n\x0b\n\x03\x04\x06\x01\x12\x04\xf7\x02\x08\x1b\
    \n^\n\x04\x04\x06\x04\0\x12\x06\xfa\x02\x02\x9c\x03\x03\x1aN\x20Use\x20c\
    ase\x20categories\x20that\x20the\x20audio\x20recognition\x20request\x20c\
    an\x20be\x20described\n\x20by.\n\n\r\n\x05\x04\x06\x04\0\x01\x12\x04\xfa\
    \x02\x07\x16\ng\n\x06\x04\x06\x04\0\x02\0\x12\x04\xfd\x02\x04%\x1aW\x20U\
    se\x20case\x20is\x20either\x20unknown\x20or\x20is\x20something\x20other\
    \x20than\x20one\x20of\x20the\x20other\n\x20values\x20below.\n\n\x0f\n\
    \x07\x04\x06\x04\0\x02\0\x01\x12\x04\xfd\x02\x04\x20\n\x0f\n\x07\x04\x06\
    \x04\0\x02\0\x02\x12\x04\xfd\x02#$\n\xec\x01\n\x06\x04\x06\x04\0\x02\x01\
    \x12\x04\x83\x03\x04\x13\x1a\xdb\x01\x20Multiple\x20people\x20in\x20a\
    \x20conversation\x20or\x20discussion.\x20For\x20example\x20in\x20a\n\x20\
    meeting\x20with\x20two\x20or\x20more\x20people\x20actively\x20participat\
    ing.\x20Typically\n\x20all\x20the\x20primary\x20people\x20speaking\x20wo\
    uld\x20be\x20in\x20the\x20same\x20room\x20(if\x20not,\n\x20see\x20PHONE_\
    CALL)\n\n\x0f\n\x07\x04\x06\x04\0\x02\x01\x01\x12\x04\x83\x03\x04\x0e\n\
    \x0f\n\x07\x04\x06\x04\0\x02\x01\x02\x12\x04\x83\x03\x11\x12\n_\n\x06\
    \x04\x06\x04\0\x02\x02\x12\x04\x87\x03\x04\x15\x1aO\x20One\x20or\x20more\
    \x20persons\x20lecturing\x20or\x20presenting\x20to\x20others,\x20mostly\
    \n\x20uninterrupted.\n\n\x0f\n\x07\x04\x06\x04\0\x02\x02\x01\x12\x04\x87\
    \x03\x04\x10\n\x0f\n\x07\x04\x06\x04\0\x02\x02\x02\x12\x04\x87\x03\x13\
    \x14\n\x8a\x01\n\x06\x04\x06\x04\0\x02\x03\x12\x04\x8b\x03\x04\x13\x1az\
    \x20A\x20phone-call\x20or\x20video-conference\x20in\x20which\x20two\x20o\
    r\x20more\x20people,\x20who\x20are\n\x20not\x20in\x20the\x20same\x20room\
    ,\x20are\x20actively\x20participating.\n\n\x0f\n\x07\x04\x06\x04\0\x02\
    \x03\x01\x12\x04\x8b\x03\x04\x0e\n\x0f\n\x07\x04\x06\x04\0\x02\x03\x02\
    \x12\x04\x8b\x03\x11\x12\nN\n\x06\x04\x06\x04\0\x02\x04\x12\x04\x8e\x03\
    \x04\x12\x1a>\x20A\x20recorded\x20message\x20intended\x20for\x20another\
    \x20person\x20to\x20listen\x20to.\n\n\x0f\n\x07\x04\x06\x04\0\x02\x04\
    \x01\x12\x04\x8e\x03\x04\r\n\x0f\n\x07\x04\x06\x04\0\x02\x04\x02\x12\x04\
    \x8e\x03\x10\x11\nG\n\x06\x04\x06\x04\0\x02\x05\x12\x04\x91\x03\x04\x20\
    \x1a7\x20Professionally\x20produced\x20audio\x20(eg.\x20TV\x20Show,\x20P\
    odcast).\n\n\x0f\n\x07\x04\x06\x04\0\x02\x05\x01\x12\x04\x91\x03\x04\x1b\
    \n\x0f\n\x07\x04\x06\x04\0\x02\x05\x02\x12\x04\x91\x03\x1e\x1f\nD\n\x06\
    \x04\x06\x04\0\x02\x06\x12\x04\x94\x03\x04\x15\x1a4\x20Transcribe\x20spo\
    ken\x20questions\x20and\x20queries\x20into\x20text.\n\n\x0f\n\x07\x04\
    \x06\x04\0\x02\x06\x01\x12\x04\x94\x03\x04\x10\n\x0f\n\x07\x04\x06\x04\0\
    \x02\x06\x02\x12\x04\x94\x03\x13\x14\nN\n\x06\x04\x06\x04\0\x02\x07\x12\
    \x04\x97\x03\x04\x16\x1a>\x20Transcribe\x20voice\x20commands,\x20such\
    \x20as\x20for\x20controlling\x20a\x20device.\n\n\x0f\n\x07\x04\x06\x04\0\
    \x02\x07\x01\x12\x04\x97\x03\x04\x11\n\x0f\n\x07\x04\x06\x04\0\x02\x07\
    \x02\x12\x04\x97\x03\x14\x15\ns\n\x06\x04\x06\x04\0\x02\x08\x12\x04\x9b\
    \x03\x04\x12\x1ac\x20Transcribe\x20speech\x20to\x20text\x20to\x20create\
    \x20a\x20written\x20document,\x20such\x20as\x20a\n\x20text-message,\x20e\
    mail\x20or\x20report.\n\n\x0f\n\x07\x04\x06\x04\0\x02\x08\x01\x12\x04\
    \x9b\x03\x04\r\n\x0f\n\x07\x04\x06\x04\0\x02\x08\x02\x12\x04\x9b\x03\x10\
    \x11\nT\n\x04\x04\x06\x04\x01\x12\x06\x9f\x03\x02\xad\x03\x03\x1aD\x20En\
    umerates\x20the\x20types\x20of\x20capture\x20settings\x20describing\x20a\
    n\x20audio\x20file.\n\n\r\n\x05\x04\x06\x04\x01\x01\x12\x04\x9f\x03\x07\
    \x19\n*\n\x06\x04\x06\x04\x01\x02\0\x12\x04\xa1\x03\x04(\x1a\x1a\x20Audi\
    o\x20type\x20is\x20not\x20known.\n\n\x0f\n\x07\x04\x06\x04\x01\x02\0\x01\
    \x12\x04\xa1\x03\x04#\n\x0f\n\x07\x04\x06\x04\x01\x02\0\x02\x12\x04\xa1\
    \x03&'\n\xbc\x01\n\x06\x04\x06\x04\x01\x02\x01\x12\x04\xa6\x03\x04\x12\
    \x1a\xab\x01\x20The\x20audio\x20was\x20captured\x20from\x20a\x20closely\
    \x20placed\x20microphone.\x20Eg.\x20phone,\n\x20dictaphone,\x20or\x20han\
    dheld\x20microphone.\x20Generally\x20if\x20there\x20speaker\x20is\x20wit\
    hin\n\x201\x20meter\x20of\x20the\x20microphone.\n\n\x0f\n\x07\x04\x06\
    \x04\x01\x02\x01\x01\x12\x04\xa6\x03\x04\r\n\x0f\n\x07\x04\x06\x04\x01\
    \x02\x01\x02\x12\x04\xa6\x03\x10\x11\nC\n\x06\x04\x06\x04\x01\x02\x02\
    \x12\x04\xa9\x03\x04\x11\x1a3\x20The\x20speaker\x20if\x20within\x203\x20\
    meters\x20of\x20the\x20microphone.\n\n\x0f\n\x07\x04\x06\x04\x01\x02\x02\
    \x01\x12\x04\xa9\x03\x04\x0c\n\x0f\n\x07\x04\x06\x04\x01\x02\x02\x02\x12\
    \x04\xa9\x03\x0f\x10\nM\n\x06\x04\x06\x04\x01\x02\x03\x12\x04\xac\x03\
    \x04\x11\x1a=\x20The\x20speaker\x20is\x20more\x20than\x203\x20meters\x20\
    away\x20from\x20the\x20microphone.\n\n\x0f\n\x07\x04\x06\x04\x01\x02\x03\
    \x01\x12\x04\xac\x03\x04\x0c\n\x0f\n\x07\x04\x06\x04\x01\x02\x03\x02\x12\
    \x04\xac\x03\x0f\x10\n@\n\x04\x04\x06\x04\x02\x12\x06\xb0\x03\x02\xb9\
    \x03\x03\x1a0\x20The\x20original\x20media\x20the\x20speech\x20was\x20rec\
    orded\x20on.\n\n\r\n\x05\x04\x06\x04\x02\x01\x12\x04\xb0\x03\x07\x18\n.\
    \n\x06\x04\x06\x04\x02\x02\0\x12\x04\xb2\x03\x04(\x1a\x1e\x20Unknown\x20\
    original\x20media\x20type.\n\n\x0f\n\x07\x04\x06\x04\x02\x02\0\x01\x12\
    \x04\xb2\x03\x04#\n\x0f\n\x07\x04\x06\x04\x02\x02\0\x02\x12\x04\xb2\x03&\
    '\n8\n\x06\x04\x06\x04\x02\x02\x01\x12\x04\xb5\x03\x04\x0e\x1a(\x20The\
    \x20speech\x20data\x20is\x20an\x20audio\x20recording.\n\n\x0f\n\x07\x04\
    \x06\x04\x02\x02\x01\x01\x12\x04\xb5\x03\x04\t\n\x0f\n\x07\x04\x06\x04\
    \x02\x02\x01\x02\x12\x04\xb5\x03\x0c\r\nA\n\x06\x04\x06\x04\x02\x02\x02\
    \x12\x04\xb8\x03\x04\x0e\x1a1\x20The\x20speech\x20data\x20originally\x20\
    recorded\x20on\x20a\x20video.\n\n\x0f\n\x07\x04\x06\x04\x02\x02\x02\x01\
    \x12\x04\xb8\x03\x04\t\n\x0f\n\x07\x04\x06\x04\x02\x02\x02\x02\x12\x04\
    \xb8\x03\x0c\r\nB\n\x04\x04\x06\x04\x03\x12\x06\xbc\x03\x02\xd1\x03\x03\
    \x1a2\x20The\x20type\x20of\x20device\x20the\x20speech\x20was\x20recorded\
    \x20with.\n\n\r\n\x05\x04\x06\x04\x03\x01\x12\x04\xbc\x03\x07\x1a\n2\n\
    \x06\x04\x06\x04\x03\x02\0\x12\x04\xbe\x03\x04*\x1a\"\x20The\x20recordin\
    g\x20device\x20is\x20unknown.\n\n\x0f\n\x07\x04\x06\x04\x03\x02\0\x01\
    \x12\x04\xbe\x03\x04%\n\x0f\n\x07\x04\x06\x04\x03\x02\0\x02\x12\x04\xbe\
    \x03()\n6\n\x06\x04\x06\x04\x03\x02\x01\x12\x04\xc1\x03\x04\x13\x1a&\x20\
    Speech\x20was\x20recorded\x20on\x20a\x20smartphone.\n\n\x0f\n\x07\x04\
    \x06\x04\x03\x02\x01\x01\x12\x04\xc1\x03\x04\x0e\n\x0f\n\x07\x04\x06\x04\
    \x03\x02\x01\x02\x12\x04\xc1\x03\x11\x12\nJ\n\x06\x04\x06\x04\x03\x02\
    \x02\x12\x04\xc4\x03\x04\x0b\x1a:\x20Speech\x20was\x20recorded\x20using\
    \x20a\x20personal\x20computer\x20or\x20tablet.\n\n\x0f\n\x07\x04\x06\x04\
    \x03\x02\x02\x01\x12\x04\xc4\x03\x04\x06\n\x0f\n\x07\x04\x06\x04\x03\x02\
    \x02\x02\x12\x04\xc4\x03\t\n\n8\n\x06\x04\x06\x04\x03\x02\x03\x12\x04\
    \xc7\x03\x04\x13\x1a(\x20Speech\x20was\x20recorded\x20over\x20a\x20phone\
    \x20line.\n\n\x0f\n\x07\x04\x06\x04\x03\x02\x03\x01\x12\x04\xc7\x03\x04\
    \x0e\n\x0f\n\x07\x04\x06\x04\x03\x02\x03\x02\x12\x04\xc7\x03\x11\x12\n3\
    \n\x06\x04\x06\x04\x03\x02\x04\x12\x04\xca\x03\x04\x10\x1a#\x20Speech\
    \x20was\x20recorded\x20in\x20a\x20vehicle.\n\n\x0f\n\x07\x04\x06\x04\x03\
    \x02\x04\x01\x12\x04\xca\x03\x04\x0b\n\x0f\n\x07\x04\x06\x04\x03\x02\x04\
    \x02\x12\x04\xca\x03\x0e\x0f\n/\n\x06\x04\x06\x04\x03\x02\x05\x12\x04\
    \xcd\x03\x04\x1d\x1a\x1f\x20Speech\x20was\x20recorded\x20outdoors.\n\n\
    \x0f\n\x07\x04\x06\x04\x03\x02\x05\x01\x12\x04\xcd\x03\x04\x18\n\x0f\n\
    \x07\x04\x06\x04\x03\x02\x05\x02\x12\x04\xcd\x03\x1b\x1c\n.\n\x06\x04\
    \x06\x04\x03\x02\x06\x12\x04\xd0\x03\x04\x1c\x1a\x1e\x20Speech\x20was\
    \x20recorded\x20indoors.\n\n\x0f\n\x07\x04\x06\x04\x03\x02\x06\x01\x12\
    \x04\xd0\x03\x04\x17\n\x0f\n\x07\x04\x06\x04\x03\x02\x06\x02\x12\x04\xd0\
    \x03\x1a\x1b\nX\n\x04\x04\x06\x02\0\x12\x04\xd4\x03\x02'\x1aJ\x20The\x20\
    use\x20case\x20most\x20closely\x20describing\x20the\x20audio\x20content\
    \x20to\x20be\x20recognized.\n\n\r\n\x05\x04\x06\x02\0\x06\x12\x04\xd4\
    \x03\x02\x11\n\r\n\x05\x04\x06\x02\0\x01\x12\x04\xd4\x03\x12\"\n\r\n\x05\
    \x04\x06\x02\0\x03\x12\x04\xd4\x03%&\n\x89\x02\n\x04\x04\x06\x02\x01\x12\
    \x04\xda\x03\x02*\x1a\xfa\x01\x20The\x20industry\x20vertical\x20to\x20wh\
    ich\x20this\x20speech\x20recognition\x20request\x20most\n\x20closely\x20\
    applies.\x20This\x20is\x20most\x20indicative\x20of\x20the\x20topics\x20c\
    ontained\n\x20in\x20the\x20audio.\x20\x20Use\x20the\x206-digit\x20NAICS\
    \x20code\x20to\x20identify\x20the\x20industry\n\x20vertical\x20-\x20see\
    \x20https://www.naics.com/search/.\n\n\r\n\x05\x04\x06\x02\x01\x05\x12\
    \x04\xda\x03\x02\x08\n\r\n\x05\x04\x06\x02\x01\x01\x12\x04\xda\x03\t%\n\
    \r\n\x05\x04\x06\x02\x01\x03\x12\x04\xda\x03()\nV\n\x04\x04\x06\x02\x02\
    \x12\x04\xdd\x03\x02-\x1aH\x20The\x20audio\x20type\x20that\x20most\x20cl\
    osely\x20describes\x20the\x20audio\x20being\x20recognized.\n\n\r\n\x05\
    \x04\x06\x02\x02\x06\x12\x04\xdd\x03\x02\x14\n\r\n\x05\x04\x06\x02\x02\
    \x01\x12\x04\xdd\x03\x15(\n\r\n\x05\x04\x06\x02\x02\x03\x12\x04\xdd\x03+\
    ,\n>\n\x04\x04\x06\x02\x03\x12\x04\xe0\x03\x02,\x1a0\x20The\x20original\
    \x20media\x20the\x20speech\x20was\x20recorded\x20on.\n\n\r\n\x05\x04\x06\
    \x02\x03\x06\x12\x04\xe0\x03\x02\x13\n\r\n\x05\x04\x06\x02\x03\x01\x12\
    \x04\xe0\x03\x14'\n\r\n\x05\x04\x06\x02\x03\x03\x12\x04\xe0\x03*+\n@\n\
    \x04\x04\x06\x02\x04\x12\x04\xe3\x03\x020\x1a2\x20The\x20type\x20of\x20d\
    evice\x20the\x20speech\x20was\x20recorded\x20with.\n\n\r\n\x05\x04\x06\
    \x02\x04\x06\x12\x04\xe3\x03\x02\x15\n\r\n\x05\x04\x06\x02\x04\x01\x12\
    \x04\xe3\x03\x16+\n\r\n\x05\x04\x06\x02\x04\x03\x12\x04\xe3\x03./\n\x9e\
    \x01\n\x04\x04\x06\x02\x05\x12\x04\xe8\x03\x02#\x1a\x8f\x01\x20The\x20de\
    vice\x20used\x20to\x20make\x20the\x20recording.\x20\x20Examples\x20'Nexu\
    s\x205X'\x20or\n\x20'Polycom\x20SoundStation\x20IP\x206000'\x20or\x20'PO\
    TS'\x20or\x20'VoIP'\x20or\n\x20'Cardioid\x20Microphone'.\n\n\r\n\x05\x04\
    \x06\x02\x05\x05\x12\x04\xe8\x03\x02\x08\n\r\n\x05\x04\x06\x02\x05\x01\
    \x12\x04\xe8\x03\t\x1e\n\r\n\x05\x04\x06\x02\x05\x03\x12\x04\xe8\x03!\"\
    \n\xfd\x01\n\x04\x04\x06\x02\x06\x12\x04\xee\x03\x02\x20\x1a\xee\x01\x20\
    Mime\x20type\x20of\x20the\x20original\x20audio\x20file.\x20\x20For\x20ex\
    ample\x20`audio/m4a`,\n\x20`audio/x-alaw-basic`,\x20`audio/mp3`,\x20`aud\
    io/3gpp`.\n\x20A\x20list\x20of\x20possible\x20audio\x20mime\x20types\x20\
    is\x20maintained\x20at\n\x20http://www.iana.org/assignments/media-types/\
    media-types.xhtml#audio\n\n\r\n\x05\x04\x06\x02\x06\x05\x12\x04\xee\x03\
    \x02\x08\n\r\n\x05\x04\x06\x02\x06\x01\x12\x04\xee\x03\t\x1b\n\r\n\x05\
    \x04\x06\x02\x06\x03\x12\x04\xee\x03\x1e\x1f\nj\n\x04\x04\x06\x02\x07\
    \x12\x04\xf2\x03\x02\x1a\x1a\\\x20Description\x20of\x20the\x20content.\
    \x20Eg.\x20\"Recordings\x20of\x20federal\x20supreme\x20court\n\x20hearin\
    gs\x20from\x202012\".\n\n\r\n\x05\x04\x06\x02\x07\x05\x12\x04\xf2\x03\
    \x02\x08\n\r\n\x05\x04\x06\x02\x07\x01\x12\x04\xf2\x03\t\x14\n\r\n\x05\
    \x04\x06\x02\x07\x03\x12\x04\xf2\x03\x17\x19\nn\n\x02\x04\x07\x12\x06\
    \xf7\x03\0\x85\x04\x01\x1a`\x20Provides\x20\"hints\"\x20to\x20the\x20spe\
    ech\x20recognizer\x20to\x20favor\x20specific\x20words\x20and\x20phrases\
    \n\x20in\x20the\x20results.\n\n\x0b\n\x03\x04\x07\x01\x12\x04\xf7\x03\
    \x08\x15\n\xea\x05\n\x04\x04\x07\x02\0\x12\x04\x84\x04\x02\x1e\x1a\xdb\
    \x05\x20A\x20list\x20of\x20strings\x20containing\x20words\x20and\x20phra\
    ses\x20\"hints\"\x20so\x20that\n\x20the\x20speech\x20recognition\x20is\
    \x20more\x20likely\x20to\x20recognize\x20them.\x20This\x20can\x20be\x20u\
    sed\n\x20to\x20improve\x20the\x20accuracy\x20for\x20specific\x20words\
    \x20and\x20phrases,\x20for\x20example,\x20if\n\x20specific\x20commands\
    \x20are\x20typically\x20spoken\x20by\x20the\x20user.\x20This\x20can\x20a\
    lso\x20be\x20used\n\x20to\x20add\x20additional\x20words\x20to\x20the\x20\
    vocabulary\x20of\x20the\x20recognizer.\x20See\n\x20[usage\x20limits](htt\
    ps://cloud.google.com/speech-to-text/quotas#content).\n\n\x20List\x20ite\
    ms\x20can\x20also\x20be\x20set\x20to\x20classes\x20for\x20groups\x20of\
    \x20words\x20that\x20represent\n\x20common\x20concepts\x20that\x20occur\
    \x20in\x20natural\x20language.\x20For\x20example,\x20rather\x20than\n\
    \x20providing\x20phrase\x20hints\x20for\x20every\x20month\x20of\x20the\
    \x20year,\x20using\x20the\x20$MONTH\x20class\n\x20improves\x20the\x20lik\
    elihood\x20of\x20correctly\x20transcribing\x20audio\x20that\x20includes\
    \n\x20months.\n\n\r\n\x05\x04\x07\x02\0\x04\x12\x04\x84\x04\x02\n\n\r\n\
    \x05\x04\x07\x02\0\x05\x12\x04\x84\x04\x0b\x11\n\r\n\x05\x04\x07\x02\0\
    \x01\x12\x04\x84\x04\x12\x19\n\r\n\x05\x04\x07\x02\0\x03\x12\x04\x84\x04\
    \x1c\x1d\n\xbf\x02\n\x02\x04\x08\x12\x06\x8b\x04\0\x9d\x04\x01\x1a\xb0\
    \x02\x20Contains\x20audio\x20data\x20in\x20the\x20encoding\x20specified\
    \x20in\x20the\x20`RecognitionConfig`.\n\x20Either\x20`content`\x20or\x20\
    `uri`\x20must\x20be\x20supplied.\x20Supplying\x20both\x20or\x20neither\n\
    \x20returns\x20[google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALI\
    D_ARGUMENT].\x20See\n\x20[content\x20limits](https://cloud.google.com/sp\
    eech-to-text/quotas#content).\n\n\x0b\n\x03\x04\x08\x01\x12\x04\x8b\x04\
    \x08\x18\nb\n\x04\x04\x08\x08\0\x12\x06\x8e\x04\x02\x9c\x04\x03\x1aR\x20\
    The\x20audio\x20source,\x20which\x20is\x20either\x20inline\x20content\
    \x20or\x20a\x20Google\x20Cloud\n\x20Storage\x20uri.\n\n\r\n\x05\x04\x08\
    \x08\0\x01\x12\x04\x8e\x04\x08\x14\n\xcd\x01\n\x04\x04\x08\x02\0\x12\x04\
    \x92\x04\x04\x16\x1a\xbe\x01\x20The\x20audio\x20data\x20bytes\x20encoded\
    \x20as\x20specified\x20in\n\x20`RecognitionConfig`.\x20Note:\x20as\x20wi\
    th\x20all\x20bytes\x20fields,\x20proto\x20buffers\x20use\x20a\n\x20pure\
    \x20binary\x20representation,\x20whereas\x20JSON\x20representations\x20u\
    se\x20base64.\n\n\r\n\x05\x04\x08\x02\0\x05\x12\x04\x92\x04\x04\t\n\r\n\
    \x05\x04\x08\x02\0\x01\x12\x04\x92\x04\n\x11\n\r\n\x05\x04\x08\x02\0\x03\
    \x12\x04\x92\x04\x14\x15\n\xf3\x03\n\x04\x04\x08\x02\x01\x12\x04\x9b\x04\
    \x04\x13\x1a\xe4\x03\x20URI\x20that\x20points\x20to\x20a\x20file\x20that\
    \x20contains\x20audio\x20data\x20bytes\x20as\x20specified\x20in\n\x20`Re\
    cognitionConfig`.\x20The\x20file\x20must\x20not\x20be\x20compressed\x20(\
    for\x20example,\x20gzip).\n\x20Currently,\x20only\x20Google\x20Cloud\x20\
    Storage\x20URIs\x20are\n\x20supported,\x20which\x20must\x20be\x20specifi\
    ed\x20in\x20the\x20following\x20format:\n\x20`gs://bucket_name/object_na\
    me`\x20(other\x20URI\x20formats\x20return\n\x20[google.rpc.Code.INVALID_\
    ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]).\x20For\x20more\x20informat\
    ion,\x20see\n\x20[Request\x20URIs](https://cloud.google.com/storage/docs\
    /reference-uris).\n\n\r\n\x05\x04\x08\x02\x01\x05\x12\x04\x9b\x04\x04\n\
    \n\r\n\x05\x04\x08\x02\x01\x01\x12\x04\x9b\x04\x0b\x0e\n\r\n\x05\x04\x08\
    \x02\x01\x03\x12\x04\x9b\x04\x11\x12\n\xab\x01\n\x02\x04\t\x12\x06\xa2\
    \x04\0\xa6\x04\x01\x1a\x9c\x01\x20The\x20only\x20message\x20returned\x20\
    to\x20the\x20client\x20by\x20the\x20`Recognize`\x20method.\x20It\n\x20co\
    ntains\x20the\x20result\x20as\x20zero\x20or\x20more\x20sequential\x20`Sp\
    eechRecognitionResult`\n\x20messages.\n\n\x0b\n\x03\x04\t\x01\x12\x04\
    \xa2\x04\x08\x19\nh\n\x04\x04\t\x02\0\x12\x04\xa5\x04\x02/\x1aZ\x20Seque\
    ntial\x20list\x20of\x20transcription\x20results\x20corresponding\x20to\n\
    \x20sequential\x20portions\x20of\x20audio.\n\n\r\n\x05\x04\t\x02\0\x04\
    \x12\x04\xa5\x04\x02\n\n\r\n\x05\x04\t\x02\0\x06\x12\x04\xa5\x04\x0b\"\n\
    \r\n\x05\x04\t\x02\0\x01\x12\x04\xa5\x04#*\n\r\n\x05\x04\t\x02\0\x03\x12\
    \x04\xa5\x04-.\n\xcf\x02\n\x02\x04\n\x12\x06\xad\x04\0\xb1\x04\x01\x1a\
    \xc0\x02\x20The\x20only\x20message\x20returned\x20to\x20the\x20client\
    \x20by\x20the\x20`LongRunningRecognize`\x20method.\n\x20It\x20contains\
    \x20the\x20result\x20as\x20zero\x20or\x20more\x20sequential\x20`SpeechRe\
    cognitionResult`\n\x20messages.\x20It\x20is\x20included\x20in\x20the\x20\
    `result.response`\x20field\x20of\x20the\x20`Operation`\n\x20returned\x20\
    by\x20the\x20`GetOperation`\x20call\x20of\x20the\x20`google::longrunning\
    ::Operations`\n\x20service.\n\n\x0b\n\x03\x04\n\x01\x12\x04\xad\x04\x08$\
    \nh\n\x04\x04\n\x02\0\x12\x04\xb0\x04\x02/\x1aZ\x20Sequential\x20list\
    \x20of\x20transcription\x20results\x20corresponding\x20to\n\x20sequentia\
    l\x20portions\x20of\x20audio.\n\n\r\n\x05\x04\n\x02\0\x04\x12\x04\xb0\
    \x04\x02\n\n\r\n\x05\x04\n\x02\0\x06\x12\x04\xb0\x04\x0b\"\n\r\n\x05\x04\
    \n\x02\0\x01\x12\x04\xb0\x04#*\n\r\n\x05\x04\n\x02\0\x03\x12\x04\xb0\x04\
    -.\n\xe8\x01\n\x02\x04\x0b\x12\x06\xb6\x04\0\xc0\x04\x01\x1a\xd9\x01\x20\
    Describes\x20the\x20progress\x20of\x20a\x20long-running\x20`LongRunningR\
    ecognize`\x20call.\x20It\x20is\n\x20included\x20in\x20the\x20`metadata`\
    \x20field\x20of\x20the\x20`Operation`\x20returned\x20by\x20the\n\x20`Get\
    Operation`\x20call\x20of\x20the\x20`google::longrunning::Operations`\x20\
    service.\n\n\x0b\n\x03\x04\x0b\x01\x12\x04\xb6\x04\x08$\n\x9b\x01\n\x04\
    \x04\x0b\x02\0\x12\x04\xb9\x04\x02\x1d\x1a\x8c\x01\x20Approximate\x20per\
    centage\x20of\x20audio\x20processed\x20thus\x20far.\x20Guaranteed\x20to\
    \x20be\x20100\n\x20when\x20the\x20audio\x20is\x20fully\x20processed\x20a\
    nd\x20the\x20results\x20are\x20available.\n\n\r\n\x05\x04\x0b\x02\0\x05\
    \x12\x04\xb9\x04\x02\x07\n\r\n\x05\x04\x0b\x02\0\x01\x12\x04\xb9\x04\x08\
    \x18\n\r\n\x05\x04\x0b\x02\0\x03\x12\x04\xb9\x04\x1b\x1c\n3\n\x04\x04\
    \x0b\x02\x01\x12\x04\xbc\x04\x02+\x1a%\x20Time\x20when\x20the\x20request\
    \x20was\x20received.\n\n\r\n\x05\x04\x0b\x02\x01\x06\x12\x04\xbc\x04\x02\
    \x1b\n\r\n\x05\x04\x0b\x02\x01\x01\x12\x04\xbc\x04\x1c&\n\r\n\x05\x04\
    \x0b\x02\x01\x03\x12\x04\xbc\x04)*\n:\n\x04\x04\x0b\x02\x02\x12\x04\xbf\
    \x04\x021\x1a,\x20Time\x20of\x20the\x20most\x20recent\x20processing\x20u\
    pdate.\n\n\r\n\x05\x04\x0b\x02\x02\x06\x12\x04\xbf\x04\x02\x1b\n\r\n\x05\
    \x04\x0b\x02\x02\x01\x12\x04\xbf\x04\x1c,\n\r\n\x05\x04\x0b\x02\x02\x03\
    \x12\x04\xbf\x04/0\n\x81\x11\n\x02\x04\x0c\x12\x06\xf3\x04\0\x8f\x05\x01\
    \x1a\xf2\x10\x20`StreamingRecognizeResponse`\x20is\x20the\x20only\x20mes\
    sage\x20returned\x20to\x20the\x20client\x20by\n\x20`StreamingRecognize`.\
    \x20A\x20series\x20of\x20zero\x20or\x20more\x20`StreamingRecognizeRespon\
    se`\n\x20messages\x20are\x20streamed\x20back\x20to\x20the\x20client.\x20\
    If\x20there\x20is\x20no\x20recognizable\n\x20audio,\x20and\x20`single_ut\
    terance`\x20is\x20set\x20to\x20false,\x20then\x20no\x20messages\x20are\
    \x20streamed\n\x20back\x20to\x20the\x20client.\n\n\x20Here's\x20an\x20ex\
    ample\x20of\x20a\x20series\x20of\x20ten\x20`StreamingRecognizeResponse`s\
    \x20that\x20might\n\x20be\x20returned\x20while\x20processing\x20audio:\n\
    \n\x201.\x20results\x20{\x20alternatives\x20{\x20transcript:\x20\"tube\"\
    \x20}\x20stability:\x200.01\x20}\n\n\x202.\x20results\x20{\x20alternativ\
    es\x20{\x20transcript:\x20\"to\x20be\x20a\"\x20}\x20stability:\x200.01\
    \x20}\n\n\x203.\x20results\x20{\x20alternatives\x20{\x20transcript:\x20\
    \"to\x20be\"\x20}\x20stability:\x200.9\x20}\n\x20\x20\x20\x20results\x20\
    {\x20alternatives\x20{\x20transcript:\x20\"\x20or\x20not\x20to\x20be\"\
    \x20}\x20stability:\x200.01\x20}\n\n\x204.\x20results\x20{\x20alternativ\
    es\x20{\x20transcript:\x20\"to\x20be\x20or\x20not\x20to\x20be\"\n\x20\
    \x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\
    \x20\x20\x20\x20\x20\x20\x20\x20\x20\x20confidence:\x200.92\x20}\n\x20\
    \x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20alternatives\x20{\
    \x20transcript:\x20\"to\x20bee\x20or\x20not\x20to\x20bee\"\x20}\n\x20\
    \x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20is_final:\x20true\
    \x20}\n\n\x205.\x20results\x20{\x20alternatives\x20{\x20transcript:\x20\
    \"\x20that's\"\x20}\x20stability:\x200.01\x20}\n\n\x206.\x20results\x20{\
    \x20alternatives\x20{\x20transcript:\x20\"\x20that\x20is\"\x20}\x20stabi\
    lity:\x200.9\x20}\n\x20\x20\x20\x20results\x20{\x20alternatives\x20{\x20\
    transcript:\x20\"\x20the\x20question\"\x20}\x20stability:\x200.01\x20}\n\
    \n\x207.\x20results\x20{\x20alternatives\x20{\x20transcript:\x20\"\x20th\
    at\x20is\x20the\x20question\"\n\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\
    \x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\
    \x20confidence:\x200.98\x20}\n\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\
    \x20\x20\x20\x20alternatives\x20{\x20transcript:\x20\"\x20that\x20was\
    \x20the\x20question\"\x20}\n\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\
    \x20\x20\x20is_final:\x20true\x20}\n\n\x20Notes:\n\n\x20-\x20Only\x20two\
    \x20of\x20the\x20above\x20responses\x20#4\x20and\x20#7\x20contain\x20fin\
    al\x20results;\x20they\x20are\n\x20\x20\x20indicated\x20by\x20`is_final:\
    \x20true`.\x20Concatenating\x20these\x20together\x20generates\x20the\n\
    \x20\x20\x20full\x20transcript:\x20\"to\x20be\x20or\x20not\x20to\x20be\
    \x20that\x20is\x20the\x20question\".\n\n\x20-\x20The\x20others\x20contai\
    n\x20interim\x20`results`.\x20#3\x20and\x20#6\x20contain\x20two\x20inter\
    im\n\x20\x20\x20`results`:\x20the\x20first\x20portion\x20has\x20a\x20hig\
    h\x20stability\x20and\x20is\x20less\x20likely\x20to\n\x20\x20\x20change;\
    \x20the\x20second\x20portion\x20has\x20a\x20low\x20stability\x20and\x20i\
    s\x20very\x20likely\x20to\n\x20\x20\x20change.\x20A\x20UI\x20designer\
    \x20might\x20choose\x20to\x20show\x20only\x20high\x20stability\x20`resul\
    ts`.\n\n\x20-\x20The\x20specific\x20`stability`\x20and\x20`confidence`\
    \x20values\x20shown\x20above\x20are\x20only\x20for\n\x20\x20\x20illustra\
    tive\x20purposes.\x20Actual\x20values\x20may\x20vary.\n\n\x20-\x20In\x20\
    each\x20response,\x20only\x20one\x20of\x20these\x20fields\x20will\x20be\
    \x20set:\n\x20\x20\x20\x20\x20`error`,\n\x20\x20\x20\x20\x20`speech_even\
    t_type`,\x20or\n\x20\x20\x20\x20\x20one\x20or\x20more\x20(repeated)\x20`\
    results`.\n\n\x0b\n\x03\x04\x0c\x01\x12\x04\xf3\x04\x08\"\n5\n\x04\x04\
    \x0c\x04\0\x12\x06\xf5\x04\x02\x81\x05\x03\x1a%\x20Indicates\x20the\x20t\
    ype\x20of\x20speech\x20event.\n\n\r\n\x05\x04\x0c\x04\0\x01\x12\x04\xf5\
    \x04\x07\x16\n,\n\x06\x04\x0c\x04\0\x02\0\x12\x04\xf7\x04\x04!\x1a\x1c\
    \x20No\x20speech\x20event\x20specified.\n\n\x0f\n\x07\x04\x0c\x04\0\x02\
    \0\x01\x12\x04\xf7\x04\x04\x1c\n\x0f\n\x07\x04\x0c\x04\0\x02\0\x02\x12\
    \x04\xf7\x04\x1f\x20\n\x88\x04\n\x06\x04\x0c\x04\0\x02\x01\x12\x04\x80\
    \x05\x04\x20\x1a\xf7\x03\x20This\x20event\x20indicates\x20that\x20the\
    \x20server\x20has\x20detected\x20the\x20end\x20of\x20the\x20user's\n\x20\
    speech\x20utterance\x20and\x20expects\x20no\x20additional\x20speech.\x20\
    Therefore,\x20the\x20server\n\x20will\x20not\x20process\x20additional\
    \x20audio\x20(although\x20it\x20may\x20subsequently\x20return\n\x20addit\
    ional\x20results).\x20The\x20client\x20should\x20stop\x20sending\x20addi\
    tional\x20audio\n\x20data,\x20half-close\x20the\x20gRPC\x20connection,\
    \x20and\x20wait\x20for\x20any\x20additional\x20results\n\x20until\x20the\
    \x20server\x20closes\x20the\x20gRPC\x20connection.\x20This\x20event\x20i\
    s\x20only\x20sent\x20if\n\x20`single_utterance`\x20was\x20set\x20to\x20`\
    true`,\x20and\x20is\x20not\x20used\x20otherwise.\n\n\x0f\n\x07\x04\x0c\
    \x04\0\x02\x01\x01\x12\x04\x80\x05\x04\x1b\n\x0f\n\x07\x04\x0c\x04\0\x02\
    \x01\x02\x12\x04\x80\x05\x1e\x1f\n}\n\x04\x04\x0c\x02\0\x12\x04\x85\x05\
    \x02\x1e\x1ao\x20If\x20set,\x20returns\x20a\x20[google.rpc.Status][googl\
    e.rpc.Status]\x20message\x20that\n\x20specifies\x20the\x20error\x20for\
    \x20the\x20operation.\n\n\r\n\x05\x04\x0c\x02\0\x06\x12\x04\x85\x05\x02\
    \x13\n\r\n\x05\x04\x0c\x02\0\x01\x12\x04\x85\x05\x14\x19\n\r\n\x05\x04\
    \x0c\x02\0\x03\x12\x04\x85\x05\x1c\x1d\n\xa9\x02\n\x04\x04\x0c\x02\x01\
    \x12\x04\x8b\x05\x022\x1a\x9a\x02\x20This\x20repeated\x20list\x20contain\
    s\x20zero\x20or\x20more\x20results\x20that\n\x20correspond\x20to\x20cons\
    ecutive\x20portions\x20of\x20the\x20audio\x20currently\x20being\x20proce\
    ssed.\n\x20It\x20contains\x20zero\x20or\x20one\x20`is_final=true`\x20res\
    ult\x20(the\x20newly\x20settled\x20portion),\n\x20followed\x20by\x20zero\
    \x20or\x20more\x20`is_final=false`\x20results\x20(the\x20interim\x20resu\
    lts).\n\n\r\n\x05\x04\x0c\x02\x01\x04\x12\x04\x8b\x05\x02\n\n\r\n\x05\
    \x04\x0c\x02\x01\x06\x12\x04\x8b\x05\x0b%\n\r\n\x05\x04\x0c\x02\x01\x01\
    \x12\x04\x8b\x05&-\n\r\n\x05\x04\x0c\x02\x01\x03\x12\x04\x8b\x0501\n3\n\
    \x04\x04\x0c\x02\x02\x12\x04\x8e\x05\x02(\x1a%\x20Indicates\x20the\x20ty\
    pe\x20of\x20speech\x20event.\n\n\r\n\x05\x04\x0c\x02\x02\x06\x12\x04\x8e\
    \x05\x02\x11\n\r\n\x05\x04\x0c\x02\x02\x01\x12\x04\x8e\x05\x12#\n\r\n\
    \x05\x04\x0c\x02\x02\x03\x12\x04\x8e\x05&'\n\x81\x01\n\x02\x04\r\x12\x06\
    \x93\x05\0\xb6\x05\x01\x1as\x20A\x20streaming\x20speech\x20recognition\
    \x20result\x20corresponding\x20to\x20a\x20portion\x20of\x20the\x20audio\
    \n\x20that\x20is\x20currently\x20being\x20processed.\n\n\x0b\n\x03\x04\r\
    \x01\x12\x04\x93\x05\x08\"\n\x83\x02\n\x04\x04\r\x02\0\x12\x04\x98\x05\
    \x029\x1a\xf4\x01\x20May\x20contain\x20one\x20or\x20more\x20recognition\
    \x20hypotheses\x20(up\x20to\x20the\n\x20maximum\x20specified\x20in\x20`m\
    ax_alternatives`).\n\x20These\x20alternatives\x20are\x20ordered\x20in\
    \x20terms\x20of\x20accuracy,\x20with\x20the\x20top\x20(first)\n\x20alter\
    native\x20being\x20the\x20most\x20probable,\x20as\x20ranked\x20by\x20the\
    \x20recognizer.\n\n\r\n\x05\x04\r\x02\0\x04\x12\x04\x98\x05\x02\n\n\r\n\
    \x05\x04\r\x02\0\x06\x12\x04\x98\x05\x0b'\n\r\n\x05\x04\r\x02\0\x01\x12\
    \x04\x98\x05(4\n\r\n\x05\x04\r\x02\0\x03\x12\x04\x98\x0578\n\xd1\x02\n\
    \x04\x04\r\x02\x01\x12\x04\x9f\x05\x02\x14\x1a\xc2\x02\x20If\x20`false`,\
    \x20this\x20`StreamingRecognitionResult`\x20represents\x20an\n\x20interi\
    m\x20result\x20that\x20may\x20change.\x20If\x20`true`,\x20this\x20is\x20\
    the\x20final\x20time\x20the\n\x20speech\x20service\x20will\x20return\x20\
    this\x20particular\x20`StreamingRecognitionResult`,\n\x20the\x20recogniz\
    er\x20will\x20not\x20return\x20any\x20further\x20hypotheses\x20for\x20th\
    is\x20portion\x20of\n\x20the\x20transcript\x20and\x20corresponding\x20au\
    dio.\n\n\r\n\x05\x04\r\x02\x01\x05\x12\x04\x9f\x05\x02\x06\n\r\n\x05\x04\
    \r\x02\x01\x01\x12\x04\x9f\x05\x07\x0f\n\r\n\x05\x04\r\x02\x01\x03\x12\
    \x04\x9f\x05\x12\x13\n\xd2\x02\n\x04\x04\r\x02\x02\x12\x04\xa6\x05\x02\
    \x16\x1a\xc3\x02\x20An\x20estimate\x20of\x20the\x20likelihood\x20that\
    \x20the\x20recognizer\x20will\x20not\n\x20change\x20its\x20guess\x20abou\
    t\x20this\x20interim\x20result.\x20Values\x20range\x20from\x200.0\n\x20(\
    completely\x20unstable)\x20to\x201.0\x20(completely\x20stable).\n\x20Thi\
    s\x20field\x20is\x20only\x20provided\x20for\x20interim\x20results\x20(`i\
    s_final=false`).\n\x20The\x20default\x20of\x200.0\x20is\x20a\x20sentinel\
    \x20value\x20indicating\x20`stability`\x20was\x20not\x20set.\n\n\r\n\x05\
    \x04\r\x02\x02\x05\x12\x04\xa6\x05\x02\x07\n\r\n\x05\x04\r\x02\x02\x01\
    \x12\x04\xa6\x05\x08\x11\n\r\n\x05\x04\r\x02\x02\x03\x12\x04\xa6\x05\x14\
    \x15\n^\n\x04\x04\r\x02\x03\x12\x04\xaa\x05\x02/\x1aP\x20Time\x20offset\
    \x20of\x20the\x20end\x20of\x20this\x20result\x20relative\x20to\x20the\n\
    \x20beginning\x20of\x20the\x20audio.\n\n\r\n\x05\x04\r\x02\x03\x06\x12\
    \x04\xaa\x05\x02\x1a\n\r\n\x05\x04\r\x02\x03\x01\x12\x04\xaa\x05\x1b*\n\
    \r\n\x05\x04\r\x02\x03\x03\x12\x04\xaa\x05-.\n\xd8\x01\n\x04\x04\r\x02\
    \x04\x12\x04\xaf\x05\x02\x18\x1a\xc9\x01\x20For\x20multi-channel\x20audi\
    o,\x20this\x20is\x20the\x20channel\x20number\x20corresponding\x20to\x20t\
    he\n\x20recognized\x20result\x20for\x20the\x20audio\x20from\x20that\x20c\
    hannel.\n\x20For\x20audio_channel_count\x20=\x20N,\x20its\x20output\x20v\
    alues\x20can\x20range\x20from\x20'1'\x20to\x20'N'.\n\n\r\n\x05\x04\r\x02\
    \x04\x05\x12\x04\xaf\x05\x02\x07\n\r\n\x05\x04\r\x02\x04\x01\x12\x04\xaf\
    \x05\x08\x13\n\r\n\x05\x04\r\x02\x04\x03\x12\x04\xaf\x05\x16\x17\n\xd6\
    \x01\n\x04\x04\r\x02\x05\x12\x06\xb4\x05\x02\xb5\x050\x1a\xc5\x01\x20The\
    \x20[BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)\x20language\
    \x20tag\x20of\n\x20the\x20language\x20in\x20this\x20result.\x20This\x20l\
    anguage\x20code\x20was\x20detected\x20to\x20have\x20the\n\x20most\x20lik\
    elihood\x20of\x20being\x20spoken\x20in\x20the\x20audio.\n\n\r\n\x05\x04\
    \r\x02\x05\x05\x12\x04\xb4\x05\x02\x08\n\r\n\x05\x04\r\x02\x05\x01\x12\
    \x04\xb4\x05\t\x16\n\r\n\x05\x04\r\x02\x05\x03\x12\x04\xb4\x05\x19\x1a\n\
    \r\n\x05\x04\r\x02\x05\x08\x12\x04\xb5\x05\x04/\n\x10\n\x08\x04\r\x02\
    \x05\x08\x9c\x08\0\x12\x04\xb5\x05\x05.\nT\n\x02\x04\x0e\x12\x06\xb9\x05\
    \0\xc4\x05\x01\x1aF\x20A\x20speech\x20recognition\x20result\x20correspon\
    ding\x20to\x20a\x20portion\x20of\x20the\x20audio.\n\n\x0b\n\x03\x04\x0e\
    \x01\x12\x04\xb9\x05\x08\x1f\n\x83\x02\n\x04\x04\x0e\x02\0\x12\x04\xbe\
    \x05\x029\x1a\xf4\x01\x20May\x20contain\x20one\x20or\x20more\x20recognit\
    ion\x20hypotheses\x20(up\x20to\x20the\n\x20maximum\x20specified\x20in\
    \x20`max_alternatives`).\n\x20These\x20alternatives\x20are\x20ordered\
    \x20in\x20terms\x20of\x20accuracy,\x20with\x20the\x20top\x20(first)\n\
    \x20alternative\x20being\x20the\x20most\x20probable,\x20as\x20ranked\x20\
    by\x20the\x20recognizer.\n\n\r\n\x05\x04\x0e\x02\0\x04\x12\x04\xbe\x05\
    \x02\n\n\r\n\x05\x04\x0e\x02\0\x06\x12\x04\xbe\x05\x0b'\n\r\n\x05\x04\
    \x0e\x02\0\x01\x12\x04\xbe\x05(4\n\r\n\x05\x04\x0e\x02\0\x03\x12\x04\xbe\
    \x0578\n\xd8\x01\n\x04\x04\x0e\x02\x01\x12\x04\xc3\x05\x02\x18\x1a\xc9\
    \x01\x20For\x20multi-channel\x20audio,\x20this\x20is\x20the\x20channel\
    \x20number\x20corresponding\x20to\x20the\n\x20recognized\x20result\x20fo\
    r\x20the\x20audio\x20from\x20that\x20channel.\n\x20For\x20audio_channel_\
    count\x20=\x20N,\x20its\x20output\x20values\x20can\x20range\x20from\x20'\
    1'\x20to\x20'N'.\n\n\r\n\x05\x04\x0e\x02\x01\x05\x12\x04\xc3\x05\x02\x07\
    \n\r\n\x05\x04\x0e\x02\x01\x01\x12\x04\xc3\x05\x08\x13\n\r\n\x05\x04\x0e\
    \x02\x01\x03\x12\x04\xc3\x05\x16\x17\n<\n\x02\x04\x0f\x12\x06\xc7\x05\0\
    \xd8\x05\x01\x1a.\x20Alternative\x20hypotheses\x20(a.k.a.\x20n-best\x20l\
    ist).\n\n\x0b\n\x03\x04\x0f\x01\x12\x04\xc7\x05\x08$\nK\n\x04\x04\x0f\
    \x02\0\x12\x04\xc9\x05\x02\x18\x1a=\x20Transcript\x20text\x20representin\
    g\x20the\x20words\x20that\x20the\x20user\x20spoke.\n\n\r\n\x05\x04\x0f\
    \x02\0\x05\x12\x04\xc9\x05\x02\x08\n\r\n\x05\x04\x0f\x02\0\x01\x12\x04\
    \xc9\x05\t\x13\n\r\n\x05\x04\x0f\x02\0\x03\x12\x04\xc9\x05\x16\x17\n\xcd\
    \x03\n\x04\x04\x0f\x02\x01\x12\x04\xd2\x05\x02\x17\x1a\xbe\x03\x20The\
    \x20confidence\x20estimate\x20between\x200.0\x20and\x201.0.\x20A\x20high\
    er\x20number\n\x20indicates\x20an\x20estimated\x20greater\x20likelihood\
    \x20that\x20the\x20recognized\x20words\x20are\n\x20correct.\x20This\x20f\
    ield\x20is\x20set\x20only\x20for\x20the\x20top\x20alternative\x20of\x20a\
    \x20non-streaming\n\x20result\x20or,\x20of\x20a\x20streaming\x20result\
    \x20where\x20`is_final=true`.\n\x20This\x20field\x20is\x20not\x20guarant\
    eed\x20to\x20be\x20accurate\x20and\x20users\x20should\x20not\x20rely\x20\
    on\x20it\n\x20to\x20be\x20always\x20provided.\n\x20The\x20default\x20of\
    \x200.0\x20is\x20a\x20sentinel\x20value\x20indicating\x20`confidence`\
    \x20was\x20not\x20set.\n\n\r\n\x05\x04\x0f\x02\x01\x05\x12\x04\xd2\x05\
    \x02\x07\n\r\n\x05\x04\x0f\x02\x01\x01\x12\x04\xd2\x05\x08\x12\n\r\n\x05\
    \x04\x0f\x02\x01\x03\x12\x04\xd2\x05\x15\x16\n\xbd\x01\n\x04\x04\x0f\x02\
    \x02\x12\x04\xd7\x05\x02\x1e\x1a\xae\x01\x20A\x20list\x20of\x20word-spec\
    ific\x20information\x20for\x20each\x20recognized\x20word.\n\x20Note:\x20\
    When\x20`enable_speaker_diarization`\x20is\x20true,\x20you\x20will\x20se\
    e\x20all\x20the\x20words\n\x20from\x20the\x20beginning\x20of\x20the\x20a\
    udio.\n\n\r\n\x05\x04\x0f\x02\x02\x04\x12\x04\xd7\x05\x02\n\n\r\n\x05\
    \x04\x0f\x02\x02\x06\x12\x04\xd7\x05\x0b\x13\n\r\n\x05\x04\x0f\x02\x02\
    \x01\x12\x04\xd7\x05\x14\x19\n\r\n\x05\x04\x0f\x02\x02\x03\x12\x04\xd7\
    \x05\x1c\x1d\n?\n\x02\x04\x10\x12\x06\xdb\x05\0\xf6\x05\x01\x1a1\x20Word\
    -specific\x20information\x20for\x20recognized\x20words.\n\n\x0b\n\x03\
    \x04\x10\x01\x12\x04\xdb\x05\x08\x10\n\xa4\x02\n\x04\x04\x10\x02\0\x12\
    \x04\xe2\x05\x02*\x1a\x95\x02\x20Time\x20offset\x20relative\x20to\x20the\
    \x20beginning\x20of\x20the\x20audio,\n\x20and\x20corresponding\x20to\x20\
    the\x20start\x20of\x20the\x20spoken\x20word.\n\x20This\x20field\x20is\
    \x20only\x20set\x20if\x20`enable_word_time_offsets=true`\x20and\x20only\
    \n\x20in\x20the\x20top\x20hypothesis.\n\x20This\x20is\x20an\x20experimen\
    tal\x20feature\x20and\x20the\x20accuracy\x20of\x20the\x20time\x20offset\
    \x20can\n\x20vary.\n\n\r\n\x05\x04\x10\x02\0\x06\x12\x04\xe2\x05\x02\x1a\
    \n\r\n\x05\x04\x10\x02\0\x01\x12\x04\xe2\x05\x1b%\n\r\n\x05\x04\x10\x02\
    \0\x03\x12\x04\xe2\x05()\n\xa2\x02\n\x04\x04\x10\x02\x01\x12\x04\xea\x05\
    \x02(\x1a\x93\x02\x20Time\x20offset\x20relative\x20to\x20the\x20beginnin\
    g\x20of\x20the\x20audio,\n\x20and\x20corresponding\x20to\x20the\x20end\
    \x20of\x20the\x20spoken\x20word.\n\x20This\x20field\x20is\x20only\x20set\
    \x20if\x20`enable_word_time_offsets=true`\x20and\x20only\n\x20in\x20the\
    \x20top\x20hypothesis.\n\x20This\x20is\x20an\x20experimental\x20feature\
    \x20and\x20the\x20accuracy\x20of\x20the\x20time\x20offset\x20can\n\x20va\
    ry.\n\n\r\n\x05\x04\x10\x02\x01\x06\x12\x04\xea\x05\x02\x1a\n\r\n\x05\
    \x04\x10\x02\x01\x01\x12\x04\xea\x05\x1b#\n\r\n\x05\x04\x10\x02\x01\x03\
    \x12\x04\xea\x05&'\nB\n\x04\x04\x10\x02\x02\x12\x04\xed\x05\x02\x12\x1a4\
    \x20The\x20word\x20corresponding\x20to\x20this\x20set\x20of\x20informati\
    on.\n\n\r\n\x05\x04\x10\x02\x02\x05\x12\x04\xed\x05\x02\x08\n\r\n\x05\
    \x04\x10\x02\x02\x01\x12\x04\xed\x05\t\r\n\r\n\x05\x04\x10\x02\x02\x03\
    \x12\x04\xed\x05\x10\x11\n\xc6\x02\n\x04\x04\x10\x02\x03\x12\x06\xf4\x05\
    \x02\xf5\x050\x1a\xb5\x02\x20A\x20distinct\x20integer\x20value\x20is\x20\
    assigned\x20for\x20every\x20speaker\x20within\n\x20the\x20audio.\x20This\
    \x20field\x20specifies\x20which\x20one\x20of\x20those\x20speakers\x20was\
    \x20detected\x20to\n\x20have\x20spoken\x20this\x20word.\x20Value\x20rang\
    es\x20from\x20'1'\x20to\x20diarization_speaker_count.\n\x20speaker_tag\
    \x20is\x20set\x20if\x20enable_speaker_diarization\x20=\x20'true'\x20and\
    \x20only\x20in\x20the\n\x20top\x20alternative.\n\n\r\n\x05\x04\x10\x02\
    \x03\x05\x12\x04\xf4\x05\x02\x07\n\r\n\x05\x04\x10\x02\x03\x01\x12\x04\
    \xf4\x05\x08\x13\n\r\n\x05\x04\x10\x02\x03\x03\x12\x04\xf4\x05\x16\x17\n\
    \r\n\x05\x04\x10\x02\x03\x08\x12\x04\xf5\x05\x04/\n\x10\n\x08\x04\x10\
    \x02\x03\x08\x9c\x08\0\x12\x04\xf5\x05\x05.b\x06proto3\
";

static file_descriptor_proto_lazy: ::protobuf::rt::LazyV2<::protobuf::descriptor::FileDescriptorProto> = ::protobuf::rt::LazyV2::INIT;

fn parse_descriptor_proto() -> ::protobuf::descriptor::FileDescriptorProto {
    ::protobuf::Message::parse_from_bytes(file_descriptor_proto_data).unwrap()
}

pub fn file_descriptor_proto() -> &'static ::protobuf::descriptor::FileDescriptorProto {
    file_descriptor_proto_lazy.get(|| {
        parse_descriptor_proto()
    })
}
